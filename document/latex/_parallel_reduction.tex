\doxysection{Parallel Reduction}
\hypertarget{_parallel_reduction}{}\label{_parallel_reduction}\index{Parallel Reduction@{Parallel Reduction}}
Taskflow provides template function that constructs a task to perform parallel reduction over a range of items.\hypertarget{_parallel_reduction_ParallelReductionInclude}{}\doxysubsection{\texorpdfstring{Include the Header}{Include the Header}}\label{_parallel_reduction_ParallelReductionInclude}
You need to include the header file, {\ttfamily \doxylink{taskflow_2algorithm_2reduce_8hpp}{taskflow/algorithm/reduce.\+hpp}}, for creating a parallel-\/reduction task.


\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{preprocessor}{\#include\ <\mbox{\hyperlink{taskflow_2algorithm_2reduce_8hpp}{taskflow/algorithm/reduce.hpp}}>}}

\end{DoxyCode}
\hypertarget{_parallel_reduction_A2ParallelReduction}{}\doxysubsection{\texorpdfstring{Create a Parallel-\/\+Reduction Task}{Create a Parallel-\/\+Reduction Task}}\label{_parallel_reduction_A2ParallelReduction}
The reduction task created by \doxylink{classtf_1_1_flow_builder_afb24798ebf46e253a40b01bffb1da6a7}{tf\+::\+Taskflow\+::reduce(\+B first, E last, T\& result, O bop, P part)} performs parallel reduction over a range of elements specified by {\ttfamily \mbox{[}first, last)} using the binary operator {\ttfamily bop} and stores the reduced result in {\ttfamily result}. It represents the parallel execution of the following reduction loop\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{keywordflow}{for}(\textcolor{keyword}{auto}\ itr=first;\ itr<last;\ itr++)\ \{}
\DoxyCodeLine{\ \ \mbox{\hyperlink{imgui__impl__opengl3__loader_8h_aa7f56a70231ed8bc64f97aa7c37fcb19}{result}}\ =\ bop(\mbox{\hyperlink{imgui__impl__opengl3__loader_8h_aa7f56a70231ed8bc64f97aa7c37fcb19}{result}},\ *itr);}
\DoxyCodeLine{\}}

\end{DoxyCode}


At runtime, the reduction task spawns a subflow to perform parallel reduction. The reduced result is stored in {\ttfamily result} that will be captured by reference in the reduction task. It is your responsibility to ensure {\ttfamily result} remains alive during the parallel execution.


\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{keywordtype}{int}\ \mbox{\hyperlink{test__parallel__for__each_8cpp_a539b07c7f86d3a9854ed81da50a4fb7d}{sum}}\ =\ 100;}
\DoxyCodeLine{std::vector<int>\ \mbox{\hyperlink{benchmarks_2for__each_2for__each_8hpp_ad86cbaae2e3f21959301250e9f7c2701}{vec}}\ =\ \{1,\ 2,\ 3,\ 4,\ 5,\ 6,\ 7,\ 8,\ 9,\ 10\};}
\DoxyCodeLine{}
\DoxyCodeLine{\mbox{\hyperlink{classtf_1_1_task}{tf::Task}}\ \mbox{\hyperlink{test__partitioner__whitebox_8h_a5c4cf3d37a4eee22275de22cb9619863}{task}}\ =\ \mbox{\hyperlink{poisson_8hpp_aa56fe360bb0ae38e0082f49e394ff825}{taskflow}}.reduce(\mbox{\hyperlink{benchmarks_2for__each_2for__each_8hpp_ad86cbaae2e3f21959301250e9f7c2701}{vec}}.begin(),\ \mbox{\hyperlink{benchmarks_2for__each_2for__each_8hpp_ad86cbaae2e3f21959301250e9f7c2701}{vec}}.end(),\ \mbox{\hyperlink{test__parallel__for__each_8cpp_a539b07c7f86d3a9854ed81da50a4fb7d}{sum}},\ }
\DoxyCodeLine{\ \ []\ (\textcolor{keywordtype}{int}\ l,\ \textcolor{keywordtype}{int}\ \mbox{\hyperlink{offscreen_8c_a4788d82c901b9367dd5c0daff8a7616b}{r}})\ \{\ return\ l\ +\ r;\ \}\ \ \textcolor{comment}{//\ binary\ reducer\ operator}}
\DoxyCodeLine{);}
\DoxyCodeLine{\mbox{\hyperlink{thread__pool_8cpp_a543e564a8407bbeac15cb2d929fec755}{executor}}.run(\mbox{\hyperlink{poisson_8hpp_aa56fe360bb0ae38e0082f49e394ff825}{taskflow}}).wait();}
\DoxyCodeLine{}
\DoxyCodeLine{assert(\mbox{\hyperlink{test__parallel__for__each_8cpp_a539b07c7f86d3a9854ed81da50a4fb7d}{sum}}\ ==\ 100\ +\ 55);}

\end{DoxyCode}


The order in which the binary operator is applied to pairs of elements is {\itshape unspecified}. In other words, the elements of the range may be grouped and rearranged in arbitrary order. The result and the argument types of the binary operator must be consistent with the input data type.\hypertarget{_parallel_reduction_ParallelReductionCaptureIteratorsByReference}{}\doxysubsection{\texorpdfstring{Capture Iterators by Reference}{Capture Iterators by Reference}}\label{_parallel_reduction_ParallelReductionCaptureIteratorsByReference}
You can pass iterators by reference using @std\+\_\+ref to marshal parameter update between dependent tasks. This is especially useful when the range is unknown at the time of creating a parallel-\/reduction task, but needs initialization from another task.


\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{keywordtype}{int}\ \mbox{\hyperlink{test__parallel__for__each_8cpp_a539b07c7f86d3a9854ed81da50a4fb7d}{sum}}\ =\ 100;}
\DoxyCodeLine{std::vector<int>\ \mbox{\hyperlink{benchmarks_2for__each_2for__each_8hpp_ad86cbaae2e3f21959301250e9f7c2701}{vec}};}
\DoxyCodeLine{std::vector<int>::iterator\ first,\ last;}
\DoxyCodeLine{}
\DoxyCodeLine{\mbox{\hyperlink{classtf_1_1_task}{tf::Task}}\ \mbox{\hyperlink{structinit}{init}}\ =\ \mbox{\hyperlink{poisson_8hpp_aa56fe360bb0ae38e0082f49e394ff825}{taskflow}}.emplace([\&]()\{}
\DoxyCodeLine{\ \ \mbox{\hyperlink{benchmarks_2for__each_2for__each_8hpp_ad86cbaae2e3f21959301250e9f7c2701}{vec}}\ \ \ =\ \{1,\ 2,\ 3,\ 4,\ 5,\ 6,\ 7,\ 8,\ 9,\ 10\};}
\DoxyCodeLine{\ \ first\ =\ \mbox{\hyperlink{benchmarks_2for__each_2for__each_8hpp_ad86cbaae2e3f21959301250e9f7c2701}{vec}}.begin();}
\DoxyCodeLine{\ \ last\ \ =\ \mbox{\hyperlink{benchmarks_2for__each_2for__each_8hpp_ad86cbaae2e3f21959301250e9f7c2701}{vec}}.end();}
\DoxyCodeLine{\});}
\DoxyCodeLine{}
\DoxyCodeLine{tf::Task\ \mbox{\hyperlink{test__partitioner__whitebox_8h_a5c4cf3d37a4eee22275de22cb9619863}{task}}\ =\ \mbox{\hyperlink{poisson_8hpp_aa56fe360bb0ae38e0082f49e394ff825}{taskflow}}.reduce(std::ref(first),\ std::ref(last),\ \mbox{\hyperlink{test__parallel__for__each_8cpp_a539b07c7f86d3a9854ed81da50a4fb7d}{sum}},\ }
\DoxyCodeLine{\ \ []\ (\textcolor{keywordtype}{int}\ l,\ \textcolor{keywordtype}{int}\ \mbox{\hyperlink{offscreen_8c_a4788d82c901b9367dd5c0daff8a7616b}{r}})\ \{\ \textcolor{keywordflow}{return}\ l\ +\ \mbox{\hyperlink{offscreen_8c_a4788d82c901b9367dd5c0daff8a7616b}{r}};\ \}\ \ \textcolor{comment}{//\ binary\ reducer\ operator}}
\DoxyCodeLine{);}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{//\ wrong!\ must\ use\ std::ref,\ or\ first\ and\ last\ are\ captured\ by\ copy}}
\DoxyCodeLine{\textcolor{comment}{//\ tf::Task\ task\ =\ taskflow.reduce(first,\ last,\ sum,\ []\ (int\ l,\ int\ r)\ \{\ }}
\DoxyCodeLine{\textcolor{comment}{//\ \ \ return\ l\ +\ r;\ \ \ \ //\ binary\ reducer\ operator}}
\DoxyCodeLine{\textcolor{comment}{//\ \});}}
\DoxyCodeLine{}
\DoxyCodeLine{\mbox{\hyperlink{boing_8c_a2858154e2009b0e6e616f313177762bc}{init}}.precede(\mbox{\hyperlink{test__partitioner__whitebox_8h_a5c4cf3d37a4eee22275de22cb9619863}{task}});}
\DoxyCodeLine{}
\DoxyCodeLine{\mbox{\hyperlink{thread__pool_8cpp_a543e564a8407bbeac15cb2d929fec755}{executor}}.\mbox{\hyperlink{classtf_1_1_executor_a519777f5783981d534e9e53b99712069}{run}}(\mbox{\hyperlink{poisson_8hpp_aa56fe360bb0ae38e0082f49e394ff825}{taskflow}}).wait();}
\DoxyCodeLine{}
\DoxyCodeLine{assert(\mbox{\hyperlink{test__parallel__for__each_8cpp_a539b07c7f86d3a9854ed81da50a4fb7d}{sum}}\ ==\ 100\ +\ 55);}

\end{DoxyCode}


In the above example, when {\ttfamily init} finishes, {\ttfamily vec} has been initialized to 10 elements with {\ttfamily first} and {\ttfamily last} pointing to the data range of {\ttfamily vec}. The reduction task will then work on this initialized range as a result of passing iterators by reference.\hypertarget{_parallel_reduction_A2ParallelTransformationReduction}{}\doxysubsection{\texorpdfstring{Create a Parallel-\/\+Transform-\/\+Reduction Task}{Create a Parallel-\/\+Transform-\/\+Reduction Task}}\label{_parallel_reduction_A2ParallelTransformationReduction}
It is common to transform each element into a new data type and then perform reduction on the transformed elements. Taskflow provides a method, \doxylink{classtf_1_1_flow_builder_aa62d24438c0860e76153ffd129deba41}{tf\+::\+Taskflow\+::transform\+\_\+reduce(\+B first, E last, T\& result, BOP bop, UOP uop, P part)}, that applies {\ttfamily uop} to transform each element in the specified range and then perform parallel reduction over {\ttfamily result} and transformed elements. It represents the parallel execution of the following reduction loop\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{keywordflow}{for}(\textcolor{keyword}{auto}\ itr=first;\ itr<last;\ itr++)\ \{}
\DoxyCodeLine{\ \ \mbox{\hyperlink{imgui__impl__opengl3__loader_8h_aa7f56a70231ed8bc64f97aa7c37fcb19}{result}}\ =\ bop(\mbox{\hyperlink{imgui__impl__opengl3__loader_8h_aa7f56a70231ed8bc64f97aa7c37fcb19}{result}},\ uop(*itr));}
\DoxyCodeLine{\}}

\end{DoxyCode}


The example below transforms each digit in a string to an integer number and then sums up all integers in parallel.


\begin{DoxyCode}{0}
\DoxyCodeLine{std::string\ str\ =\ \textcolor{stringliteral}{"{}12345678"{}};}
\DoxyCodeLine{\textcolor{keywordtype}{int}\ \mbox{\hyperlink{test__parallel__for__each_8cpp_a539b07c7f86d3a9854ed81da50a4fb7d}{sum}}\ \{0\};}
\DoxyCodeLine{\mbox{\hyperlink{classtf_1_1_task}{tf::Task}}\ \mbox{\hyperlink{test__partitioner__whitebox_8h_a5c4cf3d37a4eee22275de22cb9619863}{task}}\ =\ \mbox{\hyperlink{poisson_8hpp_aa56fe360bb0ae38e0082f49e394ff825}{taskflow}}.transform\_reduce(str.begin(),\ str.end(),\ \mbox{\hyperlink{test__parallel__for__each_8cpp_a539b07c7f86d3a9854ed81da50a4fb7d}{sum}},}
\DoxyCodeLine{\ \ []\ (\textcolor{keywordtype}{int}\ \mbox{\hyperlink{_cwise__product_8cpp_ad2cbe4616e813eb9af81732dca777b24}{a}},\ \textcolor{keywordtype}{int}\ \mbox{\hyperlink{offscreen_8c_a846c9667e34d56c560bb7f0ac6e173f6}{b}})\ \{\ \ \ \ \ \ \textcolor{comment}{//\ binary\ reduction\ operator}}
\DoxyCodeLine{\ \ \ \ return\ a\ +\ b;}
\DoxyCodeLine{\ \ \},\ \ }
\DoxyCodeLine{\ \ []\ (\textcolor{keywordtype}{char}\ \mbox{\hyperlink{bench_vec_add_8cpp_a41689956983587b085f9da3e48f31d99}{c}})\ -\/>\ \textcolor{keywordtype}{int}\ \{\ \ \ \ \ \textcolor{comment}{//\ unary\ transformation\ operator}}
\DoxyCodeLine{\ \ \ \ return\ c\ -\/\ \textcolor{stringliteral}{'0'};}
\DoxyCodeLine{\ \ \}\ \ \ }
\DoxyCodeLine{);\ }
\DoxyCodeLine{\mbox{\hyperlink{thread__pool_8cpp_a543e564a8407bbeac15cb2d929fec755}{executor}}.run(\mbox{\hyperlink{poisson_8hpp_aa56fe360bb0ae38e0082f49e394ff825}{taskflow}}).wait();\ }
\DoxyCodeLine{assert(\mbox{\hyperlink{test__parallel__for__each_8cpp_a539b07c7f86d3a9854ed81da50a4fb7d}{sum}}\ ==\ 1\ +\ 2\ +\ 3\ +\ 4\ +\ 5\ +\ 6\ +\ 7\ +\ 8);\ \ \textcolor{comment}{//\ sum\ will\ be\ 36\ }}

\end{DoxyCode}


The order in which we apply the binary operator on the transformed elements is {\itshape unspecified}. It is possible that the binary operator will take {\itshape r-\/value} in both arguments, for example, {\ttfamily bop(uop(\texorpdfstring{$\ast$}{*}itr1), uop(\texorpdfstring{$\ast$}{*}itr2))}, due to the transformed temporaries. When data passing is expensive, you may define the result type {\ttfamily T} to be move-\/constructible.\hypertarget{_parallel_reduction_ParallelReductionCreateAReduceByIndexTask}{}\doxysubsection{\texorpdfstring{Create a Reduce-\/by-\/\+Index Task}{Create a Reduce-\/by-\/\+Index Task}}\label{_parallel_reduction_ParallelReductionCreateAReduceByIndexTask}
Unlike {\ttfamily \doxylink{classtf_1_1_flow_builder_afb24798ebf46e253a40b01bffb1da6a7}{tf\+::\+Taskflow\+::reduce}}, the {\ttfamily \doxylink{classtf_1_1_flow_builder_a3ea810696c4b29824d1aaef15342c825}{tf\+::\+Taskflow\+::reduce\+\_\+by\+\_\+index}} function lets you perform a parallel reduction over an index range, but with more control over how each part of the range is processed. This is useful when you need to customize the reduction process for each subrange or you want to incorporate optimizations like SIMD. The example below performs a sum-\/reduction over all elements in {\ttfamily data} with {\ttfamily res\+:} ~\newline



\begin{DoxyCode}{0}
\DoxyCodeLine{std::vector<double>\ \mbox{\hyperlink{imgui__impl__opengl3__loader_8h_a02796e583e939f923a255e43d2c3b177}{data}}(100000);}
\DoxyCodeLine{\textcolor{keywordtype}{double}\ \mbox{\hyperlink{_partial_redux__count_8cpp_acbe60897559b79afc28b79b0687b5f29}{res}}\ =\ 1.0;}
\DoxyCodeLine{\mbox{\hyperlink{poisson_8hpp_aa56fe360bb0ae38e0082f49e394ff825}{taskflow}}.reduce\_by\_index(}
\DoxyCodeLine{\ \ \textcolor{comment}{//\ index\ range}}
\DoxyCodeLine{\ \ \mbox{\hyperlink{classtf_1_1_index_range}{tf::IndexRange<size\_t>}}(0,\ \mbox{\hyperlink{main-override-static_8c_a0240ac851181b84ac374872dc5434ee4}{N}},\ 1),}
\DoxyCodeLine{\ \ \textcolor{comment}{//\ final\ result}}
\DoxyCodeLine{\ \ \mbox{\hyperlink{_partial_redux__count_8cpp_acbe60897559b79afc28b79b0687b5f29}{res}},}
\DoxyCodeLine{\ \ \textcolor{comment}{//\ local\ reducer}}
\DoxyCodeLine{\ \ [\&](\mbox{\hyperlink{classtf_1_1_index_range}{tf::IndexRange<size\_t>}}\ subrange,\ std::optional<double>\ running\_total)\ \{\ }
\DoxyCodeLine{\ \ \ \ \textcolor{keywordtype}{double}\ residual\ =\ running\_total\ ?\ *running\_total\ :\ 0.0;}
\DoxyCodeLine{\ \ \ \ \textcolor{keywordflow}{for}(\textcolor{keywordtype}{size\_t}\ \mbox{\hyperlink{_bi_c_g_s_t_a_b__step__by__step_8cpp_acb559820d9ca11295b4500f179ef6392}{i}}=subrange.\mbox{\hyperlink{classtf_1_1_index_range_a2b52381358ab392efa257e185a33d4af}{begin}}();\ \mbox{\hyperlink{_bi_c_g_s_t_a_b__step__by__step_8cpp_acb559820d9ca11295b4500f179ef6392}{i}}<subrange.\mbox{\hyperlink{classtf_1_1_index_range_a280096cb4056bc19b86da77d019434e4}{end}}();\ \mbox{\hyperlink{_bi_c_g_s_t_a_b__step__by__step_8cpp_acb559820d9ca11295b4500f179ef6392}{i}}+=subrange.\mbox{\hyperlink{classtf_1_1_index_range_aafd4f2d04614e550649cd9b7912e0bf1}{step\_size}}())\ \{}
\DoxyCodeLine{\ \ \ \ \ \ \mbox{\hyperlink{imgui__impl__opengl3__loader_8h_a02796e583e939f923a255e43d2c3b177}{data}}[\mbox{\hyperlink{_bi_c_g_s_t_a_b__step__by__step_8cpp_acb559820d9ca11295b4500f179ef6392}{i}}]\ =\ 1.0;\ \ \ \ \ \ \ \ \textcolor{comment}{//\ we\ initialize\ the\ data\ here}}
\DoxyCodeLine{\ \ \ \ \ \ residual\ +=\ \mbox{\hyperlink{imgui__impl__opengl3__loader_8h_a02796e583e939f923a255e43d2c3b177}{data}}[\mbox{\hyperlink{_bi_c_g_s_t_a_b__step__by__step_8cpp_acb559820d9ca11295b4500f179ef6392}{i}}];}
\DoxyCodeLine{\ \ \ \ \}}
\DoxyCodeLine{\ \ \ \ \mbox{\hyperlink{printf_8h_aee3ed3a831f25f07e7be3919fff2203a}{printf}}(\textcolor{stringliteral}{"{}partial\ sum\ =\ \%lf\(\backslash\)n"{}},\ residual);}
\DoxyCodeLine{\ \ \ \ \textcolor{keywordflow}{return}\ residual;}
\DoxyCodeLine{\ \ \},}
\DoxyCodeLine{\ \ \textcolor{comment}{//\ global\ reducer}}
\DoxyCodeLine{\ \ std::plus<double>()}
\DoxyCodeLine{);}
\DoxyCodeLine{}
\DoxyCodeLine{\mbox{\hyperlink{thread__pool_8cpp_a543e564a8407bbeac15cb2d929fec755}{executor}}.\mbox{\hyperlink{classtf_1_1_executor_a519777f5783981d534e9e53b99712069}{run}}(\mbox{\hyperlink{poisson_8hpp_aa56fe360bb0ae38e0082f49e394ff825}{taskflow}}).wait();}
\DoxyCodeLine{assert(\mbox{\hyperlink{_partial_redux__count_8cpp_acbe60897559b79afc28b79b0687b5f29}{res}}\ ==\ 100001);}

\end{DoxyCode}


The local reducer {\ttfamily lop} computes a partial sum for each subrange, and the global reducer {\ttfamily gop} combines the partial results into the final result and store it in {\ttfamily res}, whose initial value (i.\+e., {\ttfamily 1.\+0} here) also participates in the reduction process. The second argument of the local reducer is a @std\+\_\+optional type, which indicates the current partial sum until this subrange. Apparently, the first subrange does not have any partial sum since there is no running total from previous subranges (i.\+e., {\ttfamily running\+\_\+total} is @std\+\_\+nullopt).\hypertarget{_parallel_reduction_ParallelReductionConfigureAPartitioner}{}\doxysubsection{\texorpdfstring{Configure a Partitioner}{Configure a Partitioner}}\label{_parallel_reduction_ParallelReductionConfigureAPartitioner}
You can configure a partitioner for parallel-\/reduction tasks to run with different scheduling methods, such as guided partitioning, dynamic partitioning, and static partitioning. The following example creates two parallel-\/reduction tasks using two different partitioners, one with the static partitioning algorithm and another one with the guided partitioning algorithm\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{\mbox{\hyperlink{classtf_1_1_static_partitioner}{tf::StaticPartitioner}}\ static\_partitioner;}
\DoxyCodeLine{\mbox{\hyperlink{classtf_1_1_guided_partitioner}{tf::GuidedPartitioner}}\ guided\_partitioner;}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{keywordtype}{int}\ sum1\ =\ 100,\ sum2\ =\ 100;}
\DoxyCodeLine{std::vector<int>\ \mbox{\hyperlink{benchmarks_2for__each_2for__each_8hpp_ad86cbaae2e3f21959301250e9f7c2701}{vec}}\ =\ \{1,\ 2,\ 3,\ 4,\ 5,\ 6,\ 7,\ 8,\ 9,\ 10\};}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{//\ create\ a\ parallel-\/reduction\ task\ with\ static\ partitioner}}
\DoxyCodeLine{\mbox{\hyperlink{poisson_8hpp_aa56fe360bb0ae38e0082f49e394ff825}{taskflow}}.reduce(\mbox{\hyperlink{benchmarks_2for__each_2for__each_8hpp_ad86cbaae2e3f21959301250e9f7c2701}{vec}}.begin(),\ \mbox{\hyperlink{benchmarks_2for__each_2for__each_8hpp_ad86cbaae2e3f21959301250e9f7c2701}{vec}}.end(),\ sum1,\ }
\DoxyCodeLine{\ \ []\ (\textcolor{keywordtype}{int}\ l,\ \textcolor{keywordtype}{int}\ \mbox{\hyperlink{offscreen_8c_a4788d82c901b9367dd5c0daff8a7616b}{r}})\ \{\ return\ l\ +\ r;\ \},}
\DoxyCodeLine{\ \ static\_partitioner}
\DoxyCodeLine{);}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{//\ create\ a\ parallel-\/reduction\ task\ with\ guided\ partitioner}}
\DoxyCodeLine{\mbox{\hyperlink{poisson_8hpp_aa56fe360bb0ae38e0082f49e394ff825}{taskflow}}.reduce(\mbox{\hyperlink{benchmarks_2for__each_2for__each_8hpp_ad86cbaae2e3f21959301250e9f7c2701}{vec}}.begin(),\ \mbox{\hyperlink{benchmarks_2for__each_2for__each_8hpp_ad86cbaae2e3f21959301250e9f7c2701}{vec}}.end(),\ sum2,\ }
\DoxyCodeLine{\ \ []\ (\textcolor{keywordtype}{int}\ l,\ \textcolor{keywordtype}{int}\ \mbox{\hyperlink{offscreen_8c_a4788d82c901b9367dd5c0daff8a7616b}{r}})\ \{\ return\ l\ +\ r;\ \},}
\DoxyCodeLine{\ \ guided\_partitioner}
\DoxyCodeLine{);}

\end{DoxyCode}


\begin{DoxyAttention}{注意}
By default, parallel-\/reduction tasks use \doxylink{namespacetf_ace2c5adcd5039483eebb6dbdbb6f33e3}{tf\+::\+Default\+Partitioner} if no partitioner is specified. 
\end{DoxyAttention}
