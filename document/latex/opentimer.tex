\doxysection{Static Timing Analysis}
\hypertarget{opentimer}{}\label{opentimer}\index{Static Timing Analysis@{Static Timing Analysis}}
We have applied Taskflow to solve a real-\/world VLSI static timing analysis problem that incorporates hundreds of millions of tasks and dependencies. The goal is to analyze the timing behavior of a design.\hypertarget{opentimer_UseCasesOpenTimer}{}\doxysubsection{\texorpdfstring{Open\+Timer\+: A High-\/performance Timing Analysis Tool}{Open\+Timer\+: A High-\/performance Timing Analysis Tool}}\label{opentimer_UseCasesOpenTimer}
\doxylink{class_static}{Static} timing analysis (STA) is an important step in the overall chip design flow. It verifies the static behavior of a circuit design and ensure its correct functionality under the given clock speed. However, efficient parallel timing analysis is extremely challenging to design and implement, due to large irregularity and graph-\/oriented computing. The following figure shows an extracted timing graph from an industrial design.



We consider our research project \href{https://github.com/OpenTimer/OpenTimer}{\texttt{ Open\+Timer}}, an open-\/source static timing analyzer that has been used in many industrial and academic projects. The first release v1 in 2015 implemented the {\itshape pipeline-\/based levelization} algorithm using the Open\+MP 4.\+5 task dependency clause. To overcome the performance bottleneck caused by pipeline, we rewrote the core incremental timing engine using Taskflow in the second release v2.\hypertarget{opentimer_UseCaseOpenTimerProgrammingEffort}{}\doxysubsection{\texorpdfstring{Programming Effort}{Programming Effort}}\label{opentimer_UseCaseOpenTimerProgrammingEffort}
The table below measures the software costs of two Open\+Timer versions using the Linux tool @\+SLOCCount. In Open\+Timer v2, a large amount of exhaustive Open\+MP dependency clauses that were used to carry out task dependencies are now replaced with only a few lines of flexible Taskflow code (9123 vs 4482). The maximum cyclomatic complexity in a single function is reduced from 58 to 20, due to Taskflow\textquotesingle{}s programmability.

 \tabulinesep=1mm
\begin{longtabu}spread 0pt [c]{*{5}{|X[-1]}|}
\hline
\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Tool   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Task Model   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Lines of Code   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Cyclomatic Complexity   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Cost    }\\\cline{1-5}
\endfirsthead
\hline
\endfoot
\hline
\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Tool   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Task Model   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Lines of Code   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Cyclomatic Complexity   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Cost    }\\\cline{1-5}
\endhead
\PBS\centering Open\+Timer v1   &\PBS\centering Open\+MP 4.\+5   &\PBS\centering 9123   &\PBS\centering 58   &\PBS\centering \$275,287    \\\cline{1-5}
\PBS\centering Open\+Timer v2   &\PBS\centering Taskflow   &\PBS\centering 4482   &\PBS\centering 20   &\PBS\centering \$130,523   \\\cline{1-5}
\end{longtabu}


Open\+Timer v1 relied on a pipeline data structure to adtop loop parallelism with Open\+MP. We found it very difficult to go beyond this paradigm because of the insufficient support for dynamic dependencies in Open\+MP. With Taskflow in place, we can break this bottleneck and easily model both static and dynamic task dependencies at programming time and runtime. The task dependency graph flows computations naturally with the timing graph, providing improved asynchrony and performance. The following figure shows a task graph to carry one iteration of timing update.\hypertarget{opentimer_UseCaseOpenTimerPerformanceImprovement}{}\doxysubsection{\texorpdfstring{Performance Improvement}{Performance Improvement}}\label{opentimer_UseCaseOpenTimerPerformanceImprovement}
We compare the performance between Open\+Timer v1 and v2. We evaluated the runtime versus incremental iterations under 16 CPUs on two industrial circuit designs tv80 (5.\+3K gates and 5.\+3K nets) and vga\+\_\+lcd (139.\+5K gates and 139.\+6K nets) with 45nm Nan\+Gate cell libraris. Each incremental iteration refers a design modification followed by a timing query to trigger a timing update. In v1, this includes the time to reconstruct the data structure required by Open\+MP to alter the task dependencies. In v2, this includes the time to create and launch a new task dependency graph



The scalability of Taskflow is shown in the Figure below. We used two million-\/scale designs, netcard (1.\+4M gates) and leon3mp (1.\+2M gates) to evaluate the runtime of v1 and v2 across different number of CPUs. There are two important observations. First, v2 is slightly slower than v1 at one CPU (3-\/4\%), where all Open\+MP\textquotesingle{}s constructs are literally disabled. This shows the graph overhead of Taskflow; yet it is negligible. Second, v2 is consistently faster than v1 regardless of CPU numbers except one. This highlights that Taskflow\textquotesingle{}s programming model largely improves the design of a parallel VLSI timing engine that would otherwise not be possible with Open\+MP.

\hypertarget{opentimer_UseCaseOpenTimerConclusion}{}\doxysubsection{\texorpdfstring{Conclusion}{Conclusion}}\label{opentimer_UseCaseOpenTimerConclusion}
Programming models matter. Different models give different implementations. The parallel code sections may run fast, yet the data structures to support a parallel decomposition strategy may outweigh its parallelism benefits. In Open\+Timer v1, loop-\/based Open\+MP code is very fast. But it\textquotesingle{}s too costly to maintain the pipeline data structure over iterations.\hypertarget{opentimer_UseCaseOpenTimerReferences}{}\doxysubsection{\texorpdfstring{References}{References}}\label{opentimer_UseCaseOpenTimerReferences}
\begin{DoxyItemize}
\item Tsung-\/\+Wei Huang, Guannan Guo, Chun-\/\+Xun Lin, and Martin Wong, "{}\href{https://tsung-wei-huang.github.io/papers/tcad21-ot2.pdf}{\texttt{ Open\+Timer v2\+: A New Parallel Incremental Timing Analysis Engine}},"{} {\itshape IEEE Transactions on Computer-\/\+Aided Design of Integrated Circuits and Systems (TCAD)}, vol. 40, no. 4, pp. 776-\/786, April 2021 \item Tsung-\/\+Wei Huang, Chun-\/\+Xun Lin, Guannan Guo, and Martin Wong, "{}\href{ipdps19.pdf}{\texttt{ Cpp-\/\+Taskflow\+: Fast Task-\/based Parallel Programming using Modern C++}},"{} {\itshape IEEE International Parallel and Distributed Processing Symposium (IPDPS)}, pp. 974-\/983, Rio de Janeiro, Brazil, 2019. \item Tsung-\/\+Wei Huang and Martin Wong, "{}\href{huang_15_01.pdf}{\texttt{ Open\+Timer\+: A High-\/\+Performance Timing Analysis Tool}},"{} {\itshape IEEE/\+ACM International Conference on Computer-\/\+Aided Design (ICCAD)}, pp. 895-\/902, Austin, TX, 2015. \end{DoxyItemize}
