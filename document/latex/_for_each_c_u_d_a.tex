\doxysection{Parallel Iterations}
\hypertarget{_for_each_c_u_d_a}{}\label{_for_each_c_u_d_a}\index{Parallel Iterations@{Parallel Iterations}}
\doxylink{classtf_1_1cuda_flow}{tf\+::cuda\+Flow} provides two template methods, \doxylink{classtf_1_1cuda_flow_a1a681f6223853b6445dcfdad07e4d0fd}{tf\+::cuda\+Flow\+::for\+\_\+each} and \doxylink{classtf_1_1cuda_flow_a34f1ea89e5651faa6e8af522a42556ac}{tf\+::cuda\+Flow\+::for\+\_\+each\+\_\+index}, for creating tasks to perform parallel iterations over a range of items.\hypertarget{_for_each_c_u_d_a_CUDAForEachIncludeTheHeader}{}\doxysubsection{\texorpdfstring{Include the Header}{Include the Header}}\label{_for_each_c_u_d_a_CUDAForEachIncludeTheHeader}
You need to include the header file, {\ttfamily taskflow/cuda/algorithm/for\+\_\+each.hpp}, for creating a parallel-\/iteration task.


\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{preprocessor}{\#include\ <\mbox{\hyperlink{taskflow_2cuda_2algorithm_2for__each_8hpp}{taskflow/cuda/algorithm/for\_each.hpp}}>}}

\end{DoxyCode}
\hypertarget{_for_each_c_u_d_a_ForEachCUDAIndexBasedParallelFor}{}\doxysubsection{\texorpdfstring{Index-\/based Parallel Iterations}{Index-\/based Parallel Iterations}}\label{_for_each_c_u_d_a_ForEachCUDAIndexBasedParallelFor}
Index-\/based parallel-\/for performs parallel iterations over a range {\ttfamily \mbox{[}first, last)} with the given {\ttfamily step} size. The task created by \doxylink{classtf_1_1cuda_flow_a34f1ea89e5651faa6e8af522a42556ac}{tf\+::cuda\+Flow\+::for\+\_\+each\+\_\+index(\+I first, I last, I step, C callable)} represents a kernel of parallel execution for the following loop\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{comment}{//\ positive\ step:\ first,\ first+step,\ first+2*step,\ ...}}
\DoxyCodeLine{\textcolor{keywordflow}{for}(\textcolor{keyword}{auto}\ \mbox{\hyperlink{_bi_c_g_s_t_a_b__step__by__step_8cpp_acb559820d9ca11295b4500f179ef6392}{i}}=first;\ \mbox{\hyperlink{_bi_c_g_s_t_a_b__step__by__step_8cpp_acb559820d9ca11295b4500f179ef6392}{i}}<last;\ \mbox{\hyperlink{_bi_c_g_s_t_a_b__step__by__step_8cpp_acb559820d9ca11295b4500f179ef6392}{i}}+=step)\ \{}
\DoxyCodeLine{\ \ callable(\mbox{\hyperlink{_bi_c_g_s_t_a_b__step__by__step_8cpp_acb559820d9ca11295b4500f179ef6392}{i}});}
\DoxyCodeLine{\}}
\DoxyCodeLine{\textcolor{comment}{//\ negative\ step:\ first,\ first-\/step,\ first-\/2*step,\ ...}}
\DoxyCodeLine{\textcolor{keywordflow}{for}(\textcolor{keyword}{auto}\ \mbox{\hyperlink{_bi_c_g_s_t_a_b__step__by__step_8cpp_acb559820d9ca11295b4500f179ef6392}{i}}=first;\ \mbox{\hyperlink{_bi_c_g_s_t_a_b__step__by__step_8cpp_acb559820d9ca11295b4500f179ef6392}{i}}>last;\ \mbox{\hyperlink{_bi_c_g_s_t_a_b__step__by__step_8cpp_acb559820d9ca11295b4500f179ef6392}{i}}+=step)\ \{}
\DoxyCodeLine{\ \ callable(\mbox{\hyperlink{_bi_c_g_s_t_a_b__step__by__step_8cpp_acb559820d9ca11295b4500f179ef6392}{i}});}
\DoxyCodeLine{\}}

\end{DoxyCode}


Each iteration {\ttfamily i} is independent of each other and is assigned one kernel thread to run the callable. Since the callable runs on GPU, it must be declared with a {\ttfamily \+\_\+\+\_\+device\+\_\+\+\_\+} specifier. The following example creates a kernel that assigns each entry of {\ttfamily gpu\+\_\+data} to 1 over the range {\ttfamily }\mbox{[}0, 100) with step size 1.


\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{comment}{//\ assigns\ each\ element\ in\ gpu\_data\ to\ 1\ over\ the\ range\ [0,\ 100)\ with\ step\ size\ 1}}
\DoxyCodeLine{cudaflow.for\_each\_index(0,\ 100,\ 1,\ [gpu\_data]\ \_\_device\_\_\ (\textcolor{keywordtype}{int}\ idx)\ \{}
\DoxyCodeLine{\ \ gpu\_data[idx]\ =\ 1;}
\DoxyCodeLine{\});}

\end{DoxyCode}
\hypertarget{_for_each_c_u_d_a_ForEachCUDAIteratorBasedParallelIterations}{}\doxysubsection{\texorpdfstring{Iterator-\/based Parallel Iterations}{Iterator-\/based Parallel Iterations}}\label{_for_each_c_u_d_a_ForEachCUDAIteratorBasedParallelIterations}
Iterator-\/based parallel-\/for performs parallel iterations over a range specified by two STL-\/styled iterators, {\ttfamily first} and {\ttfamily last}. The task created by \doxylink{classtf_1_1cuda_flow_a1a681f6223853b6445dcfdad07e4d0fd}{tf\+::cuda\+Flow\+::for\+\_\+each(\+I first, I last, C callable)} represents a parallel execution of the following loop\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{keywordflow}{for}(\textcolor{keyword}{auto}\ \mbox{\hyperlink{_bi_c_g_s_t_a_b__step__by__step_8cpp_acb559820d9ca11295b4500f179ef6392}{i}}=first;\ \mbox{\hyperlink{_bi_c_g_s_t_a_b__step__by__step_8cpp_acb559820d9ca11295b4500f179ef6392}{i}}<last;\ \mbox{\hyperlink{_bi_c_g_s_t_a_b__step__by__step_8cpp_acb559820d9ca11295b4500f179ef6392}{i}}++)\ \{}
\DoxyCodeLine{\ \ callable(*\mbox{\hyperlink{_bi_c_g_s_t_a_b__step__by__step_8cpp_acb559820d9ca11295b4500f179ef6392}{i}});}
\DoxyCodeLine{\}}

\end{DoxyCode}


The two iterators, {\ttfamily first} and {\ttfamily last}, are typically two raw pointers to the first element and the next to the last element in the range in GPU memory space. The following example creates a {\ttfamily for\+\_\+each} kernel that assigns each element in {\ttfamily gpu\+\_\+data} to 1 over the range {\ttfamily \mbox{[}gpu\+\_\+data, gpu\+\_\+data + 1000)}.


\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{comment}{//\ assigns\ each\ element\ to\ 1\ over\ the\ range\ [gpu\_data,\ gpu\_data\ +\ 1000)}}
\DoxyCodeLine{cudaflow.for\_each(gpu\_data,\ gpu\_data\ +\ 1000,\ []\ \_\_device\_\_\ (\textcolor{keywordtype}{int}\&\ item)\ \{}
\DoxyCodeLine{\ \ item\ =\ 1;}
\DoxyCodeLine{\});\ }

\end{DoxyCode}


Each iteration is independent of each other and is assigned one kernel thread to run the callable. Since the callable runs on GPU, it must be declared with a {\ttfamily \+\_\+\+\_\+device\+\_\+\+\_\+} specifier.\hypertarget{_for_each_c_u_d_a_ForEachCUDAMiscellaneousItems}{}\doxysubsection{\texorpdfstring{Miscellaneous Items}{Miscellaneous Items}}\label{_for_each_c_u_d_a_ForEachCUDAMiscellaneousItems}
The parallel-\/iteration algorithms are also available in \doxylink{classtf_1_1cuda_flow_capturer_a0b2f1bcd59f0b42e0f823818348b4ae7}{tf\+::cuda\+Flow\+Capturer\+::for\+\_\+each} and \doxylink{classtf_1_1cuda_flow_capturer_aeb877f42ee3a627c40f1c9c84e31ba3c}{tf\+::cuda\+Flow\+Capturer\+::for\+\_\+each\+\_\+index}. 