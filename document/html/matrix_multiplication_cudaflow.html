<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="zh">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.13.2"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>source: Matrix Multiplication (cudaFlow)</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(function() { init_search(); });
/* @license-end */
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">source
   </div>
  </td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="搜索" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- 制作者 Doxygen 1.13.2 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('matrix_multiplication_cudaflow.html',''); initResizable(true); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">载入中...</div>
<div class="SRStatus" id="Searching">搜索中...</div>
<div class="SRStatus" id="NoMatches">未找到</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Matrix Multiplication (cudaFlow)</div></div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>目录</h3>
<ul>
  <li class="level1">
    <a href="#GPUAcceleratedMatrixMultiplication">Define a Matrix Multiplication Kernel</a>
  </li>
  <li class="level1">
    <a href="#DefineAcudaFlowForMatrixMultiplication">Define a cudaFlow for Matrix Multiplication</a>
  </li>
  <li class="level1">
    <a href="#MatrixMultiplicationcudaFlowBenchmarking">Benchmarking</a>
  </li>
</ul>
</div>
<div class="textblock"><p>Following up on <a class="el" href="matrix_multiplication.html">Matrix Multiplication</a>, this page studies how to accelerate a matrix multiplication workload on a GPU using <a class="el" href="classtf_1_1cuda_flow.html" title="class to create a cudaFlow task dependency graph">tf::cudaFlow</a>.</p>
<h1><a class="anchor" id="GPUAcceleratedMatrixMultiplication"></a>
Define a Matrix Multiplication Kernel</h1>
<p>GPU can perform a lot of parallel computations more than CPUs. It is especially useful for data-intensive computing such as matrix multiplication. With GPU, we express the parallel patterns at a fine-grained level. The kernel, written in CUDA, is described as follows:</p>
<div class="fragment"><div class="line"><span class="comment">// CUDA kernel to perform matrix multiplication</span></div>
<div class="line">__global__ <span class="keywordtype">void</span> matmul(<span class="keywordtype">int</span> *<a class="code hl_typedef" href="bench__gemm_8cpp.html#addc86e8508f14411ec98f521c520f875">A</a>, <span class="keywordtype">int</span> *<a class="code hl_typedef" href="bench__gemm_8cpp.html#a37a83060ac796961b44991c836f083f7">B</a>, <span class="keywordtype">int</span> *<a class="code hl_define" href="test__buffer__node_8cpp.html#ac4cf4b2ab929bd23951a8676eeac086b">C</a>, <span class="keywordtype">int</span> <a class="code hl_define" href="test__overwrite__node_8cpp.html#a52037c938e3c1b126c6277da5ca689d0">M</a>, <span class="keywordtype">int</span> K, <span class="keywordtype">int</span> <a class="code hl_define" href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a>) {</div>
<div class="line">  <span class="keywordtype">int</span> <a class="code hl_function" href="_matrix_base__row_8cpp.html#a64ef8efef59f875033a27e7cbbc879ec">row</a> = <a class="code hl_variable" href="cuda__common_8h.html#ab30e5f6958c9264d3c5235d463eb2b57">blockIdx</a>.y * <a class="code hl_variable" href="cuda__common_8h.html#a1a2cdcc50d7e1505a058c5832ebe5702">blockDim</a>.y + <a class="code hl_variable" href="cuda__common_8h.html#a0a680a9519f7aaccce02a4bb4c0a0b52">threadIdx</a>.y;</div>
<div class="line">  <span class="keywordtype">int</span> <a class="code hl_function" href="_matrix_base__col_8cpp.html#aa168d9544aa6d49fce0cbfc0bec849b0">col</a> = <a class="code hl_variable" href="cuda__common_8h.html#ab30e5f6958c9264d3c5235d463eb2b57">blockIdx</a>.x * <a class="code hl_variable" href="cuda__common_8h.html#a1a2cdcc50d7e1505a058c5832ebe5702">blockDim</a>.x + <a class="code hl_variable" href="cuda__common_8h.html#a0a680a9519f7aaccce02a4bb4c0a0b52">threadIdx</a>.x;</div>
<div class="line">  <span class="keywordtype">int</span> <a class="code hl_variable" href="test__parallel__for__each_8cpp.html#a539b07c7f86d3a9854ed81da50a4fb7d">sum</a> = 0;</div>
<div class="line">  <span class="keywordflow">if</span>(<a class="code hl_function" href="_matrix_base__col_8cpp.html#aa168d9544aa6d49fce0cbfc0bec849b0">col</a> &lt; <a class="code hl_define" href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a> &amp;&amp; <a class="code hl_function" href="_matrix_base__row_8cpp.html#a64ef8efef59f875033a27e7cbbc879ec">row</a> &lt; <a class="code hl_define" href="test__overwrite__node_8cpp.html#a52037c938e3c1b126c6277da5ca689d0">M</a>) {</div>
<div class="line">    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> <a class="code hl_variable" href="_bi_c_g_s_t_a_b__step__by__step_8cpp.html#acb559820d9ca11295b4500f179ef6392">i</a> = 0; <a class="code hl_variable" href="_bi_c_g_s_t_a_b__step__by__step_8cpp.html#acb559820d9ca11295b4500f179ef6392">i</a> &lt; K; <a class="code hl_variable" href="_bi_c_g_s_t_a_b__step__by__step_8cpp.html#acb559820d9ca11295b4500f179ef6392">i</a>++) {</div>
<div class="line">      <a class="code hl_variable" href="test__parallel__for__each_8cpp.html#a539b07c7f86d3a9854ed81da50a4fb7d">sum</a> += <a class="code hl_variable" href="_cwise__product_8cpp.html#ad2cbe4616e813eb9af81732dca777b24">a</a>[<a class="code hl_function" href="_matrix_base__row_8cpp.html#a64ef8efef59f875033a27e7cbbc879ec">row</a> * K + <a class="code hl_variable" href="_bi_c_g_s_t_a_b__step__by__step_8cpp.html#acb559820d9ca11295b4500f179ef6392">i</a>] * <a class="code hl_variable" href="offscreen_8c.html#a846c9667e34d56c560bb7f0ac6e173f6">b</a>[<a class="code hl_variable" href="_bi_c_g_s_t_a_b__step__by__step_8cpp.html#acb559820d9ca11295b4500f179ef6392">i</a> * <a class="code hl_define" href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a> + <a class="code hl_function" href="_matrix_base__col_8cpp.html#aa168d9544aa6d49fce0cbfc0bec849b0">col</a>];</div>
<div class="line">    }</div>
<div class="line">    <a class="code hl_variable" href="bench_vec_add_8cpp.html#a41689956983587b085f9da3e48f31d99">c</a>[<a class="code hl_function" href="_matrix_base__row_8cpp.html#a64ef8efef59f875033a27e7cbbc879ec">row</a> * <a class="code hl_define" href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a> + <a class="code hl_function" href="_matrix_base__col_8cpp.html#aa168d9544aa6d49fce0cbfc0bec849b0">col</a>] = <a class="code hl_variable" href="test__parallel__for__each_8cpp.html#a539b07c7f86d3a9854ed81da50a4fb7d">sum</a>;</div>
<div class="line">  }</div>
<div class="line">}</div>
<div class="ttc" id="a_bi_c_g_s_t_a_b__step__by__step_8cpp_html_acb559820d9ca11295b4500f179ef6392"><div class="ttname"><a href="_bi_c_g_s_t_a_b__step__by__step_8cpp.html#acb559820d9ca11295b4500f179ef6392">i</a></div><div class="ttdeci">int i</div><div class="ttdef"><b>定义</b> BiCGSTAB_step_by_step.cpp:9</div></div>
<div class="ttc" id="a_cwise__product_8cpp_html_ad2cbe4616e813eb9af81732dca777b24"><div class="ttname"><a href="_cwise__product_8cpp.html#ad2cbe4616e813eb9af81732dca777b24">a</a></div><div class="ttdeci">Array33i a</div><div class="ttdef"><b>定义</b> Cwise_product.cpp:1</div></div>
<div class="ttc" id="a_matrix_base__col_8cpp_html_aa168d9544aa6d49fce0cbfc0bec849b0"><div class="ttname"><a href="_matrix_base__col_8cpp.html#aa168d9544aa6d49fce0cbfc0bec849b0">col</a></div><div class="ttdeci">m col(1)</div></div>
<div class="ttc" id="a_matrix_base__row_8cpp_html_a64ef8efef59f875033a27e7cbbc879ec"><div class="ttname"><a href="_matrix_base__row_8cpp.html#a64ef8efef59f875033a27e7cbbc879ec">row</a></div><div class="ttdeci">m row(1)</div></div>
<div class="ttc" id="abench__gemm_8cpp_html_a37a83060ac796961b44991c836f083f7"><div class="ttname"><a href="bench__gemm_8cpp.html#a37a83060ac796961b44991c836f083f7">B</a></div><div class="ttdeci">Matrix&lt; SCALARB, Dynamic, Dynamic &gt; B</div><div class="ttdef"><b>定义</b> bench_gemm.cpp:36</div></div>
<div class="ttc" id="abench__gemm_8cpp_html_addc86e8508f14411ec98f521c520f875"><div class="ttname"><a href="bench__gemm_8cpp.html#addc86e8508f14411ec98f521c520f875">A</a></div><div class="ttdeci">Matrix&lt; SCALARA, Dynamic, Dynamic &gt; A</div><div class="ttdef"><b>定义</b> bench_gemm.cpp:35</div></div>
<div class="ttc" id="abench_vec_add_8cpp_html_a41689956983587b085f9da3e48f31d99"><div class="ttname"><a href="bench_vec_add_8cpp.html#a41689956983587b085f9da3e48f31d99">c</a></div><div class="ttdeci">Scalar Scalar * c</div><div class="ttdef"><b>定义</b> benchVecAdd.cpp:17</div></div>
<div class="ttc" id="acuda__common_8h_html_a0a680a9519f7aaccce02a4bb4c0a0b52"><div class="ttname"><a href="cuda__common_8h.html#a0a680a9519f7aaccce02a4bb4c0a0b52">threadIdx</a></div><div class="ttdeci">dim3 threadIdx</div><div class="ttdef"><b>定义</b> cuda_common.h:11</div></div>
<div class="ttc" id="acuda__common_8h_html_a1a2cdcc50d7e1505a058c5832ebe5702"><div class="ttname"><a href="cuda__common_8h.html#a1a2cdcc50d7e1505a058c5832ebe5702">blockDim</a></div><div class="ttdeci">dim3 blockDim</div><div class="ttdef"><b>定义</b> cuda_common.h:11</div></div>
<div class="ttc" id="acuda__common_8h_html_ab30e5f6958c9264d3c5235d463eb2b57"><div class="ttname"><a href="cuda__common_8h.html#ab30e5f6958c9264d3c5235d463eb2b57">blockIdx</a></div><div class="ttdeci">dim3 blockIdx</div><div class="ttdef"><b>定义</b> cuda_common.h:11</div></div>
<div class="ttc" id="amain-override-static_8c_html_a0240ac851181b84ac374872dc5434ee4"><div class="ttname"><a href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a></div><div class="ttdeci">#define N</div><div class="ttdef"><b>定义</b> main-override-static.c:141</div></div>
<div class="ttc" id="aoffscreen_8c_html_a846c9667e34d56c560bb7f0ac6e173f6"><div class="ttname"><a href="offscreen_8c.html#a846c9667e34d56c560bb7f0ac6e173f6">b</a></div><div class="ttdeci">float b</div><div class="ttdef"><b>定义</b> offscreen.c:42</div></div>
<div class="ttc" id="atest__buffer__node_8cpp_html_ac4cf4b2ab929bd23951a8676eeac086b"><div class="ttname"><a href="test__buffer__node_8cpp.html#ac4cf4b2ab929bd23951a8676eeac086b">C</a></div><div class="ttdeci">#define C</div><div class="ttdef"><b>定义</b> test_buffer_node.cpp:28</div></div>
<div class="ttc" id="atest__overwrite__node_8cpp_html_a52037c938e3c1b126c6277da5ca689d0"><div class="ttname"><a href="test__overwrite__node_8cpp.html#a52037c938e3c1b126c6277da5ca689d0">M</a></div><div class="ttdeci">#define M</div><div class="ttdef"><b>定义</b> test_overwrite_node.cpp:30</div></div>
<div class="ttc" id="atest__parallel__for__each_8cpp_html_a539b07c7f86d3a9854ed81da50a4fb7d"><div class="ttname"><a href="test__parallel__for__each_8cpp.html#a539b07c7f86d3a9854ed81da50a4fb7d">sum</a></div><div class="ttdeci">tbb::atomic&lt; size_t &gt; sum</div><div class="ttdef"><b>定义</b> test_parallel_for_each.cpp:32</div></div>
</div><!-- fragment --><p>Each CUDA thread corresponds to an element of <code>C</code> and compute its result. Instead of storing each matrix in a 2D array, we use 1D layout to ease the data transfer between CPU and GPU. In a row-major layout, an element <code>(x, y)</code> in the 2D matrix can be addressed at <code>x * width + y</code> in the transformed 1D layout.</p>
<div class="image">
<img src="images/matrix_multiplication_4.png" alt="" width="70%"/>
</div>
<h1><a class="anchor" id="DefineAcudaFlowForMatrixMultiplication"></a>
Define a cudaFlow for Matrix Multiplication</h1>
<p>The next step is to allocate memory for <code><a class="el" href="bench__gemm_8cpp.html#addc86e8508f14411ec98f521c520f875">A</a></code>, <code><a class="el" href="bench__gemm_8cpp.html#a37a83060ac796961b44991c836f083f7">B</a></code>, and <code>C</code> at a GPU. We create three tasks each calling <code>cudaMalloc</code> to allocate space for one matrix. Then, we create a cudaFlow to offload matrix multiplication to a GPU. The entire code is described as follows:</p>
<div class="fragment"><div class="line"><span class="keywordtype">void</span> <a class="code hl_function" href="external_2taskflow_2benchmarks_2matrix__multiplication_2main_8cpp.html#a3a744240c07a8320395e70bc269dba64">matrix_multiplication</a>(<span class="keywordtype">int</span>* <a class="code hl_typedef" href="bench__gemm_8cpp.html#addc86e8508f14411ec98f521c520f875">A</a>, <span class="keywordtype">int</span>* <a class="code hl_typedef" href="bench__gemm_8cpp.html#a37a83060ac796961b44991c836f083f7">B</a>, <span class="keywordtype">int</span>* <a class="code hl_define" href="test__buffer__node_8cpp.html#ac4cf4b2ab929bd23951a8676eeac086b">C</a>, <span class="keywordtype">int</span> <a class="code hl_define" href="test__overwrite__node_8cpp.html#a52037c938e3c1b126c6277da5ca689d0">M</a>, <span class="keywordtype">int</span> K, <span class="keywordtype">int</span> <a class="code hl_define" href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a>) {</div>
<div class="line">  </div>
<div class="line">  <a class="code hl_class" href="classtf_1_1_taskflow.html">tf::Taskflow</a> <a class="code hl_function" href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a>;</div>
<div class="line">  <a class="code hl_class" href="classtf_1_1_executor.html">tf::Executor</a> <a class="code hl_variable" href="thread__pool_8cpp.html#a543e564a8407bbeac15cb2d929fec755">executor</a>;</div>
<div class="line"> </div>
<div class="line">  <span class="comment">// allocate the host and gpu storage for A</span></div>
<div class="line">  <a class="code hl_class" href="classtf_1_1_task.html">tf::Task</a> allocate_a = <a class="code hl_function" href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a>.emplace([&amp;](){</div>
<div class="line">    cudaMalloc(&amp;da, <a class="code hl_define" href="test__overwrite__node_8cpp.html#a52037c938e3c1b126c6277da5ca689d0">M</a>*K*<span class="keyword">sizeof</span>(<span class="keywordtype">int</span>));</div>
<div class="line">  }).<a class="code hl_typedef" href="imgui__impl__opengl3__loader_8h.html#aab18cfce5ee7c6881ae04f18be70d94a">name</a>(<span class="stringliteral">&quot;allocate_a&quot;</span>);</div>
<div class="line">  </div>
<div class="line">  <span class="comment">// allocate the host and gpu storage for B</span></div>
<div class="line">  <a class="code hl_class" href="classtf_1_1_task.html">tf::Task</a> allocate_b = <a class="code hl_function" href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a>.emplace([&amp;](){</div>
<div class="line">    cudaMalloc(&amp;db, K*<a class="code hl_define" href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a>*<span class="keyword">sizeof</span>(<span class="keywordtype">int</span>));</div>
<div class="line">  }).<a class="code hl_typedef" href="imgui__impl__opengl3__loader_8h.html#aab18cfce5ee7c6881ae04f18be70d94a">name</a>(<span class="stringliteral">&quot;allocate_b&quot;</span>);</div>
<div class="line">  </div>
<div class="line">  <span class="comment">// allocate the host and gpu storage for C</span></div>
<div class="line">  <a class="code hl_class" href="classtf_1_1_task.html">tf::Task</a> allocate_c = <a class="code hl_function" href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a>.emplace([&amp;](){</div>
<div class="line">    cudaMalloc(&amp;dc, <a class="code hl_define" href="test__overwrite__node_8cpp.html#a52037c938e3c1b126c6277da5ca689d0">M</a>*<a class="code hl_define" href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a>*<span class="keyword">sizeof</span>(<span class="keywordtype">int</span>));</div>
<div class="line">  }).<a class="code hl_typedef" href="imgui__impl__opengl3__loader_8h.html#aab18cfce5ee7c6881ae04f18be70d94a">name</a>(<span class="stringliteral">&quot;allocate_c&quot;</span>);</div>
<div class="line">  </div>
<div class="line">  <span class="comment">// create a cudaFlow task to run the matrix multiplication</span></div>
<div class="line">  tf::Task <a class="code hl_class" href="classtf_1_1cuda_flow.html">cudaFlow</a> = <a class="code hl_function" href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a>.emplace([&amp;](){</div>
<div class="line"> </div>
<div class="line">    tf::cudaFlow cf;</div>
<div class="line">  </div>
<div class="line">    <span class="comment">// copy data to da, db, and dc</span></div>
<div class="line">    tf::cudaTask copy_da = cf.<a class="code hl_function" href="classtf_1_1cuda_graph_base.html#a02a041d5dd9e1e8958eb43e09331051e">copy</a>(da, <a class="code hl_typedef" href="bench__gemm_8cpp.html#addc86e8508f14411ec98f521c520f875">A</a>, <a class="code hl_define" href="test__overwrite__node_8cpp.html#a52037c938e3c1b126c6277da5ca689d0">M</a>*K).name(<span class="stringliteral">&quot;H2D_A&quot;</span>);</div>
<div class="line">    tf::cudaTask copy_db = cf.<a class="code hl_function" href="classtf_1_1cuda_graph_base.html#a02a041d5dd9e1e8958eb43e09331051e">copy</a>(db, <a class="code hl_typedef" href="bench__gemm_8cpp.html#a37a83060ac796961b44991c836f083f7">B</a>, K*<a class="code hl_define" href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a>).name(<span class="stringliteral">&quot;H2D_B&quot;</span>);</div>
<div class="line">    tf::cudaTask copy_hc = cf.<a class="code hl_function" href="classtf_1_1cuda_graph_base.html#a02a041d5dd9e1e8958eb43e09331051e">copy</a>(<a class="code hl_define" href="test__buffer__node_8cpp.html#ac4cf4b2ab929bd23951a8676eeac086b">C</a>, dc, <a class="code hl_define" href="test__overwrite__node_8cpp.html#a52037c938e3c1b126c6277da5ca689d0">M</a>*<a class="code hl_define" href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a>).name(<span class="stringliteral">&quot;D2H_C&quot;</span>);</div>
<div class="line">  </div>
<div class="line">    dim3 grid  ((K+16-1)/16, (<a class="code hl_define" href="test__overwrite__node_8cpp.html#a52037c938e3c1b126c6277da5ca689d0">M</a>+16-1)/16);</div>
<div class="line">    dim3 <a class="code hl_typedef" href="mimalloc_8h.html#af7f922b73e3acdb4a430b72f1a1334a5">block</a> (16, 16);</div>
<div class="line">  </div>
<div class="line">    tf::cudaTask kmatmul = cf.<a class="code hl_function" href="classtf_1_1cuda_graph_base.html#a1473a15a6023fbc25e1f029f2ff84aec">kernel</a>(grid, <a class="code hl_typedef" href="mimalloc_8h.html#af7f922b73e3acdb4a430b72f1a1334a5">block</a>, 0, matmul, da, db, dc, <a class="code hl_define" href="test__overwrite__node_8cpp.html#a52037c938e3c1b126c6277da5ca689d0">M</a>, K, <a class="code hl_define" href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a>)</div>
<div class="line">                             .name(<span class="stringliteral">&quot;matmul&quot;</span>);</div>
<div class="line">  </div>
<div class="line">    kmatmul.<a class="code hl_function" href="classtf_1_1cuda_task.html#a4a9ca1a34bac47e4c9b04eb4fb2f7775">succeed</a>(copy_da, copy_db)</div>
<div class="line">           .<a class="code hl_function" href="classtf_1_1cuda_task.html#abdd68287ec4dff4216af34d1db44d1b4">precede</a>(copy_hc);</div>
<div class="line"> </div>
<div class="line">    <span class="comment">// launch the cudaFlow</span></div>
<div class="line">    <a class="code hl_typedef" href="namespacetf.html#af19c9b301dc0b0fe2a51a960fa427e83">tf::cudaStream</a> stream;</div>
<div class="line">    cf.run(stream);</div>
<div class="line">    stream.<a class="code hl_function" href="classtf_1_1cuda_stream_base.html#a08857ff2874cd5378e578822e2e96dd0">synchronize</a>();</div>
<div class="line">  </div>
<div class="line">  }).<a class="code hl_typedef" href="imgui__impl__opengl3__loader_8h.html#aab18cfce5ee7c6881ae04f18be70d94a">name</a>(<span class="stringliteral">&quot;cudaFlow&quot;</span>);</div>
<div class="line">  </div>
<div class="line">  <span class="comment">// free the gpu storage</span></div>
<div class="line">  <span class="keyword">auto</span> <a class="code hl_define" href="mimalloc-override_8h.html#a9d4b5df3530d1bc733070a4669ba6ebc">free</a> = <a class="code hl_function" href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a>.emplace([&amp;](){</div>
<div class="line">    cudaFree(da);</div>
<div class="line">    cudaFree(db);</div>
<div class="line">    cudaFree(dc);</div>
<div class="line">  }).<a class="code hl_typedef" href="imgui__impl__opengl3__loader_8h.html#aab18cfce5ee7c6881ae04f18be70d94a">name</a>(<span class="stringliteral">&quot;free&quot;</span>);</div>
<div class="line">  </div>
<div class="line">  <span class="comment">// create dependency</span></div>
<div class="line">  <a class="code hl_class" href="classtf_1_1cuda_flow.html">cudaFlow</a>.succeed(allocate_a, allocate_b, allocate_c)</div>
<div class="line">          .precede(<a class="code hl_define" href="mimalloc-override_8h.html#a9d4b5df3530d1bc733070a4669ba6ebc">free</a>);</div>
<div class="line">  </div>
<div class="line">  <span class="comment">// dump the graph without unfolding the cudaFlow</span></div>
<div class="line">  <a class="code hl_function" href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a>.<a class="code hl_function" href="classtf_1_1cuda_graph_base.html#abd73a9268b80e74803f241ee10a842b6">dump</a>(std::cout);</div>
<div class="line"> </div>
<div class="line">  <span class="comment">// run the taskflow</span></div>
<div class="line">  <a class="code hl_variable" href="thread__pool_8cpp.html#a543e564a8407bbeac15cb2d929fec755">executor</a>.<a class="code hl_function" href="classtf_1_1_executor.html#a519777f5783981d534e9e53b99712069">run</a>(<a class="code hl_function" href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a>).wait();</div>
<div class="line"> </div>
<div class="line">  <span class="comment">// dump the entire execution graph including unfolded cudaFlow</span></div>
<div class="line">  <a class="code hl_function" href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a>.dump(std::cout);</div>
<div class="line">}</div>
<div class="ttc" id="aclasstf_1_1_executor_html"><div class="ttname"><a href="classtf_1_1_executor.html">tf::Executor</a></div><div class="ttdoc">class to create an executor for running a taskflow graph</div><div class="ttdef"><b>定义</b> executor-dl.hpp:51</div></div>
<div class="ttc" id="aclasstf_1_1_executor_html_a519777f5783981d534e9e53b99712069"><div class="ttname"><a href="classtf_1_1_executor.html#a519777f5783981d534e9e53b99712069">tf::Executor::run</a></div><div class="ttdeci">tf::Future&lt; void &gt; run(Taskflow &amp;taskflow)</div><div class="ttdoc">runs a taskflow once</div><div class="ttdef"><b>定义</b> executor-dl.hpp:2067</div></div>
<div class="ttc" id="aclasstf_1_1_task_html"><div class="ttname"><a href="classtf_1_1_task.html">tf::Task</a></div><div class="ttdoc">class to create a task handle over a node in a taskflow graph</div><div class="ttdef"><b>定义</b> task.hpp:150</div></div>
<div class="ttc" id="aclasstf_1_1_taskflow_html"><div class="ttname"><a href="classtf_1_1_taskflow.html">tf::Taskflow</a></div><div class="ttdoc">class to create a taskflow object</div><div class="ttdef"><b>定义</b> taskflow.hpp:67</div></div>
<div class="ttc" id="aclasstf_1_1cuda_flow_html"><div class="ttname"><a href="classtf_1_1cuda_flow.html">tf::cudaFlow</a></div><div class="ttdoc">class to create a cudaFlow task dependency graph</div><div class="ttdef"><b>定义</b> cudaflow.hpp:51</div></div>
<div class="ttc" id="aclasstf_1_1cuda_graph_base_html_a02a041d5dd9e1e8958eb43e09331051e"><div class="ttname"><a href="classtf_1_1cuda_graph_base.html#a02a041d5dd9e1e8958eb43e09331051e">tf::cudaGraphBase::copy</a></div><div class="ttdeci">cudaTask copy(T *tgt, const T *src, size_t num)</div><div class="ttdoc">creates a memcopy task that copies typed data</div><div class="ttdef"><b>定义</b> cuda_graph.hpp:896</div></div>
<div class="ttc" id="aclasstf_1_1cuda_graph_base_html_a1473a15a6023fbc25e1f029f2ff84aec"><div class="ttname"><a href="classtf_1_1cuda_graph_base.html#a1473a15a6023fbc25e1f029f2ff84aec">tf::cudaGraphBase::kernel</a></div><div class="ttdeci">cudaTask kernel(dim3 g, dim3 b, size_t s, F f, ArgsT... args)</div><div class="ttdoc">creates a kernel task</div><div class="ttdef"><b>定义</b> cuda_graph.hpp:831</div></div>
<div class="ttc" id="aclasstf_1_1cuda_graph_base_html_abd73a9268b80e74803f241ee10a842b6"><div class="ttname"><a href="classtf_1_1cuda_graph_base.html#abd73a9268b80e74803f241ee10a842b6">tf::cudaGraphBase::dump</a></div><div class="ttdeci">void dump(std::ostream &amp;os)</div><div class="ttdoc">dumps the CUDA graph to a DOT format through the given output stream</div><div class="ttdef"><b>定义</b> cuda_graph.hpp:776</div></div>
<div class="ttc" id="aclasstf_1_1cuda_stream_base_html_a08857ff2874cd5378e578822e2e96dd0"><div class="ttname"><a href="classtf_1_1cuda_stream_base.html#a08857ff2874cd5378e578822e2e96dd0">tf::cudaStreamBase::synchronize</a></div><div class="ttdeci">void synchronize() const</div><div class="ttdoc">synchronizes the associated stream</div><div class="ttdef"><b>定义</b> cuda_stream.hpp:212</div></div>
<div class="ttc" id="aclasstf_1_1cuda_task_html_a4a9ca1a34bac47e4c9b04eb4fb2f7775"><div class="ttname"><a href="classtf_1_1cuda_task.html#a4a9ca1a34bac47e4c9b04eb4fb2f7775">tf::cudaTask::succeed</a></div><div class="ttdeci">cudaTask &amp; succeed(Ts &amp;&amp;... tasks)</div><div class="ttdoc">adds precedence links from other tasks to this</div><div class="ttdef"><b>定义</b> cuda_graph.hpp:368</div></div>
<div class="ttc" id="aclasstf_1_1cuda_task_html_abdd68287ec4dff4216af34d1db44d1b4"><div class="ttname"><a href="classtf_1_1cuda_task.html#abdd68287ec4dff4216af34d1db44d1b4">tf::cudaTask::precede</a></div><div class="ttdeci">cudaTask &amp; precede(Ts &amp;&amp;... tasks)</div><div class="ttdoc">adds precedence links from this to other tasks</div><div class="ttdef"><b>定义</b> cuda_graph.hpp:357</div></div>
<div class="ttc" id="aexternal_2taskflow_2benchmarks_2matrix__multiplication_2main_8cpp_html_a3a744240c07a8320395e70bc269dba64"><div class="ttname"><a href="external_2taskflow_2benchmarks_2matrix__multiplication_2main_8cpp.html#a3a744240c07a8320395e70bc269dba64">matrix_multiplication</a></div><div class="ttdeci">void matrix_multiplication(const std::string &amp;model, const unsigned num_threads, const unsigned num_rounds)</div><div class="ttdef"><b>定义</b> main.cpp:7</div></div>
<div class="ttc" id="aimgui__impl__opengl3__loader_8h_html_aab18cfce5ee7c6881ae04f18be70d94a"><div class="ttname"><a href="imgui__impl__opengl3__loader_8h.html#aab18cfce5ee7c6881ae04f18be70d94a">name</a></div><div class="ttdeci">const GLchar * name</div><div class="ttdef"><b>定义</b> imgui_impl_opengl3_loader.h:312</div></div>
<div class="ttc" id="amimalloc-override_8h_html_a9d4b5df3530d1bc733070a4669ba6ebc"><div class="ttname"><a href="mimalloc-override_8h.html#a9d4b5df3530d1bc733070a4669ba6ebc">free</a></div><div class="ttdeci">#define free(p)</div><div class="ttdef"><b>定义</b> mimalloc-override.h:24</div></div>
<div class="ttc" id="amimalloc_8h_html_af7f922b73e3acdb4a430b72f1a1334a5"><div class="ttname"><a href="mimalloc_8h.html#af7f922b73e3acdb4a430b72f1a1334a5">block</a></div><div class="ttdeci">const mi_heap_area_t void * block</div><div class="ttdoc">This is the const version of block(Index,Index,Index,Index). *‍/</div><div class="ttdef"><b>定义</b> mimalloc.h:265</div></div>
<div class="ttc" id="anamespacetf_html_af19c9b301dc0b0fe2a51a960fa427e83"><div class="ttname"><a href="namespacetf.html#af19c9b301dc0b0fe2a51a960fa427e83">tf::cudaStream</a></div><div class="ttdeci">cudaStreamBase&lt; cudaStreamCreator, cudaStreamDeleter &gt; cudaStream</div><div class="ttdoc">default smart pointer type to manage a cudaStream_t object with unique ownership</div><div class="ttdef"><b>定义</b> cuda_stream.hpp:299</div></div>
<div class="ttc" id="apoisson_8hpp_html_aa56fe360bb0ae38e0082f49e394ff825"><div class="ttname"><a href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a></div><div class="ttdeci">void taskflow(int nx, int ny, double dx, double dy, double *f, int itold, int itnew, double *u, double *unew, int block_size, unsigned num_threads)</div><div class="ttdef"><b>定义</b> taskflow.cpp:6</div></div>
<div class="ttc" id="athread__pool_8cpp_html_a543e564a8407bbeac15cb2d929fec755"><div class="ttname"><a href="thread__pool_8cpp.html#a543e564a8407bbeac15cb2d929fec755">executor</a></div><div class="ttdeci">tf::Executor executor</div><div class="ttdef"><b>定义</b> thread_pool.cpp:6</div></div>
</div><!-- fragment --><p>Within the cudaFlow, we create two host-to-device (H2D) tasks that copy data from <code><a class="el" href="bench__gemm_8cpp.html#addc86e8508f14411ec98f521c520f875">A</a></code> and <code><a class="el" href="bench__gemm_8cpp.html#a37a83060ac796961b44991c836f083f7">B</a></code> to <code>da</code> and <code>db</code>, one device-to-host (D2H) task that copies the result from <code>dc</code> to <code>C</code>, and one kernel task that launches <code>matmul</code> on the GPU (by default, GPU 0). H2D tasks precede the kernel and the kernel precedes the D2H task. These GPU operations form a GPU task graph managed by a cudaFlow. The first dump of the taskflow gives the following graph:</p>
<p><a class="el" href="bench__gemm_8cpp.html#addc86e8508f14411ec98f521c520f875">A</a> cudaFlow encapsulates a GPU task dependency graph similar to a <a class="el" href="classtf_1_1_subflow.html" title="class to construct a subflow graph from the execution of a dynamic task">tf::Subflow</a> (see <a class="el" href="_subflow_tasking.html">Subflow Tasking</a>). In order to visualize it, we need to execute the graph first and then dump the taskflow.</p>
<h1><a class="anchor" id="MatrixMultiplicationcudaFlowBenchmarking"></a>
Benchmarking</h1>
<p>We run three versions of matrix multiplication, sequential CPU, parallel CPUs, and one GPU, on a machine of 12 Intel i7-8700 CPUs at 3.20 GHz and a Nvidia RTX 2080 GPU using various matrix sizes of <code><a class="el" href="bench__gemm_8cpp.html#addc86e8508f14411ec98f521c520f875">A</a></code>, <code><a class="el" href="bench__gemm_8cpp.html#a37a83060ac796961b44991c836f083f7">B</a></code>, and <code>C</code>.</p>
<div align="center"> <table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter"><a class="el" href="bench__gemm_8cpp.html#addc86e8508f14411ec98f521c520f875">A</a>   </th><th class="markdownTableHeadCenter"><a class="el" href="bench__gemm_8cpp.html#a37a83060ac796961b44991c836f083f7">B</a>   </th><th class="markdownTableHeadCenter">C   </th><th class="markdownTableHeadCenter">CPU Sequential   </th><th class="markdownTableHeadCenter">CPU Parallel   </th><th class="markdownTableHeadCenter">GPU Parallel    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">10x10   </td><td class="markdownTableBodyCenter">10x10   </td><td class="markdownTableBodyCenter">10x10   </td><td class="markdownTableBodyCenter">0.142 ms   </td><td class="markdownTableBodyCenter">0.414 ms   </td><td class="markdownTableBodyCenter">82 ms    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">100x100   </td><td class="markdownTableBodyCenter">100x100   </td><td class="markdownTableBodyCenter">100x100   </td><td class="markdownTableBodyCenter">1.641 ms   </td><td class="markdownTableBodyCenter">0.733 ms   </td><td class="markdownTableBodyCenter">83 ms    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">1000x1000   </td><td class="markdownTableBodyCenter">1000x1000   </td><td class="markdownTableBodyCenter">1000x1000   </td><td class="markdownTableBodyCenter">1532 ms   </td><td class="markdownTableBodyCenter">504 ms   </td><td class="markdownTableBodyCenter">85 ms    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">2000x2000   </td><td class="markdownTableBodyCenter">2000x2000   </td><td class="markdownTableBodyCenter">2000x2000   </td><td class="markdownTableBodyCenter">25688 ms   </td><td class="markdownTableBodyCenter">4387 ms   </td><td class="markdownTableBodyCenter">133 ms    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">3000x3000   </td><td class="markdownTableBodyCenter">3000x3000   </td><td class="markdownTableBodyCenter">3000x3000   </td><td class="markdownTableBodyCenter">104838 ms   </td><td class="markdownTableBodyCenter">16170 ms   </td><td class="markdownTableBodyCenter">214 ms    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">4000x4000   </td><td class="markdownTableBodyCenter">4000x4000   </td><td class="markdownTableBodyCenter">4000x4000   </td><td class="markdownTableBodyCenter">250133 ms   </td><td class="markdownTableBodyCenter">39646 ms   </td><td class="markdownTableBodyCenter">427 ms   </td></tr>
</table>
</div><p>As the matrix size increases, the speed-up of GPU over CPUs becomes prominent. For example, at <code>4000x4000</code>, the GPU runtime is 585.8 times faster than the sequential CPU runtime and is 92.8 times faster than the parallel CPU solutions. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">制作者 <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.13.2 </li>
  </ul>
</div>
</body>
</html>
