<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="zh">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.13.2"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>source: Linear Algebra with cuBLAS</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(function() { init_search(); });
/* @license-end */
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">source
   </div>
  </td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="搜索" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- 制作者 Doxygen 1.13.2 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('_linear_algebracublas_flow_capturer.html',''); initResizable(true); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">载入中...</div>
<div class="SRStatus" id="Searching">搜索中...</div>
<div class="SRStatus" id="NoMatches">未找到</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Linear Algebra with cuBLAS</div></div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>目录</h3>
<ul>
  <li class="level1">
    <a href="#WhatIsBLAS">What is BLAS?</a>
  </li>
  <li class="level1">
    <a href="#HowToUsecublasFlowCapturer">What is a cublasFlow Capturer? Why?</a>
  </li>
  <li class="level1">
    <a href="#DataModelOscublasFlowCapturer">Understand the Data Model</a>
    <ul>
      <li class="level2">
        <a href="#cublasFlowCapturerDataModelExample">Example: Transform Data Layout in Matrix Multiplication</a>
      </li>
    </ul>
  </li>
  <li class="level1">
    <a href="#cublasFlowCapturerLevel-1">Use Level-1 Methods</a>
  </li>
  <li class="level1">
    <a href="#cublasFlowCapturerLeve2-1">Use Level-2 Methods</a>
    <ul>
      <li class="level2">
        <a href="#cublasFlowCapturerLevel2Example">Example: Solve a Triangular Linear System</a>
      </li>
    </ul>
  </li>
  <li class="level1">
    <a href="#cublasFlowCapturerLevel-3">Use Level-3 Methods</a>
    <ul>
      <li class="level2">
        <a href="#cublasFlowCapturerLevel3Example">Example: Perform General Matrix-Matrix Multiplication</a>
      </li>
    </ul>
  </li>
  <li class="level1">
    <a href="#cublasFlowCapturerExtension">Include Other cuBLAS Methods</a>
  </li>
  <li class="level1">
    <a href="#cublasFlowCapturerKnowMore">Know More About cublasFlow Capturer</a>
  </li>
</ul>
</div>
<div class="textblock"><p>Taskflow provides a library <a class="el" href="classtf_1_1cublas_flow_capturer.html" title="class to construct a cuBLAS task graph">tf::cublasFlowCapturer</a> to program and accelerate <em>basic linear algebra subprograms</em> (BLAS) on top of @cuBLAS.</p>
<div class="image">
<img src="images/LinearAlgebra.png" alt="" width="50%"/>
</div>
<h1><a class="anchor" id="WhatIsBLAS"></a>
What is BLAS?</h1>
<p>The BLAS (Basic Linear Algebra Subprograms) are routines that provide standard building blocks for performing basic vector and matrix operations. There are three levels:</p>
<ol type="1">
<li>Level 1: performs scalar, vector, and vector-vector operations</li>
<li>Level 2: performs matrix-vector operations</li>
<li>Level 3: performs matrix-matrix operations</li>
</ol>
<p>BLAS is commonly used by linear algebra software. The @cuBLAS library is an implementation of BLAS (Basic Linear Algebra Subprograms) on top of the Nvidia CUDA runtime and it allows users to access the computational resources of Nvidia GPUs.</p>
<h1><a class="anchor" id="HowToUsecublasFlowCapturer"></a>
What is a cublasFlow Capturer? Why?</h1>
<p><a class="el" href="classtf_1_1cublas_flow_capturer.html" title="class to construct a cuBLAS task graph">tf::cublasFlowCapturer</a> provides an interface over native cuBLAS functions and allows users to express linear algebra algorithms using a <em>task graph model</em>. We transform the task graph into a CUDA graph using a stream capture algorithm optimized for maximum concurrency. When a cuBLAS program is transformed into a CUDA graph, we can launch the entire graph using a single kernel call. This organization minimizes kernels launch overhead and allows the CUDA runtime to optimize the whole workflow. The following example (<code>cublasflow.cu</code>) use <a class="el" href="classtf_1_1cublas_flow_capturer.html" title="class to construct a cuBLAS task graph">tf::cublasFlowCapturer</a> to perform a 2-norm operation on a vector.</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;taskflow/cublasflow.hpp&gt;</span></div>
<div class="line"> </div>
<div class="line"><span class="keywordtype">int</span> <a class="code hl_function" href="main-override-static_8c.html#ae66f6b31b5ad750f1fe042a706a4e3d4">main</a>() {</div>
<div class="line"> </div>
<div class="line">  <span class="keyword">const</span> <span class="keywordtype">int</span> <a class="code hl_define" href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a> = 1024;</div>
<div class="line">  </div>
<div class="line">  <a class="code hl_class" href="classtf_1_1_executor.html">tf::Executor</a> <a class="code hl_variable" href="thread__pool_8cpp.html#a543e564a8407bbeac15cb2d929fec755">executor</a>;</div>
<div class="line">  <a class="code hl_class" href="classtf_1_1_taskflow.html">tf::Taskflow</a> <a class="code hl_function" href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a>(<span class="stringliteral">&quot;cublas 2-norm&quot;</span>);  <span class="comment">// initialize an unit vector</span></div>
<div class="line">  </div>
<div class="line">  std::vector&lt;float&gt; hvec(<a class="code hl_define" href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a>, 1); </div>
<div class="line">  <span class="keywordtype">float</span>  hres;                                     <span class="comment">// cpu vector</span></div>
<div class="line">  <span class="keywordtype">float</span>* gvec = <a class="code hl_function" href="namespacetf.html#a2548e58af071bf1dbbbc945c84f237c9">tf::cuda_malloc_device&lt;float&gt;</a>(<a class="code hl_define" href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a>);  <span class="comment">// gpu vector</span></div>
<div class="line">  <span class="keywordtype">float</span>* gres = <a class="code hl_function" href="namespacetf.html#a2548e58af071bf1dbbbc945c84f237c9">tf::cuda_malloc_device&lt;float&gt;</a>(1);  <span class="comment">// gpu result</span></div>
<div class="line">  </div>
<div class="line">  <a class="code hl_function" href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a>.emplace([&amp;](<a class="code hl_class" href="classtf_1_1cuda_flow_capturer.html">tf::cudaFlowCapturer</a>&amp; capturer){</div>
<div class="line">    <span class="comment">// create a cuBLAS flow capturer</span></div>
<div class="line">    <span class="keyword">auto</span> blas = capturer.make_capturer&lt;<a class="code hl_class" href="classtf_1_1cublas_flow_capturer.html">tf::cublasFlowCapturer</a>&gt;();</div>
<div class="line">    </div>
<div class="line">    <a class="code hl_class" href="classtf_1_1cuda_task.html">tf::cudaTask</a> h2d = capturer.<a class="code hl_function" href="classtf_1_1cuda_flow_capturer.html#ab70f12050e78b588f5c23d874aa4e538">copy</a>(gvec, hvec.data(), <a class="code hl_define" href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a>).name(<span class="stringliteral">&quot;h2d&quot;</span>);</div>
<div class="line">    <a class="code hl_class" href="classtf_1_1cuda_task.html">tf::cudaTask</a> nrm = blas-&gt;nrm2(<a class="code hl_define" href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a>, gvec, 1, gres).name(<span class="stringliteral">&quot;2-norm&quot;</span>);</div>
<div class="line">    <a class="code hl_class" href="classtf_1_1cuda_task.html">tf::cudaTask</a> d2h = capturer.<a class="code hl_function" href="classtf_1_1cuda_flow_capturer.html#ab70f12050e78b588f5c23d874aa4e538">copy</a>(&amp;hres, gres, 1).name(<span class="stringliteral">&quot;d2h&quot;</span>);</div>
<div class="line">  </div>
<div class="line">    nrm.<a class="code hl_function" href="classtf_1_1cuda_task.html#abdd68287ec4dff4216af34d1db44d1b4">precede</a>(d2h)</div>
<div class="line">       .<a class="code hl_function" href="classtf_1_1cuda_task.html#a4a9ca1a34bac47e4c9b04eb4fb2f7775">succeed</a>(h2d);</div>
<div class="line">  }).<a class="code hl_typedef" href="imgui__impl__opengl3__loader_8h.html#aab18cfce5ee7c6881ae04f18be70d94a">name</a>(<span class="stringliteral">&quot;capturer&quot;</span>);</div>
<div class="line">  </div>
<div class="line">  <a class="code hl_variable" href="thread__pool_8cpp.html#a543e564a8407bbeac15cb2d929fec755">executor</a>.run(<a class="code hl_function" href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a>).wait();</div>
<div class="line">  </div>
<div class="line">  <a class="code hl_function" href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a>.dump(std::cout);</div>
<div class="line">  </div>
<div class="line">  assert(hres == 32);</div>
<div class="line">}</div>
<div class="ttc" id="aclasstf_1_1_executor_html"><div class="ttname"><a href="classtf_1_1_executor.html">tf::Executor</a></div><div class="ttdoc">class to create an executor for running a taskflow graph</div><div class="ttdef"><b>定义</b> executor-dl.hpp:51</div></div>
<div class="ttc" id="aclasstf_1_1_taskflow_html"><div class="ttname"><a href="classtf_1_1_taskflow.html">tf::Taskflow</a></div><div class="ttdoc">class to create a taskflow object</div><div class="ttdef"><b>定义</b> taskflow.hpp:67</div></div>
<div class="ttc" id="aclasstf_1_1cublas_flow_capturer_html"><div class="ttname"><a href="classtf_1_1cublas_flow_capturer.html">tf::cublasFlowCapturer</a></div><div class="ttdoc">class to construct a cuBLAS task graph</div><div class="ttdef"><b>定义</b> cublas_flow.hpp:73</div></div>
<div class="ttc" id="aclasstf_1_1cuda_flow_capturer_html"><div class="ttname"><a href="classtf_1_1cuda_flow_capturer.html">tf::cudaFlowCapturer</a></div><div class="ttdoc">class to create a cudaFlow graph using stream capture</div><div class="ttdef"><b>定义</b> cuda_capturer.hpp:57</div></div>
<div class="ttc" id="aclasstf_1_1cuda_flow_capturer_html_ab70f12050e78b588f5c23d874aa4e538"><div class="ttname"><a href="classtf_1_1cuda_flow_capturer.html#ab70f12050e78b588f5c23d874aa4e538">tf::cudaFlowCapturer::copy</a></div><div class="ttdeci">cudaTask copy(T *tgt, const T *src, size_t num)</div><div class="ttdoc">captures a copy task of typed data</div><div class="ttdef"><b>定义</b> cuda_capturer.hpp:575</div></div>
<div class="ttc" id="aclasstf_1_1cuda_task_html"><div class="ttname"><a href="classtf_1_1cuda_task.html">tf::cudaTask</a></div><div class="ttdoc">class to create a task handle of a CUDA Graph node</div><div class="ttdef"><b>定义</b> cuda_graph.hpp:265</div></div>
<div class="ttc" id="aclasstf_1_1cuda_task_html_a4a9ca1a34bac47e4c9b04eb4fb2f7775"><div class="ttname"><a href="classtf_1_1cuda_task.html#a4a9ca1a34bac47e4c9b04eb4fb2f7775">tf::cudaTask::succeed</a></div><div class="ttdeci">cudaTask &amp; succeed(Ts &amp;&amp;... tasks)</div><div class="ttdoc">adds precedence links from other tasks to this</div><div class="ttdef"><b>定义</b> cuda_graph.hpp:368</div></div>
<div class="ttc" id="aclasstf_1_1cuda_task_html_abdd68287ec4dff4216af34d1db44d1b4"><div class="ttname"><a href="classtf_1_1cuda_task.html#abdd68287ec4dff4216af34d1db44d1b4">tf::cudaTask::precede</a></div><div class="ttdeci">cudaTask &amp; precede(Ts &amp;&amp;... tasks)</div><div class="ttdoc">adds precedence links from this to other tasks</div><div class="ttdef"><b>定义</b> cuda_graph.hpp:357</div></div>
<div class="ttc" id="aimgui__impl__opengl3__loader_8h_html_aab18cfce5ee7c6881ae04f18be70d94a"><div class="ttname"><a href="imgui__impl__opengl3__loader_8h.html#aab18cfce5ee7c6881ae04f18be70d94a">name</a></div><div class="ttdeci">const GLchar * name</div><div class="ttdef"><b>定义</b> imgui_impl_opengl3_loader.h:312</div></div>
<div class="ttc" id="amain-override-static_8c_html_a0240ac851181b84ac374872dc5434ee4"><div class="ttname"><a href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a></div><div class="ttdeci">#define N</div><div class="ttdef"><b>定义</b> main-override-static.c:141</div></div>
<div class="ttc" id="amain-override-static_8c_html_ae66f6b31b5ad750f1fe042a706a4e3d4"><div class="ttname"><a href="main-override-static_8c.html#ae66f6b31b5ad750f1fe042a706a4e3d4">main</a></div><div class="ttdeci">int main()</div><div class="ttdef"><b>定义</b> main-override-static.c:32</div></div>
<div class="ttc" id="anamespacetf_html_a2548e58af071bf1dbbbc945c84f237c9"><div class="ttname"><a href="namespacetf.html#a2548e58af071bf1dbbbc945c84f237c9">tf::cuda_malloc_device</a></div><div class="ttdeci">T * cuda_malloc_device(size_t N, int d)</div><div class="ttdoc">allocates memory on the given device for holding N elements of type T</div><div class="ttdef"><b>定义</b> cuda_memory.hpp:48</div></div>
<div class="ttc" id="apoisson_8hpp_html_aa56fe360bb0ae38e0082f49e394ff825"><div class="ttname"><a href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a></div><div class="ttdeci">void taskflow(int nx, int ny, double dx, double dy, double *f, int itold, int itnew, double *u, double *unew, int block_size, unsigned num_threads)</div><div class="ttdef"><b>定义</b> taskflow.cpp:6</div></div>
<div class="ttc" id="athread__pool_8cpp_html_a543e564a8407bbeac15cb2d929fec755"><div class="ttname"><a href="thread__pool_8cpp.html#a543e564a8407bbeac15cb2d929fec755">executor</a></div><div class="ttdeci">tf::Executor executor</div><div class="ttdef"><b>定义</b> thread_pool.cpp:6</div></div>
</div><!-- fragment --><p>You need to link the <code>cublas</code> library when compiling a cublasFlow capturer program:</p>
<div class="fragment"><div class="line">{.shell-session} </div>
<div class="line">~$ nvcc cublasflow.cpp -I <a class="code hl_variable" href="ittnotify__static_8h.html#a7016119bc831a22d1a351d56128518ed">path</a>/to/<a class="code hl_function" href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a>/include -lcublas</div>
<div class="ttc" id="aittnotify__static_8h_html_a7016119bc831a22d1a351d56128518ed"><div class="ttname"><a href="ittnotify__static_8h.html#a7016119bc831a22d1a351d56128518ed">path</a></div><div class="ttdeci">void const char const char int ITT_FORMAT __itt_group_sync x void const char ITT_FORMAT __itt_group_sync s void ITT_FORMAT __itt_group_sync p void ITT_FORMAT p void ITT_FORMAT p no args __itt_suppress_mode_t unsigned int void size_t ITT_FORMAT d void ITT_FORMAT p void ITT_FORMAT p __itt_model_site __itt_model_site_instance ITT_FORMAT p __itt_model_task __itt_model_task_instance ITT_FORMAT p void ITT_FORMAT p void ITT_FORMAT p void size_t ITT_FORMAT d void ITT_FORMAT p const wchar_t ITT_FORMAT s const char ITT_FORMAT s const char ITT_FORMAT s const char ITT_FORMAT s no args void ITT_FORMAT p size_t ITT_FORMAT d no args const wchar_t const wchar_t ITT_FORMAT s __itt_heap_function void size_t int ITT_FORMAT d __itt_heap_function void ITT_FORMAT p __itt_heap_function void void size_t int ITT_FORMAT d no args no args unsigned int ITT_FORMAT u const __itt_domain __itt_id ITT_FORMAT lu const __itt_domain __itt_id __itt_id __itt_string_handle ITT_FORMAT p const __itt_domain __itt_id ITT_FORMAT p const __itt_domain __itt_id __itt_timestamp __itt_timestamp ITT_FORMAT lu const __itt_domain __itt_id __itt_id __itt_string_handle ITT_FORMAT p const __itt_domain ITT_FORMAT p const __itt_domain __itt_string_handle unsigned long long ITT_FORMAT lu const __itt_domain __itt_string_handle unsigned long long ITT_FORMAT lu const __itt_domain __itt_id __itt_string_handle __itt_metadata_type size_t void ITT_FORMAT p const __itt_domain __itt_id __itt_string_handle const wchar_t size_t ITT_FORMAT lu const __itt_domain __itt_id __itt_relation __itt_id ITT_FORMAT p const wchar_t int ITT_FORMAT __itt_group_mark d __itt_event ITT_FORMAT __itt_group_mark d void const wchar_t const wchar_t int ITT_FORMAT __itt_group_sync __itt_group_fsync x void const wchar_t int const wchar_t int int ITT_FORMAT __itt_group_sync __itt_group_fsync x void ITT_FORMAT __itt_group_sync __itt_group_fsync p void ITT_FORMAT __itt_group_sync __itt_group_fsync p void size_t ITT_FORMAT lu no args __itt_obj_prop_t __itt_obj_state_t ITT_FORMAT d const char ITT_FORMAT s const char ITT_FORMAT s __itt_frame ITT_FORMAT p __itt_counter ITT_FORMAT p __itt_counter unsigned long long ITT_FORMAT lu __itt_counter unsigned long long ITT_FORMAT lu __itt_counter __itt_clock_domain unsigned long long void ITT_FORMAT p const wchar_t ITT_FORMAT S __itt_mark_type const wchar_t ITT_FORMAT S __itt_mark_type const char ITT_FORMAT s __itt_mark_type ITT_FORMAT d __itt_caller ITT_FORMAT p __itt_caller ITT_FORMAT p no args const __itt_domain __itt_clock_domain unsigned long long __itt_id ITT_FORMAT lu const __itt_domain __itt_clock_domain unsigned long long __itt_id __itt_id void ITT_FORMAT p const __itt_domain __itt_id __itt_id __itt_string_handle ITT_FORMAT p const __itt_domain __itt_id ITT_FORMAT lu const __itt_domain __itt_clock_domain unsigned long long __itt_id __itt_string_handle __itt_scope ITT_FORMAT d const __itt_domain __itt_scope __itt_string_handle const char size_t ITT_FORMAT lu const __itt_domain __itt_clock_domain unsigned long long __itt_relation __itt_id ITT_FORMAT lu __itt_track_group __itt_string_handle __itt_track_group_type ITT_FORMAT d __itt_track ITT_FORMAT p void int const int int const char int ITT_FORMAT d void void const char * path</div><div class="ttdef"><b>定义</b> ittnotify_static.h:346</div></div>
</div><!-- fragment --><p>Please refer to the page <a class="el" href="_compile_taskflow_with_c_u_d_a.html">Compile Taskflow with CUDA</a> for more details about compiling Taskflow with CUDA.</p>
<h1><a class="anchor" id="DataModelOscublasFlowCapturer"></a>
Understand the Data Model</h1>
<p>The data pointers used within <a class="el" href="classtf_1_1cublas_flow_capturer.html" title="class to construct a cuBLAS task graph">tf::cublasFlowCapturer</a> must sit in GPU memory space, including scalar pointers (<code>alpha</code> and <code>beta</code>), input pointers (e.g., vectors, matrices), and output pointers (e.g., result). By default, we set the pointer mode to <code>CUBLAS_POINTER_MODE_DEVICE</code>. You must allocate required matrices and vectors in the GPU memory space, fill them with data, call the methods defined in <a class="el" href="classtf_1_1cublas_flow_capturer.html" title="class to construct a cuBLAS task graph">tf::cublasFlowCapturer</a>, and then upload the results from GPU memory space back to the host.</p>
<dl class="section note"><dt>注解</dt><dd><a class="el" href="classtf_1_1cublas_flow_capturer.html" title="class to construct a cuBLAS task graph">tf::cublasFlowCapturer</a> currently supports only <code>float</code> and <code>double</code> data types.</dd></dl>
<p>The cuBLAS library uses <em>column-major storage</em> and 1-based indexing. Since C/C++ adopts row-major layout, we cannot use the native array semantics when matrix-matrix or matrix-vector operations are involved. We often need extra transposition on input matrices before these operations can take place correctly. In terms of storage, a row-major matrix is equivalent to a transposed column-major matrix, as shown below:</p>
<p class="formulaDsp">
<picture><source srcset="form_284_dark.png" media="(prefers-color-scheme: dark)"/><img class="formulaDsp" alt="\[A_{RowMajor} \iff A^T_{ColumnMajor}
\]" src="form_284.png"/></picture>
</p>
<h2><a class="anchor" id="cublasFlowCapturerDataModelExample"></a>
Example: Transform Data Layout in Matrix Multiplication</h2>
<p>Suppose we have a method <code>matmul(A, B, C)</code> that multiplies two matrices <code><a class="el" href="bench__gemm_8cpp.html#addc86e8508f14411ec98f521c520f875">A</a></code> and <code><a class="el" href="bench__gemm_8cpp.html#a37a83060ac796961b44991c836f083f7">B</a></code> and stores the result in <code>C</code>, using column-major storage. In C/C++, data layout is mostly row-major. Since we know a row-major matrix is equivalent in storage to a transposed column-major matrix, we can take a transposed view of this multiplication:</p>
<p class="formulaDsp">
<picture><source srcset="form_285_dark.png" media="(prefers-color-scheme: dark)"/><img class="formulaDsp" alt="\[C^T = B^T \times A^T
\]" src="form_285.png"/></picture>
</p>
<p>If the given matrices <code><a class="el" href="bench__gemm_8cpp.html#addc86e8508f14411ec98f521c520f875">A</a></code>, <code><a class="el" href="bench__gemm_8cpp.html#a37a83060ac796961b44991c836f083f7">B</a></code>, and <code>C</code> are on row-major layout, calling <code>matmul(A, B, C)</code> is equivalent to the above transposed version. The function stores the result of transposed <code>C</code> in column-major storage which in turns translates to row-major layout of <code>C</code> &ndash; <em>our desired solution</em>.</p>
<h1><a class="anchor" id="cublasFlowCapturerLevel-1"></a>
Use Level-1 Methods</h1>
<p>We currently support the following level-1 methods:</p>
<ul>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#ab1357bb1728f5fe526acef8afee7111e" title="finds the smallest index of the element of the maximum absolute magnitude">tf::cublasFlowCapturer::amax</a> finds the min element index of the max absolute magnitude in a vector</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#a7a6485c37d50b9c79205f728ab380929" title="finds the smallest index of the element of the minimum absolute magnitude">tf::cublasFlowCapturer::amin</a> finds the min element index of the min magnitude in a vector</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#ab7672cee3d219ccc75c48b62cf1d1bad" title="finds the sum of absolute values of the elements over a vector">tf::cublasFlowCapturer::asum</a> computes the sum of absolute values of elements over a vector</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#a56f8649d43652597da1c9b0a5f88b0ee" title="multiples a vector by a scalar and adds it to a vector">tf::cublasFlowCapturer::axpy</a> multiplies a vector by a scalar and adds it to another vector</li>
<li>tf::cublasFlowCapturer::copy copies a vector into another vector</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#afdfa01d9f277051e44d7ed9663555b52" title="computes the dot product of two vectors">tf::cublasFlowCapturer::dot</a> computes the dot product of two vectors</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#a8000fc6dbbb6f6f5a033f1b365e80d38" title="computes the Euclidean norm of a vector">tf::cublasFlowCapturer::nrm2</a> computes the Euclidean norm of a vector</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#adb8f5d3137f5ccb3469a5bdde454a8bf" title="scales a vector by a scalar">tf::cublasFlowCapturer::scal</a> multiples a vector by a scalar</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#a32451b05fd7eb937ce8e807b5d5abe1f" title="swaps elements between two vectors">tf::cublasFlowCapturer::swap</a> interchanges the elements of two vectors</li>
</ul>
<p>Our level-1 methods capture the native <a href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-level-1-function-reference">cublas level-1 calls</a> with internal stream(s) optimized for maximum concurrency. The two scalars, <code>alpha</code> and <code>beta</code>, and input and output matrices must sit in GPU memory space.</p>
<h1><a class="anchor" id="cublasFlowCapturerLeve2-1"></a>
Use Level-2 Methods</h1>
<p>We currently support the following level-2 methods:</p>
<ul>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#a72185bf94321948b5b3657cc9c52ad0a" title="performs matrix-vector multiplication">tf::cublasFlowCapturer::gemv</a> performs general matrix-vector multiplication</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#a3a492f3f22949e0e6b1058113eb475d0" title="similar to tf::cublasFlowCapturer::gemv but operates on C-styled row-major layout">tf::cublasFlowCapturer::c_gemv</a> performs general matrix-vector multiplication on row-major layout</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#aed19fb69f2242f4ac6429f94d7776727" title="performs symmetric matrix-vector multiplication">tf::cublasFlowCapturer::symv</a> performs symmetric matrix-vector multiplication</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#a128ac1083f1dd05690998f5dac01959e" title="similar to tf::cublasFlowCapturer::symv but operates on C-styled row-major layout">tf::cublasFlowCapturer::c_symv</a> performs symmetric matrix-vector multiplication on row-major layout</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#a6765f845c7b95daefa197fdc2a1b426d" title="performs symmetric rank-1 update">tf::cublasFlowCapturer::syr</a> performs symmetric rank-1 update</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#afd79fe59e463b91feb2cbb94079c7c8c" title="similar to tf::cublasFlowCapturer::c_syr but operates on C-styled row-major layout">tf::cublasFlowCapturer::c_syr</a> performs symmetric rank-1 update on row-major layout</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#a46443a7e6c36f2a0d655041f6227b544" title="performs symmetric rank-2 update">tf::cublasFlowCapturer::syr2</a> performs symmetric rank-2 update</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#ac3ebc265f36b4c1205360a055f197873" title="similar to tf::cublasFlowCapturer::syr2 but operates on C-styled row-major layout">tf::cublasFlowCapturer::c_syr2</a> performs symmetric rank-2 update on row-major layout</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#af0ff6efaa01bffbd20d2760b6f82bcb1" title="performs the triangular matrix-vector multiplication">tf::cublasFlowCapturer::trmv</a> performs triangular matrix-vector multiplication</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#adb57fd25e55f0b4e2f4f0045a169f8d9" title="similar to tf::cublasFlowCapturer::trmv but operates on C-styled row-major layout">tf::cublasFlowCapturer::c_trmv</a> performs triangular matrix-vector multiplication on row-major layout</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#a5f10c25901bff8c626235dfdd6d10b57" title="solves the triangular linear system with a single right-hand-side">tf::cublasFlowCapturer::trsv</a> solves triangular linear system with a single right-hand-side</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#a27ae640e916e5f3d74886c57fe19342a" title="similar to tf::cublasFlowCapturer::trsv but operates on C-styled row-major layout">tf::cublasFlowCapturer::c_trsv</a> solves triangular linear system with a single right-hand-side on row-major layout</li>
</ul>
<p>Our level-2 methods capture the native <a href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-level-2-function-reference">cublas level-2 calls</a> with internal stream(s) optimized for maximum concurrency. The two scalars, <code>alpha</code> and <code>beta</code>, and input and output matrices must sit in GPU memory space.</p>
<h2><a class="anchor" id="cublasFlowCapturerLevel2Example"></a>
Example: Solve a Triangular Linear System</h2>
<p>The following program solves a triangular linear system on row-major layout using <a class="el" href="classtf_1_1cublas_flow_capturer.html#a27ae640e916e5f3d74886c57fe19342a" title="similar to tf::cublasFlowCapturer::trsv but operates on C-styled row-major layout">tf::cublasFlowCapturer::c_trsv</a>:</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;taskflow/cublasflow.hpp&gt;</span></div>
<div class="line"> </div>
<div class="line"><span class="keywordtype">int</span> <a class="code hl_function" href="main-override-static_8c.html#ae66f6b31b5ad750f1fe042a706a4e3d4">main</a>() {</div>
<div class="line"> </div>
<div class="line">  <span class="keywordtype">int</span> <a class="code hl_define" href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a> = 3;</div>
<div class="line"> </div>
<div class="line">  <span class="keyword">const</span> std::vector&lt;float&gt; hA = {</div>
<div class="line">    1, 0, 0,  <span class="comment">// x1</span></div>
<div class="line">    1, 1, 0,  <span class="comment">// x1 + x2</span></div>
<div class="line">    1, 1, 1   <span class="comment">// x1 + x2 + x3</span></div>
<div class="line">  };</div>
<div class="line"> </div>
<div class="line">  <span class="keyword">const</span> std::vector&lt;float&gt; hB = {</div>
<div class="line">    5,        <span class="comment">// x1           = 5</span></div>
<div class="line">    4,        <span class="comment">// x1 + x2      = 4</span></div>
<div class="line">    7         <span class="comment">// x1 + x2 + x3 = 7</span></div>
<div class="line">  };</div>
<div class="line"> </div>
<div class="line">  std::vector&lt;float&gt; <a class="code hl_variable" href="offscreen_8c.html#a4788d82c901b9367dd5c0daff8a7616b">r</a>(<a class="code hl_define" href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a>, 0);</div>
<div class="line"> </div>
<div class="line">  tf::Taskflow <a class="code hl_function" href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a>(<span class="stringliteral">&quot;Ax = b&quot;</span>);</div>
<div class="line">  tf::Executor <a class="code hl_variable" href="thread__pool_8cpp.html#a543e564a8407bbeac15cb2d929fec755">executor</a>;</div>
<div class="line"> </div>
<div class="line">  <span class="keywordtype">float</span>* dA = <a class="code hl_function" href="namespacetf.html#a2548e58af071bf1dbbbc945c84f237c9">tf::cuda_malloc_device&lt;float&gt;</a>(hA.size());</div>
<div class="line">  <span class="keywordtype">float</span>* dB = <a class="code hl_function" href="namespacetf.html#a2548e58af071bf1dbbbc945c84f237c9">tf::cuda_malloc_device&lt;float&gt;</a>(hB.size());</div>
<div class="line"> </div>
<div class="line">  <a class="code hl_function" href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a>.emplace([&amp;](tf::cudaFlowCapturer&amp; capturer){</div>
<div class="line">    tf::cudaTask blas = capturer.make_capturer&lt;tf::cublasFlowCapturer&gt;();</div>
<div class="line">    tf::cudaTask h2dA = blas-&gt;copy(dA, hA.data(), hA.size()).name(<span class="stringliteral">&quot;copy A&quot;</span>);</div>
<div class="line">    tf::cudaTask h2dB = blas-&gt;copy(dB, hB.data(), hB.size()).name(<span class="stringliteral">&quot;copy B&quot;</span>);</div>
<div class="line">    tf::cudaTask <a class="code hl_function" href="level2__impl_8h.html#a98a11637ad91cac0e2a6520b31f9d825">trsv</a> = blas-&gt;c_trsv(</div>
<div class="line">      CUBLAS_FILL_MODE_LOWER, CUBLAS_OP_N, CUBLAS_DIAG_UNIT, </div>
<div class="line">      <a class="code hl_define" href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a>, dA, <a class="code hl_define" href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a>, dB, 1</div>
<div class="line">    ).name(<span class="stringliteral">&quot;trsv&quot;</span>);</div>
<div class="line">    tf::cudaTask d2h = blas-&gt;copy(<a class="code hl_variable" href="offscreen_8c.html#a4788d82c901b9367dd5c0daff8a7616b">r</a>.data(), dB, <a class="code hl_variable" href="offscreen_8c.html#a4788d82c901b9367dd5c0daff8a7616b">r</a>.size()).name(<span class="stringliteral">&quot;copy result&quot;</span>);</div>
<div class="line"> </div>
<div class="line">    <a class="code hl_function" href="level2__impl_8h.html#a98a11637ad91cac0e2a6520b31f9d825">trsv</a>.<a class="code hl_function" href="classtf_1_1cuda_task.html#a4a9ca1a34bac47e4c9b04eb4fb2f7775">succeed</a>(h2dA, h2dB)</div>
<div class="line">        .<a class="code hl_function" href="classtf_1_1cuda_task.html#abdd68287ec4dff4216af34d1db44d1b4">precede</a>(d2h);</div>
<div class="line">  }).<a class="code hl_typedef" href="imgui__impl__opengl3__loader_8h.html#aab18cfce5ee7c6881ae04f18be70d94a">name</a>(<span class="stringliteral">&quot;cublasFlow&quot;</span>);</div>
<div class="line"> </div>
<div class="line">  <a class="code hl_variable" href="thread__pool_8cpp.html#a543e564a8407bbeac15cb2d929fec755">executor</a>.<a class="code hl_function" href="classtf_1_1_executor.html#a519777f5783981d534e9e53b99712069">run</a>(<a class="code hl_function" href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a>).wait();</div>
<div class="line">  </div>
<div class="line">  std::cout &lt;&lt; <span class="stringliteral">&quot;solution of the linear system: \n&quot;</span>;</div>
<div class="line">  <span class="keywordflow">for</span>(<span class="keywordtype">size_t</span> <a class="code hl_variable" href="_bi_c_g_s_t_a_b__step__by__step_8cpp.html#acb559820d9ca11295b4500f179ef6392">i</a>=0; <a class="code hl_variable" href="_bi_c_g_s_t_a_b__step__by__step_8cpp.html#acb559820d9ca11295b4500f179ef6392">i</a>&lt;<a class="code hl_variable" href="offscreen_8c.html#a4788d82c901b9367dd5c0daff8a7616b">r</a>.size(); ++<a class="code hl_variable" href="_bi_c_g_s_t_a_b__step__by__step_8cpp.html#acb559820d9ca11295b4500f179ef6392">i</a>) {</div>
<div class="line">    std::cout &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; <a class="code hl_variable" href="_bi_c_g_s_t_a_b__step__by__step_8cpp.html#acb559820d9ca11295b4500f179ef6392">i</a> &lt;&lt; <span class="stringliteral">&quot;: &quot;</span> &lt;&lt; <a class="code hl_variable" href="offscreen_8c.html#a4788d82c901b9367dd5c0daff8a7616b">r</a>[<a class="code hl_variable" href="_bi_c_g_s_t_a_b__step__by__step_8cpp.html#acb559820d9ca11295b4500f179ef6392">i</a>] &lt;&lt; <span class="charliteral">&#39;\n&#39;</span>;</div>
<div class="line">  }</div>
<div class="line"> </div>
<div class="line">  <span class="keywordflow">return</span> 0;</div>
<div class="line">}</div>
<div class="ttc" id="a_bi_c_g_s_t_a_b__step__by__step_8cpp_html_acb559820d9ca11295b4500f179ef6392"><div class="ttname"><a href="_bi_c_g_s_t_a_b__step__by__step_8cpp.html#acb559820d9ca11295b4500f179ef6392">i</a></div><div class="ttdeci">int i</div><div class="ttdef"><b>定义</b> BiCGSTAB_step_by_step.cpp:9</div></div>
<div class="ttc" id="aclasstf_1_1_executor_html_a519777f5783981d534e9e53b99712069"><div class="ttname"><a href="classtf_1_1_executor.html#a519777f5783981d534e9e53b99712069">tf::Executor::run</a></div><div class="ttdeci">tf::Future&lt; void &gt; run(Taskflow &amp;taskflow)</div><div class="ttdoc">runs a taskflow once</div><div class="ttdef"><b>定义</b> executor-dl.hpp:2067</div></div>
<div class="ttc" id="alevel2__impl_8h_html_a98a11637ad91cac0e2a6520b31f9d825"><div class="ttname"><a href="level2__impl_8h.html#a98a11637ad91cac0e2a6520b31f9d825">trsv</a></div><div class="ttdeci">int EIGEN_BLAS_FUNC trsv(const char *uplo, const char *opa, const char *diag, const int *n, const RealScalar *pa, const int *lda, RealScalar *pb, const int *incb)</div><div class="ttdef"><b>定义</b> level2_impl.h:86</div></div>
<div class="ttc" id="aoffscreen_8c_html_a4788d82c901b9367dd5c0daff8a7616b"><div class="ttname"><a href="offscreen_8c.html#a4788d82c901b9367dd5c0daff8a7616b">r</a></div><div class="ttdeci">float r</div><div class="ttdef"><b>定义</b> offscreen.c:42</div></div>
</div><!-- fragment --><p>The program uses one cudaFlow task that spawns a capturer of (1) two copy tasks, <code>h2dA</code> and <code>h2dB</code>, to copy the triangular matrix <code><a class="el" href="bench__gemm_8cpp.html#addc86e8508f14411ec98f521c520f875">A</a></code> and the solution vector <code>b</code>, (2) one kernel task <code>trsv</code> to solve the triangular linear system storing the result in <code>dB</code>, and (3) one copy task <code>d2h</code> to copy the solution in <code>dB</code> to <code>r</code>.</p>
<h1><a class="anchor" id="cublasFlowCapturerLevel-3"></a>
Use Level-3 Methods</h1>
<p>We currently support the following level-3 methods:</p>
<ul>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#a30b437e511b5719f6253d3a9cf0a992c" title="performs matrix-matrix addition and transposition">tf::cublasFlowCapturer::geam</a> performs matrix-matrix addition/transposition</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#a756dc6637521ef4f2249711effd1d0f5" title="similar to tf::cublasFlowCapturer::geam but on row-major layout">tf::cublasFlowCapturer::c_geam</a> performs matrix-matrix addition/transposition on row-major layout</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#a8adbe06476f146b27bb00ba6054e5879" title="performs matrix-matrix multiplication">tf::cublasFlowCapturer::gemm</a> performs general matrix-matrix multiplication</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#aecfd3b623b457d277dca40c2e1b3c1c0" title="similar to tf::cublasFlowCapturer::gemm but operates on C-styled row-major layout">tf::cublasFlowCapturer::c_gemm</a> performs general matrix-matrix multiplication on row-major layout</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#a56af0e8ed80e5626fe2f594608afa405" title="performs matrix-matrix multiplication over a batch of matrices">tf::cublasFlowCapturer::gemm_batched</a> performs batched general matrix-matrix multiplication</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#aa9415957e3e48df65dc3baad86d05b38" title="similar to tf::cublasFlowCapturer::gemm_batched but operates on C-styled row-major layout">tf::cublasFlowCapturer::c_gemm_batched</a> performs batched general matrix-matrix multiplication on row-major layout</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#a36ecdcea0f24575187e44374e583df2e" title="performs matrix-matrix multiplication over a batch of matrices with strided memory access">tf::cublasFlowCapturer::gemm_sbatched</a> performs batched general matrix-matrix multiplication with strided memory access</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#ae57c53a1a07c0b4f73d90bf21fee4e1c" title="similar to tf::cublasFlowCapturer::c_gemm_sbatched but operates on C-styled row-major layout">tf::cublasFlowCapturer::c_gemm_sbatched</a> performs batched general matrix-matrix multiplication with strided memory access on row-major layout</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#a9d0eb2c37b48120bd40b1f725b507c42" title="performs the symmetric matrix-matrix multiplication">tf::cublasFlowCapturer::symm</a> performs symmetric matrix-matrix multiplication</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#a23a4636954cfdb34835b0d7a275fe4a8" title="similar to tf::cublasFlowCapturer::symm but operates on C-styled row-major layout">tf::cublasFlowCapturer::c_symm</a> performs symmetric matrix-matrix multiplication on row-major layout</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#aade5e9a358b7f4195367ef460921a236" title="performs the symmetric rank-k update">tf::cublasFlowCapturer::syrk</a> performs symmetric rank-k update</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#af9b146e7a3d4afb6658fa5fd8a860527" title="similar to tf::cublasFlowCapturer::c_syrk but operates on C-styled row-major layout">tf::cublasFlowCapturer::c_syrk</a> performs symmetric rank-k update on row-major layout</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#a45f110bd529b49531e3c83458a8990ac" title="performs the symmetric rank-2k update">tf::cublasFlowCapturer::syr2k</a> performs symmetric rank-2k update</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#ab2f1c253b6808ac011b7ea9d2fc82e58" title="similar to tf::cublasFlowCapturer::syr2k but operates on C-styled row-major layout">tf::cublasFlowCapturer::c_syr2k</a> performs symmetric rank-2k update on row-major layout</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#af5461904ac5714c5cc7eb7bbd8e2883e" title="performs a variation of the symmetric rank-k update">tf::cublasFlowCapturer::syrkx</a> performs a variation of symmetric rank-k update</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#a18ef82f489aaaa80d3d3c7cde6750729" title="similar to tf::cublasFlowCapturer::syrkx but operates on C-styled row-major layout">tf::cublasFlowCapturer::c_syrkx</a> performs a variation of symmetric rank-k update on row-major layout</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#a11e49f148b84ebc95ddeb5f4c3af78d8" title="performs triangular matrix-matrix multiplication">tf::cublasFlowCapturer::trmm</a> performs triangular matrix-matrix multiplication</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#ad9118a1eff03514a0c9f75e21e76fe35" title="similar to tf::cublasFlowCapturer::trmm but oeprates on C-styled row-major layout">tf::cublasFlowCapturer::c_trmm</a> performs triangular matrix-matrix multiplication on row-major layout</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#aa8cc2fcfeb3ffbc1146dda358b2b8188" title="solves the triangular linear system with multiple right-hand-sides">tf::cublasFlowCapturer::trsm</a> solves a triangular linear system with multiple right-hand-sides</li>
<li><a class="el" href="classtf_1_1cublas_flow_capturer.html#a7a0282cc21707315d347b5e4d8d3f25e" title="similar to tf::cublasFlowCapturer::trsm but operates on C-styled row-major layout">tf::cublasFlowCapturer::c_trsm</a> solves a triangular linear system with multiple right-hand-sides on row-major layout</li>
</ul>
<p>Our level-3 methods capture the native <a href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-level-2-function-reference">cublas level-3 calls</a> and <a href="https://docs.nvidia.com/cuda/cublas/index.html#blas-like-extension">cublas-extension calls</a> with internal stream(s) optimized for maximum concurrency. The two scalars, <code>alpha</code> and <code>beta</code>, and input and output matrices must sit in GPU memory space.</p>
<h2><a class="anchor" id="cublasFlowCapturerLevel3Example"></a>
Example: Perform General Matrix-Matrix Multiplication</h2>
<p>The following program performs general matrix multiplication on row-major layout using <a class="el" href="classtf_1_1cublas_flow_capturer.html#aecfd3b623b457d277dca40c2e1b3c1c0" title="similar to tf::cublasFlowCapturer::gemm but operates on C-styled row-major layout">tf::cublasFlowCapturer::c_gemm</a>:</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;taskflow/cublasflow.hpp&gt;</span></div>
<div class="line"> </div>
<div class="line"><span class="keywordtype">int</span> <a class="code hl_function" href="main-override-static_8c.html#ae66f6b31b5ad750f1fe042a706a4e3d4">main</a>() {</div>
<div class="line"> </div>
<div class="line">  <span class="keyword">const</span> <span class="keywordtype">int</span> <a class="code hl_define" href="test__overwrite__node_8cpp.html#a52037c938e3c1b126c6277da5ca689d0">M</a> = 2, <a class="code hl_define" href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a> = 4, K = 3;</div>
<div class="line"> </div>
<div class="line">  <span class="keyword">const</span> std::vector&lt;float&gt; hA = {      <span class="comment">// M x K matrix</span></div>
<div class="line">    11, 12, 13, </div>
<div class="line">    14, 15, 16</div>
<div class="line">  };</div>
<div class="line"> </div>
<div class="line">  <span class="keyword">const</span> std::vector&lt;float&gt; hB = {      <span class="comment">// K x N matrix</span></div>
<div class="line">    11, 12, 13, 14,</div>
<div class="line">    15, 16, 17, 18,</div>
<div class="line">    19, 20, 21, 22</div>
<div class="line">  };</div>
<div class="line"> </div>
<div class="line">  <span class="keyword">const</span> std::vector&lt;float&gt; golden = {  <span class="comment">// M x N matrix</span></div>
<div class="line">    548, 584, 620, 656,</div>
<div class="line">    683, 728, 773, 818 </div>
<div class="line">  };</div>
<div class="line"> </div>
<div class="line">  std::vector&lt;float&gt; hC(<a class="code hl_define" href="test__overwrite__node_8cpp.html#a52037c938e3c1b126c6277da5ca689d0">M</a>*<a class="code hl_define" href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a>);</div>
<div class="line">    </div>
<div class="line">  <span class="keywordtype">float</span> *dA, *dB, *dC, *dAlpha, *dBeta;</div>
<div class="line"> </div>
<div class="line">  tf::Taskflow <a class="code hl_function" href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a>(<span class="stringliteral">&quot;Matrix Multiplication&quot;</span>);</div>
<div class="line">  tf::Executor <a class="code hl_variable" href="thread__pool_8cpp.html#a543e564a8407bbeac15cb2d929fec755">executor</a>;</div>
<div class="line"> </div>
<div class="line">  tf::Task malloc_dA = <a class="code hl_function" href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a>.emplace(</div>
<div class="line">    [&amp;](){ dA = <a class="code hl_function" href="namespacetf.html#a2548e58af071bf1dbbbc945c84f237c9">tf::cuda_malloc_device&lt;float&gt;</a>(hA.size()); }</div>
<div class="line">  ).<a class="code hl_typedef" href="imgui__impl__opengl3__loader_8h.html#aab18cfce5ee7c6881ae04f18be70d94a">name</a>(<span class="stringliteral">&quot;malloc_dA&quot;</span>);      <span class="comment">// allocate GPU memory for dA</span></div>
<div class="line">  </div>
<div class="line">  tf::Task malloc_dB = <a class="code hl_function" href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a>.emplace(</div>
<div class="line">    [&amp;](){ dB = <a class="code hl_function" href="namespacetf.html#a2548e58af071bf1dbbbc945c84f237c9">tf::cuda_malloc_device&lt;float&gt;</a>(hB.size()); }</div>
<div class="line">  ).<a class="code hl_typedef" href="imgui__impl__opengl3__loader_8h.html#aab18cfce5ee7c6881ae04f18be70d94a">name</a>(<span class="stringliteral">&quot;malloc_dB&quot;</span>);      <span class="comment">// allocate GPU memory for dB</span></div>
<div class="line">  </div>
<div class="line">  tf::Task malloc_dC = <a class="code hl_function" href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a>.emplace(</div>
<div class="line">    [&amp;](){ dC = <a class="code hl_function" href="namespacetf.html#a2548e58af071bf1dbbbc945c84f237c9">tf::cuda_malloc_device&lt;float&gt;</a>(hC.size()); }</div>
<div class="line">  ).<a class="code hl_typedef" href="imgui__impl__opengl3__loader_8h.html#aab18cfce5ee7c6881ae04f18be70d94a">name</a>(<span class="stringliteral">&quot;malloc_dC&quot;</span>);      <span class="comment">// allocate GPU memory for dC</span></div>
<div class="line">  </div>
<div class="line">  tf::Task malloc_dAlpha = <a class="code hl_function" href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a>.emplace(</div>
<div class="line">    [&amp;](){ dAlpha = <a class="code hl_function" href="namespacetf.html#a2548e58af071bf1dbbbc945c84f237c9">tf::cuda_malloc_device&lt;float&gt;</a>(1); }</div>
<div class="line">  ).<a class="code hl_typedef" href="imgui__impl__opengl3__loader_8h.html#aab18cfce5ee7c6881ae04f18be70d94a">name</a>(<span class="stringliteral">&quot;malloc_dAlpha&quot;</span>);  <span class="comment">// allocate GPU memory for scalar alpha</span></div>
<div class="line">  </div>
<div class="line">  tf::Task malloc_dBeta = <a class="code hl_function" href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a>.emplace(</div>
<div class="line">    [&amp;](){ dBeta = <a class="code hl_function" href="namespacetf.html#a2548e58af071bf1dbbbc945c84f237c9">tf::cuda_malloc_device&lt;float&gt;</a>(1); }</div>
<div class="line">  ).<a class="code hl_typedef" href="imgui__impl__opengl3__loader_8h.html#aab18cfce5ee7c6881ae04f18be70d94a">name</a>(<span class="stringliteral">&quot;malloc_dBeta&quot;</span>);   <span class="comment">// allocate GPU memory for scalar beta</span></div>
<div class="line"> </div>
<div class="line">  tf::Task cublasFlow = <a class="code hl_function" href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a>.emplace([&amp;](tf::cudaFlowCapturer&amp; capturer) {</div>
<div class="line">    tf::cudaTask blas  = capturer.make_capturer&lt;tf::cublasFlowCapturer&gt;();</div>
<div class="line">    tf::cudaTask <a class="code hl_typedef" href="imgui__impl__opengl3__loader_8h.html#a090ebe65994a3ee4bb60ae3472abffc5">alpha</a> = blas-&gt;single_task([=] __device__ () { *dAlpha = 1; })</div>
<div class="line">                              .<a class="code hl_typedef" href="imgui__impl__opengl3__loader_8h.html#aab18cfce5ee7c6881ae04f18be70d94a">name</a>(<span class="stringliteral">&quot;alpha=1&quot;</span>);</div>
<div class="line">    tf::cudaTask <a class="code hl_variable" href="wave_8c.html#aabc9b3ee8fafa62b353f3956f8e3c269">beta</a>  = blas-&gt;single_task([=] __device__ () { *dBeta  = 0; })</div>
<div class="line">                              .<a class="code hl_typedef" href="imgui__impl__opengl3__loader_8h.html#aab18cfce5ee7c6881ae04f18be70d94a">name</a>(<span class="stringliteral">&quot;beta=0&quot;</span>);</div>
<div class="line">    tf::cudaTask copyA = blas-&gt;copy(dA, hA.data(), hA.size()).name(<span class="stringliteral">&quot;copyA&quot;</span>); </div>
<div class="line">    tf::cudaTask copyB = blas-&gt;copy(dB, hB.data(), hB.size()).name(<span class="stringliteral">&quot;copyB&quot;</span>);</div>
<div class="line">    tf::cudaTask <a class="code hl_function" href="bench__gemm_8cpp.html#a4e3341ba4cc101e5c46e8d6f201b21f9">gemm</a>  = blas-&gt;c_gemm(CUBLAS_OP_N, CUBLAS_OP_N,</div>
<div class="line">      <a class="code hl_define" href="test__overwrite__node_8cpp.html#a52037c938e3c1b126c6277da5ca689d0">M</a>, <a class="code hl_define" href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a>, K, dAlpha, dA, K, dB, <a class="code hl_define" href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a>, dBeta, dC, <a class="code hl_define" href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a></div>
<div class="line">    ).name(<span class="stringliteral">&quot;C = alpha * A * B + beta * C&quot;</span>);</div>
<div class="line">    tf::cudaTask copyC = blas-&gt;copy(hC.data(), dC, hC.size()).name(<span class="stringliteral">&quot;copyC&quot;</span>);</div>
<div class="line"> </div>
<div class="line">    <a class="code hl_function" href="bench__gemm_8cpp.html#a4e3341ba4cc101e5c46e8d6f201b21f9">gemm</a>.<a class="code hl_function" href="classtf_1_1cuda_task.html#a4a9ca1a34bac47e4c9b04eb4fb2f7775">succeed</a>(<a class="code hl_typedef" href="imgui__impl__opengl3__loader_8h.html#a090ebe65994a3ee4bb60ae3472abffc5">alpha</a>, <a class="code hl_variable" href="wave_8c.html#aabc9b3ee8fafa62b353f3956f8e3c269">beta</a>, copyA, copyB)</div>
<div class="line">        .<a class="code hl_function" href="classtf_1_1cuda_task.html#abdd68287ec4dff4216af34d1db44d1b4">precede</a>(copyC);</div>
<div class="line">  }).<a class="code hl_typedef" href="imgui__impl__opengl3__loader_8h.html#aab18cfce5ee7c6881ae04f18be70d94a">name</a>(<span class="stringliteral">&quot;cublasFlow&quot;</span>);</div>
<div class="line"> </div>
<div class="line">  cublasFlow.<a class="code hl_function" href="classtf_1_1_task.html#a331b1b726555072e7c7d10941257f664">succeed</a>(  <span class="comment">// cublasFlow runs after GPU memory operations</span></div>
<div class="line">    malloc_dA, malloc_dB, malloc_dC, malloc_dAlpha, malloc_dBeta</div>
<div class="line">  );</div>
<div class="line"> </div>
<div class="line">  <a class="code hl_variable" href="thread__pool_8cpp.html#a543e564a8407bbeac15cb2d929fec755">executor</a>.<a class="code hl_function" href="classtf_1_1_executor.html#a519777f5783981d534e9e53b99712069">run</a>(<a class="code hl_function" href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a>).wait();</div>
<div class="line">  </div>
<div class="line">  std::cout &lt;&lt; <span class="stringliteral">&quot;Matrix C:\n&quot;</span>;</div>
<div class="line">  <span class="keywordflow">for</span>(<span class="keywordtype">int</span> <a class="code hl_variable" href="_angle_axis__mimic__euler_8cpp.html#ab3cd915d758008bd19d0f2428fbb354a">m</a>=0; <a class="code hl_variable" href="_angle_axis__mimic__euler_8cpp.html#ab3cd915d758008bd19d0f2428fbb354a">m</a>&lt;<a class="code hl_define" href="test__overwrite__node_8cpp.html#a52037c938e3c1b126c6277da5ca689d0">M</a>; <a class="code hl_variable" href="_angle_axis__mimic__euler_8cpp.html#ab3cd915d758008bd19d0f2428fbb354a">m</a>++) {</div>
<div class="line">    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> <a class="code hl_variable" href="_bi_c_g_s_t_a_b__simple_8cpp.html#a5150192f625f4d7970d61169b9567f39">n</a>=0; <a class="code hl_variable" href="_bi_c_g_s_t_a_b__simple_8cpp.html#a5150192f625f4d7970d61169b9567f39">n</a>&lt;<a class="code hl_define" href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a>; <a class="code hl_variable" href="_bi_c_g_s_t_a_b__simple_8cpp.html#a5150192f625f4d7970d61169b9567f39">n</a>++) {</div>
<div class="line">      std::cout &lt;&lt; hC[<a class="code hl_variable" href="_angle_axis__mimic__euler_8cpp.html#ab3cd915d758008bd19d0f2428fbb354a">m</a>*<a class="code hl_define" href="main-override-static_8c.html#a0240ac851181b84ac374872dc5434ee4">N</a>+<a class="code hl_variable" href="_bi_c_g_s_t_a_b__simple_8cpp.html#a5150192f625f4d7970d61169b9567f39">n</a>] &lt;&lt; <span class="charliteral">&#39; &#39;</span>;</div>
<div class="line">    }</div>
<div class="line">    std::cout &lt;&lt; <span class="charliteral">&#39;\n&#39;</span>;</div>
<div class="line">  }</div>
<div class="line"> </div>
<div class="line">  <span class="keywordflow">return</span> 0;</div>
<div class="line">}</div>
<div class="ttc" id="a_angle_axis__mimic__euler_8cpp_html_ab3cd915d758008bd19d0f2428fbb354a"><div class="ttname"><a href="_angle_axis__mimic__euler_8cpp.html#ab3cd915d758008bd19d0f2428fbb354a">m</a></div><div class="ttdeci">Matrix3f m</div><div class="ttdef"><b>定义</b> AngleAxis_mimic_euler.cpp:1</div></div>
<div class="ttc" id="a_bi_c_g_s_t_a_b__simple_8cpp_html_a5150192f625f4d7970d61169b9567f39"><div class="ttname"><a href="_bi_c_g_s_t_a_b__simple_8cpp.html#a5150192f625f4d7970d61169b9567f39">n</a></div><div class="ttdeci">int n</div><div class="ttdef"><b>定义</b> BiCGSTAB_simple.cpp:1</div></div>
<div class="ttc" id="abench__gemm_8cpp_html_a4e3341ba4cc101e5c46e8d6f201b21f9"><div class="ttname"><a href="bench__gemm_8cpp.html#a4e3341ba4cc101e5c46e8d6f201b21f9">gemm</a></div><div class="ttdeci">EIGEN_DONT_INLINE void gemm(const A &amp;a, const B &amp;b, C &amp;c)</div><div class="ttdef"><b>定义</b> bench_gemm.cpp:130</div></div>
<div class="ttc" id="aclasstf_1_1_task_html_a331b1b726555072e7c7d10941257f664"><div class="ttname"><a href="classtf_1_1_task.html#a331b1b726555072e7c7d10941257f664">tf::Task::succeed</a></div><div class="ttdeci">Task &amp; succeed(Ts &amp;&amp;... tasks)</div><div class="ttdoc">adds precedence links from other tasks to this</div><div class="ttdef"><b>定义</b> task.hpp:402</div></div>
<div class="ttc" id="aimgui__impl__opengl3__loader_8h_html_a090ebe65994a3ee4bb60ae3472abffc5"><div class="ttname"><a href="imgui__impl__opengl3__loader_8h.html#a090ebe65994a3ee4bb60ae3472abffc5">alpha</a></div><div class="ttdeci">GLfloat GLfloat GLfloat alpha</div><div class="ttdef"><b>定义</b> imgui_impl_opengl3_loader.h:192</div></div>
<div class="ttc" id="atest__overwrite__node_8cpp_html_a52037c938e3c1b126c6277da5ca689d0"><div class="ttname"><a href="test__overwrite__node_8cpp.html#a52037c938e3c1b126c6277da5ca689d0">M</a></div><div class="ttdeci">#define M</div><div class="ttdef"><b>定义</b> test_overwrite_node.cpp:30</div></div>
<div class="ttc" id="awave_8c_html_aabc9b3ee8fafa62b353f3956f8e3c269"><div class="ttname"><a href="wave_8c.html#aabc9b3ee8fafa62b353f3956f8e3c269">beta</a></div><div class="ttdeci">GLfloat beta</div><div class="ttdef"><b>定义</b> wave.c:33</div></div>
</div><!-- fragment --><p>The program uses five static tasks to allocate GPU memory for <code>dA</code>, <code>dB</code>, <code>dC</code>, <code>dAlpha</code>, and <code>dBeta</code>, in parallel such that the expensive GPU memory operations can overlap with each other as much as possible. The <code>cublasFlow</code> task spawns a cublasFlow capturer of (1) one single kernel task <code>alpha</code> to set <code>dAlpha</code> to 1, (2) one single kernel task <code>beta</code> to set <code>dBeta</code> to 0, (3) two copy tasks, <code>copyA</code> and <code>copyB</code>, to copy data from CPU to GPU, (4) one kernel task <code>gemm</code> to perform <code>dC = dA * dB</code>, and (5) one copy task <code>copyC</code> to copy the result from GPU to CPU.</p>
<h1><a class="anchor" id="cublasFlowCapturerExtension"></a>
Include Other cuBLAS Methods</h1>
<p>We do not include all the cuBLAS functions but users can easily make extension. <a class="el" href="classtf_1_1cublas_flow_capturer.html" title="class to construct a cuBLAS task graph">tf::cublasFlowCapturer</a> is derived from tf::cudaFlowCapturerBase and is created from a factory interface tf::cudaFlowCapturer::make_capturer. Each tf::cudaFlowCapturerBase object has a pointer accessible by tf::cudaFlowCapturerBase::factory in which you can use <a class="el" href="classtf_1_1cuda_flow_capturer.html#ad0d937ae0d77239f148b66a77e35db41" title="captures a sequential CUDA operations from the given callable">tf::cudaFlowCapturer::on</a> together with <a class="el" href="classtf_1_1cublas_flow_capturer.html#a2701b05226ef193e45482c1bb56f93de" title="gets the native cublas handle associated with this cublasFlowCapturer">tf::cublasFlowCapturer::native_handle</a> to capture other cuBLAS functions that are currently not available in <a class="el" href="classtf_1_1cuda_flow_capturer.html" title="class to create a cudaFlow graph using stream capture">tf::cudaFlowCapturer</a>. The following example captures the Hermitian rank-k update using <code>cublasCherkx</code>.</p>
<div class="fragment"><div class="line"><a class="code hl_function" href="poisson_8hpp.html#aa56fe360bb0ae38e0082f49e394ff825">taskflow</a>.emplace([&amp;](<a class="code hl_class" href="classtf_1_1cuda_flow_capturer.html">tf::cudaFlowCapturer</a>&amp; capturer){</div>
<div class="line">  <span class="comment">// create a cublasFlow capturer</span></div>
<div class="line">  <span class="keyword">auto</span> blas = capturer.make_capturer&lt;<a class="code hl_class" href="classtf_1_1cublas_flow_capturer.html">tf::cublasFlowCapturer</a>&gt;();</div>
<div class="line"> </div>
<div class="line">  <span class="comment">// use the base method tf::cudaFlowCapturer::on to capture other functions</span></div>
<div class="line">  blas-&gt;factory()-&gt;on([&amp;](cudaStream_t stream){</div>
<div class="line">    cublasSetStream(blas-&gt;native_handle(), stream);</div>
<div class="line">    cublasCherkx(blas-&gt;native_handle(), your_args...);</div>
<div class="line">  }).<a class="code hl_typedef" href="imgui__impl__opengl3__loader_8h.html#aab18cfce5ee7c6881ae04f18be70d94a">name</a>(<span class="stringliteral">&quot;Hermitian rank-k update&quot;</span>);</div>
<div class="line"> </div>
<div class="line">}).<a class="code hl_typedef" href="imgui__impl__opengl3__loader_8h.html#aab18cfce5ee7c6881ae04f18be70d94a">name</a>(<span class="stringliteral">&quot;capturer&quot;</span>);</div>
</div><!-- fragment --><dl class="section warning"><dt>警告</dt><dd>While <a class="el" href="classtf_1_1cublas_flow_capturer.html#a2701b05226ef193e45482c1bb56f93de" title="gets the native cublas handle associated with this cublasFlowCapturer">tf::cublasFlowCapturer::native_handle</a> returns the native cublas handle, you must not change its properties.</dd></dl>
<p>By default, we associate the native cublas handler with <code>CUBLAS_POINTER_MODE_DEVICE</code>. The two scalars, <code>alpha</code> and/or <code>beta</code>, and input/output matrices must be accessible in GPU memory space.</p>
<h1><a class="anchor" id="cublasFlowCapturerKnowMore"></a>
Know More About cublasFlow Capturer</h1>
<p>We summarize below resources for you to know more about <a class="el" href="classtf_1_1cublas_flow_capturer.html" title="class to construct a cuBLAS task graph">tf::cublasFlowCapturer</a>:</p><ul>
<li>Study the reference of <a class="el" href="classtf_1_1cublas_flow_capturer.html" title="class to construct a cuBLAS task graph">tf::cublasFlowCapturer</a> and <a class="el" href="classtf_1_1cuda_flow_capturer.html" title="class to create a cudaFlow graph using stream capture">tf::cudaFlowCapturer</a></li>
<li>Contribute to <a class="el" href="cublas__flow_8hpp.html" title="cublasFlowCapturer include file">cublas_flow.hpp</a> by adding more BLAS methods</li>
<li>See the complete list of BLAS functions offered by @cuBLAS </li>
</ul>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">制作者 <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.13.2 </li>
  </ul>
</div>
</body>
</html>
