<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="zh">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.13.2"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>source: external/taskflow/3rd-party/eigen-3.3.7/unsupported/Eigen/CXX11/src/Tensor 目录参考</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(function() { init_search(); });
/* @license-end */
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">source
   </div>
  </td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="搜索" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- 制作者 Doxygen 1.13.2 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('dir_d977e71cbbd043db4da1270ffcf16b6b.html',''); initResizable(true); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">载入中...</div>
<div class="SRStatus" id="Searching">搜索中...</div>
<div class="SRStatus" id="NoMatches">未找到</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">Tensor 目录参考</div></div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Tensor 的目录依赖关系图</div>
<div class="dyncontent">
<div class="center"><img src="dir_d977e71cbbd043db4da1270ffcf16b6b_dep.png" border="0" usemap="#adir__d977e71cbbd043db4da1270ffcf16b6b__dep" alt="external/taskflow/3rd-party/eigen-3.3.7/unsupported/Eigen/CXX11/src/Tensor"/></div>
<!-- MAP 0 -->
</div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="files" name="files"></a>
文件</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_8h.html">Tensor.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_arg_max_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_arg_max_8h.html">TensorArgMax.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_assign_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_assign_8h.html">TensorAssign.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_base_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_base_8h.html">TensorBase.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_broadcasting_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_broadcasting_8h.html">TensorBroadcasting.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_chipping_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_chipping_8h.html">TensorChipping.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_concatenation_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_concatenation_8h.html">TensorConcatenation.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_contraction_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_contraction_8h.html">TensorContraction.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_contraction_blocking_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_contraction_blocking_8h.html">TensorContractionBlocking.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_contraction_cuda_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_contraction_cuda_8h.html">TensorContractionCuda.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_contraction_mapper_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_contraction_mapper_8h.html">TensorContractionMapper.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_contraction_thread_pool_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_contraction_thread_pool_8h.html">TensorContractionThreadPool.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_conversion_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_conversion_8h.html">TensorConversion.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_convolution_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_convolution_8h.html">TensorConvolution.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_cost_model_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_cost_model_8h.html">TensorCostModel.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_custom_op_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_custom_op_8h.html">TensorCustomOp.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_device_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_device_8h.html">TensorDevice.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_device_cuda_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_device_cuda_8h.html">TensorDeviceCuda.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_device_default_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_device_default_8h.html">TensorDeviceDefault.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_device_sycl_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_device_sycl_8h.html">TensorDeviceSycl.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_device_thread_pool_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_device_thread_pool_8h.html">TensorDeviceThreadPool.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_dimension_list_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_dimension_list_8h.html">TensorDimensionList.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_dimensions_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_dimensions_8h.html">TensorDimensions.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_eval_to_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_eval_to_8h.html">TensorEvalTo.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_evaluator_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_evaluator_8h.html">TensorEvaluator.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_executor_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_executor_8h.html">TensorExecutor.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_expr_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_expr_8h.html">TensorExpr.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_f_f_t_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_f_f_t_8h.html">TensorFFT.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_fixed_size_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_fixed_size_8h.html">TensorFixedSize.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_forced_eval_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_forced_eval_8h.html">TensorForcedEval.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_forward_declarations_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_forward_declarations_8h.html">TensorForwardDeclarations.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_functors_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_functors_8h.html">TensorFunctors.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_generator_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_generator_8h.html">TensorGenerator.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_global_functions_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_global_functions_8h.html">TensorGlobalFunctions.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_image_patch_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_image_patch_8h.html">TensorImagePatch.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_index_list_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_index_list_8h.html">TensorIndexList.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_inflation_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_inflation_8h.html">TensorInflation.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_initializer_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_initializer_8h.html">TensorInitializer.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_int_div_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_int_div_8h.html">TensorIntDiv.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_i_o_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_i_o_8h.html">TensorIO.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_layout_swap_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_layout_swap_8h.html">TensorLayoutSwap.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_macros_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_macros_8h.html">TensorMacros.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_map_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_map_8h.html">TensorMap.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_meta_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_meta_8h.html">TensorMeta.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_morphing_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_morphing_8h.html">TensorMorphing.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_padding_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_padding_8h.html">TensorPadding.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_patch_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_patch_8h.html">TensorPatch.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_random_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_random_8h.html">TensorRandom.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_reduction_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_reduction_8h.html">TensorReduction.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_reduction_cuda_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_reduction_cuda_8h.html">TensorReductionCuda.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_reduction_sycl_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_reduction_sycl_8h.html">TensorReductionSycl.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_ref_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_ref_8h.html">TensorRef.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_reverse_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_reverse_8h.html">TensorReverse.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_scan_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_scan_8h.html">TensorScan.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_shuffling_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_shuffling_8h.html">TensorShuffling.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_storage_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_storage_8h.html">TensorStorage.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_striding_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_striding_8h.html">TensorStriding.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_sycl_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_sycl_8h.html">TensorSycl.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_sycl_convert_to_device_expression_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_sycl_convert_to_device_expression_8h.html">TensorSyclConvertToDeviceExpression.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_sycl_expr_constructor_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_sycl_expr_constructor_8h.html">TensorSyclExprConstructor.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_sycl_extract_accessor_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_sycl_extract_accessor_8h.html">TensorSyclExtractAccessor.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_sycl_extract_functors_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_sycl_extract_functors_8h.html">TensorSyclExtractFunctors.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_sycl_leaf_count_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_sycl_leaf_count_8h.html">TensorSyclLeafCount.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_sycl_place_holder_expr_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_sycl_place_holder_expr_8h.html">TensorSyclPlaceHolderExpr.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_sycl_run_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_sycl_run_8h.html">TensorSyclRun.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_sycl_tuple_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_sycl_tuple_8h.html">TensorSyclTuple.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_traits_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_traits_8h.html">TensorTraits.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_u_int128_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_u_int128_8h.html">TensorUInt128.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top"><a href="_tensor_volume_patch_8h_source.html"><span class="icondoc"></span></a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_tensor_volume_patch_8h.html">TensorVolumePatch.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">详细描述</h2>
<p>Tensors are multidimensional arrays of elements. Elements are typically scalars, but more complex types such as strings are also supported.</p>
<h1><a class="anchor" id="autotoc_md1155"></a>
Tensor Classes</h1>
<p>You can manipulate a tensor with one of the following classes. They all are in the namespace <code><a class="el" href="namespace_eigen.html" title="Namespace containing all symbols from the Eigen library.">Eigen</a>.</code></p>
<h2><a class="anchor" id="autotoc_md1156"></a>
Class Tensor&lt;data_type, rank&gt;</h2>
<p>This is the class to use to create a tensor and allocate memory for it. The class is templatized with the tensor datatype, such as float or int, and the tensor rank. The rank is the number of dimensions, for example rank 2 is a matrix.</p>
<p>Tensors of this class are resizable. For example, if you assign a tensor of a different size to a <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a>, that tensor is resized to match its new value.</p>
<h3><a class="anchor" id="autotoc_md1157"></a>
Constructor <code>Tensor&lt;data_type, rank&gt;(size0, size1, ...)</code></h3>
<p>Constructor for a <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a>. The constructor must be passed <code>rank</code> integers indicating the sizes of the instance along each of the the <code>rank</code> dimensions. </p><pre class="fragment">// Create a tensor of rank 3 of sizes 2, 3, 4.  This tensor owns
// memory to hold 24 floating point values (24 = 2 x 3 x 4).
Tensor&lt;float, 3&gt; t_3d(2, 3, 4);

// Resize t_3d by assigning a tensor of different sizes, but same rank.
t_3d = Tensor&lt;float, 3&gt;(3, 4, 3);
</pre><h3><a class="anchor" id="autotoc_md1158"></a>
Constructor <code>Tensor&lt;data_type, rank&gt;(size_array)</code></h3>
<p>Constructor where the sizes for the constructor are specified as an array of values instead of an explicitly list of parameters. The array type to use is <code><a class="el" href="class_eigen_1_1array.html">Eigen::array</a>&lt;<a class="el" href="class_eigen_1_1_tensor.html">Eigen::Index</a>&gt;</code>. The array can be constructed automatically from an initializer list. </p><pre class="fragment">// Create a tensor of strings of rank 2 with sizes 5, 7.
Tensor&lt;string, 2&gt; t_2d({5, 7});
</pre><h2><a class="anchor" id="autotoc_md1159"></a>
Class <code>TensorFixedSize&lt;data_type, Sizes&lt;size0, size1, ...&gt;&gt;</code></h2>
<p>Class to use for tensors of fixed size, where the size is known at compile time. Fixed sized tensors can provide very fast computations because all their dimensions are known by the compiler. FixedSize tensors are not resizable.</p>
<p>If the total number of elements in a fixed size tensor is small enough the tensor data is held onto the stack and does not cause heap allocation and free. </p><pre class="fragment">// Create a 4 x 3 tensor of floats.
TensorFixedSize&lt;float, Sizes&lt;4, 3&gt;&gt; t_4x3;
</pre><h2><a class="anchor" id="autotoc_md1160"></a>
Class <code>TensorMap&lt;Tensor&lt;data_type, rank&gt;&gt;</code></h2>
<p>This is the class to use to create a tensor on top of memory allocated and owned by another part of your code. It allows to view any piece of allocated memory as a <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a>. Instances of this class do not own the memory where the data are stored.</p>
<p><a class="el" href="bench__gemm_8cpp.html#addc86e8508f14411ec98f521c520f875">A</a> <a class="el" href="class_tensor_map.html" title="A tensor expression mapping an existing array of data.">TensorMap</a> is not resizable because it does not own the memory where its data are stored.</p>
<h3><a class="anchor" id="autotoc_md1161"></a>
Constructor <code>TensorMap&lt;Tensor&lt;data_type, rank&gt;&gt;(data, size0, size1, ...)</code></h3>
<p>Constructor for a <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a>. The constructor must be passed a pointer to the storage for the data, and "rank" size attributes. The storage has to be large enough to hold all the data. </p><pre class="fragment">// Map a tensor of ints on top of stack-allocated storage.
int storage[128];  // 2 x 4 x 2 x 8 = 128
TensorMap&lt;Tensor&lt;int, 4&gt;&gt; t_4d(storage, 2, 4, 2, 8);

// The same storage can be viewed as a different tensor.
// You can also pass the sizes as an array.
TensorMap&lt;Tensor&lt;int, 2&gt;&gt; t_2d(storage, 16, 8);

// You can also map fixed-size tensors.  Here we get a 1d view of
// the 2d fixed-size tensor.
TensorFixedSize&lt;float, Sizes&lt;4, 5&gt;&gt; t_4x3;
TensorMap&lt;Tensor&lt;float, 1&gt;&gt; t_12(t_4x3.data(), 12);
</pre><h3><a class="anchor" id="autotoc_md1162"></a>
Class <code>TensorRef</code></h3>
<p>See Assigning to a TensorRef below.</p>
<h1><a class="anchor" id="autotoc_md1163"></a>
Accessing Tensor Elements</h1>
<h3><a class="anchor" id="autotoc_md1164"></a>
<code>&lt;data_type&gt; tensor(index0, index1...)</code></h3>
<p>Return the element at position <code>(index0, index1...)</code> in tensor <code>tensor</code>. You must pass as many parameters as the rank of <code>tensor</code>. The expression can be used as an l-value to set the value of the element at the specified position. The value returned is of the datatype of the tensor. </p><pre class="fragment">// Set the value of the element at position (0, 1, 0);
Tensor&lt;float, 3&gt; t_3d(2, 3, 4);
t_3d(0, 1, 0) = 12.0f;

// Initialize all elements to random values.
for (int i = 0; i &lt; 2; ++i) {
  for (int j = 0; j &lt; 3; ++j) {
    for (int k = 0; k &lt; 4; ++k) {
      t_3d(i, j, k) = ...some random value...;
    }
  }
}

// Print elements of a tensor.
for (int i = 0; i &lt; 2; ++i) {
  LOG(INFO) &lt;&lt; t_3d(i, 0, 0);
}
</pre><h1><a class="anchor" id="autotoc_md1165"></a>
TensorLayout</h1>
<p>The tensor library supports 2 layouts: <code>ColMajor</code> (the default) and <code>RowMajor</code>. Only the default column major layout is currently fully supported, and it is therefore not recommended to attempt to use the row major layout at the moment.</p>
<p>The layout of a tensor is optionally specified as part of its type. If not specified explicitly column major is assumed. </p><pre class="fragment">Tensor&lt;float, 3, ColMajor&gt; col_major;  // equivalent to Tensor&lt;float, 3&gt;
TensorMap&lt;Tensor&lt;float, 3, RowMajor&gt; &gt; row_major(data, ...);
</pre><p>All the arguments to an expression must use the same layout. Attempting to mix different layouts will result in a compilation error.</p>
<p>It is possible to change the layout of a tensor or an expression using the <code>swap_layout()</code> method. Note that this will also reverse the order of the dimensions. </p><pre class="fragment">Tensor&lt;float, 2, ColMajor&gt; col_major(2, 4);
Tensor&lt;float, 2, RowMajor&gt; row_major(2, 4);

Tensor&lt;float, 2&gt; col_major_result = col_major;  // ok, layouts match
Tensor&lt;float, 2&gt; col_major_result = row_major;  // will not compile

// Simple layout swap
col_major_result = row_major.swap_layout();
eigen_assert(col_major_result.dimension(0) == 4);
eigen_assert(col_major_result.dimension(1) == 2);

// Swap the layout and preserve the order of the dimensions
array&lt;int, 2&gt; shuffle(1, 0);
col_major_result = row_major.swap_layout().shuffle(shuffle);
eigen_assert(col_major_result.dimension(0) == 2);
eigen_assert(col_major_result.dimension(1) == 4);
</pre><h1><a class="anchor" id="autotoc_md1166"></a>
Tensor Operations</h1>
<p>The <a class="el" href="namespace_eigen.html" title="Namespace containing all symbols from the Eigen library.">Eigen</a> <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a> library provides a vast library of operations on Tensors: numerical operations such as addition and multiplication, geometry operations such as slicing and shuffling, etc. These operations are available as methods of the <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a> classes, and in some cases as operator overloads. For example the following code computes the elementwise addition of two tensors: </p><pre class="fragment">Tensor&lt;float, 3&gt; t1(2, 3, 4);
...set some values in t1...
Tensor&lt;float, 3&gt; t2(2, 3, 4);
...set some values in t2...
// Set t3 to the element wise sum of t1 and t2
Tensor&lt;float, 3&gt; t3 = t1 + t2;
</pre><p>While the code above looks easy enough, it is important to understand that the expression <code>t1 + t2</code> is not actually adding the values of the tensors. The expression instead constructs a "tensor operator" object of the class TensorCwiseBinaryOp&lt;scalar_sum&gt;, which has references to the tensors <code>t1</code> and <code>t2</code>. This is a small C++ object that knows how to add <code>t1</code> and <code>t2</code>. It is only when the value of the expression is assigned to the tensor <code>t3</code> that the addition is actually performed. Technically, this happens through the overloading of <code>operator=()</code> in the <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a> class.</p>
<p>This mechanism for computing tensor expressions allows for lazy evaluation and optimizations which are what make the tensor library very fast.</p>
<p>Of course, the tensor operators do nest, and the expression <code>t1 + t2 * 0.3f</code> is actually represented with the (approximate) tree of operators: </p><pre class="fragment">TensorCwiseBinaryOp&lt;scalar_sum&gt;(t1, TensorCwiseUnaryOp&lt;scalar_mul&gt;(t2, 0.3f))
</pre><h2><a class="anchor" id="autotoc_md1167"></a>
Tensor Operations and C++ "auto"</h2>
<p>Because <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a> operations create tensor operators, the C++ <code>auto</code> keyword does not have its intuitive meaning. Consider these 2 lines of code: </p><pre class="fragment">Tensor&lt;float, 3&gt; t3 = t1 + t2;
auto t4 = t1 + t2;
</pre><p>In the first line we allocate the tensor <code>t3</code> and it will contain the result of the addition of <code>t1</code> and <code>t2</code>. In the second line, <code>t4</code> is actually the tree of tensor operators that will compute the addition of <code>t1</code> and <code>t2</code>. In fact, <code>t4</code> is <em>not</em> a tensor and you cannot get the values of its elements: </p><pre class="fragment">Tensor&lt;float, 3&gt; t3 = t1 + t2;
cout &lt;&lt; t3(0, 0, 0);  // OK prints the value of t1(0, 0, 0) + t2(0, 0, 0)

auto t4 = t1 + t2;
cout &lt;&lt; t4(0, 0, 0);  // Compilation error!
</pre><p>When you use <code>auto</code> you do not get a <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a> as a result but instead a non-evaluated expression. So only use <code>auto</code> to delay evaluation.</p>
<p>Unfortunately, there is no single underlying concrete type for holding non-evaluated expressions, hence you have to use auto in the case when you do want to hold non-evaluated expressions.</p>
<p>When you need the results of set of tensor computations you have to assign the result to a <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a> that will be capable of holding onto them. This can be either a normal <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a>, a fixed size <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a>, or a <a class="el" href="class_tensor_map.html" title="A tensor expression mapping an existing array of data.">TensorMap</a> on an existing piece of memory. All the following will work: </p><pre class="fragment">auto t4 = t1 + t2;

Tensor&lt;float, 3&gt; result = t4;  // Could also be: result(t4);
cout &lt;&lt; result(0, 0, 0);

TensorMap&lt;float, 4&gt; result(&lt;a float* with enough space&gt;, &lt;size0&gt;, ...) = t4;
cout &lt;&lt; result(0, 0, 0);

TensorFixedSize&lt;float, Sizes&lt;size0, ...&gt;&gt; result = t4;
cout &lt;&lt; result(0, 0, 0);
</pre><p>Until you need the results, you can keep the operation around, and even reuse it for additional operations. As long as you keep the expression as an operation, no computation is performed. </p><pre class="fragment">// One way to compute exp((t1 + t2) * 0.2f);
auto t3 = t1 + t2;
auto t4 = t3 * 0.2f;
auto t5 = t4.exp();
Tensor&lt;float, 3&gt; result = t5;

// Another way, exactly as efficient as the previous one:
Tensor&lt;float, 3&gt; result = ((t1 + t2) * 0.2f).exp();
</pre><h2><a class="anchor" id="autotoc_md1168"></a>
Controlling When Expression are Evaluated</h2>
<p>There are several ways to control when expressions are evaluated:</p>
<ul>
<li>Assignment to a <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a>, TensorFixedSize, or <a class="el" href="class_tensor_map.html" title="A tensor expression mapping an existing array of data.">TensorMap</a>.</li>
<li>Use of the <a class="el" href="sparse__permutations_8cpp.html#abf03ad46cd5db5b4eabad69a86a13a6c">eval()</a> method.</li>
<li>Assignment to a TensorRef.</li>
</ul>
<h3><a class="anchor" id="autotoc_md1169"></a>
Assigning to a Tensor, TensorFixedSize, or TensorMap.</h3>
<p>The most common way to evaluate an expression is to assign it to a <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a>. In the example below, the <code>auto</code> declarations make the intermediate values "Operations", not Tensors, and do not cause the expressions to be evaluated. The assignment to the <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a> <code>result</code> causes the evaluation of all the operations. </p><pre class="fragment">auto t3 = t1 + t2;             // t3 is an Operation.
auto t4 = t3 * 0.2f;           // t4 is an Operation.
auto t5 = t4.exp();            // t5 is an Operation.
Tensor&lt;float, 3&gt; result = t5;  // The operations are evaluated.
</pre><p>If you know the ranks and sizes of the Operation value you can assign the Operation to a TensorFixedSize instead of a <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a>, which is a bit more efficient. </p><pre class="fragment">// We know that the result is a 4x4x2 tensor!
TensorFixedSize&lt;float, Sizes&lt;4, 4, 2&gt;&gt; result = t5;
</pre><p>Simiarly, assigning an expression to a <a class="el" href="class_tensor_map.html" title="A tensor expression mapping an existing array of data.">TensorMap</a> causes its evaluation. Like tensors of type TensorFixedSize, TensorMaps cannot be resized so they have to have the rank and sizes of the expression that are assigned to them.</p>
<h3><a class="anchor" id="autotoc_md1170"></a>
Calling <code>eval()</code>.</h3>
<p>When you compute large composite expressions, you sometimes want to tell <a class="el" href="namespace_eigen.html" title="Namespace containing all symbols from the Eigen library.">Eigen</a> that an intermediate value in the expression tree is worth evaluating ahead of time. This is done by inserting a call to the <code><a class="el" href="sparse__permutations_8cpp.html#abf03ad46cd5db5b4eabad69a86a13a6c">eval()</a></code> method of the expression Operation. </p><pre class="fragment">// The previous example could have been written:
Tensor&lt;float, 3&gt; result = ((t1 + t2) * 0.2f).exp();

// If you want to compute (t1 + t2) once ahead of time you can write:
Tensor&lt;float, 3&gt; result = ((t1 + t2).eval() * 0.2f).exp();
</pre><p>Semantically, calling <code><a class="el" href="sparse__permutations_8cpp.html#abf03ad46cd5db5b4eabad69a86a13a6c">eval()</a></code> is equivalent to materializing the value of the expression in a temporary <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a> of the right size. The code above in effect does: </p><pre class="fragment">// .eval() knows the size!
TensorFixedSize&lt;float, Sizes&lt;4, 4, 2&gt;&gt; tmp = t1 + t2;
Tensor&lt;float, 3&gt; result = (tmp * 0.2f).exp();
</pre><p>Note that the return value of <code><a class="el" href="sparse__permutations_8cpp.html#abf03ad46cd5db5b4eabad69a86a13a6c">eval()</a></code> is itself an Operation, so the following code does not do what you may think: </p><pre class="fragment">// Here t3 is an evaluation Operation.  t3 has not been evaluated yet.
auto t3 = (t1 + t2).eval();

// You can use t3 in another expression.  Still no evaluation.
auto t4 = (t3 * 0.2f).exp();

// The value is evaluated when you assign the Operation to a Tensor, using
// an intermediate tensor to represent t3.x
Tensor&lt;float, 3&gt; result = t4;
</pre><p>While in the examples above calling <code><a class="el" href="sparse__permutations_8cpp.html#abf03ad46cd5db5b4eabad69a86a13a6c">eval()</a></code> does not make a difference in performance, in other cases it can make a huge difference. In the expression below the <code>broadcast()</code> expression causes the <code>X.maximum()</code> expression to be evaluated many times: </p><pre class="fragment">Tensor&lt;...&gt; X ...;
Tensor&lt;...&gt; Y = ((X - X.maximum(depth_dim).reshape(dims2d).broadcast(bcast))
                 * beta).exp();
</pre><p>Inserting a call to <code><a class="el" href="sparse__permutations_8cpp.html#abf03ad46cd5db5b4eabad69a86a13a6c">eval()</a></code> between the <code>maximum()</code> and <code><a class="el" href="boing_8c.html#a5272e39ef9d8944cb3f99d656f9f555a">reshape()</a></code> calls guarantees that maximum() is only computed once and greatly speeds-up execution: </p><pre class="fragment">Tensor&lt;...&gt; Y =
  ((X - X.maximum(depth_dim).eval().reshape(dims2d).broadcast(bcast))
    * beta).exp();
</pre><p>In the other example below, the tensor <code>Y</code> is both used in the expression and its assignment. This is an aliasing problem and if the evaluation is not done in the right order Y will be updated incrementally during the evaluation resulting in bogus results: </p><pre class="fragment"> Tensor&lt;...&gt; Y ...;
 Y = Y / (Y.sum(depth_dim).reshape(dims2d).broadcast(bcast));
</pre><p>Inserting a call to <code><a class="el" href="sparse__permutations_8cpp.html#abf03ad46cd5db5b4eabad69a86a13a6c">eval()</a></code> between the <code><a class="el" href="test__parallel__for__each_8cpp.html#a539b07c7f86d3a9854ed81da50a4fb7d">sum()</a></code> and <code><a class="el" href="boing_8c.html#a5272e39ef9d8944cb3f99d656f9f555a">reshape()</a></code> expressions ensures that the sum is computed before any updates to <code>Y</code> are done. </p><pre class="fragment"> Y = Y / (Y.sum(depth_dim).eval().reshape(dims2d).broadcast(bcast));
</pre><p>Note that an eval around the full right hand side expression is not needed because the generated has to compute the i-th value of the right hand side before assigning it to the left hand side.</p>
<p>However, if you were assigning the expression value to a shuffle of <code>Y</code> then you would need to force an eval for correctness by adding an <code><a class="el" href="sparse__permutations_8cpp.html#abf03ad46cd5db5b4eabad69a86a13a6c">eval()</a></code> call for the right hand side: </p><pre class="fragment"> Y.shuffle(...) =
    (Y / (Y.sum(depth_dim).eval().reshape(dims2d).broadcast(bcast))).eval();
</pre><h3><a class="anchor" id="autotoc_md1171"></a>
Assigning to a <code>TensorRef</code>.</h3>
<p>If you need to access only a few elements from the value of an expression you can avoid materializing the value in a full tensor by using a TensorRef.</p>
<p><a class="el" href="bench__gemm_8cpp.html#addc86e8508f14411ec98f521c520f875">A</a> TensorRef is a small wrapper class for any <a class="el" href="namespace_eigen.html" title="Namespace containing all symbols from the Eigen library.">Eigen</a> Operation. It provides overloads for the <code>()</code> operator that let you access individual values in the expression. TensorRef is convenient, because the Operation themselves do not provide a way to access individual elements. </p><pre class="fragment">// Create a TensorRef for the expression.  The expression is not
// evaluated yet.
TensorRef&lt;Tensor&lt;float, 3&gt; &gt; ref = ((t1 + t2) * 0.2f).exp();

// Use "ref" to access individual elements.  The expression is evaluated
// on the fly.
float at_0 = ref(0, 0, 0);
cout &lt;&lt; ref(0, 1, 0);
</pre><p>Only use TensorRef when you need a subset of the values of the expression. TensorRef only computes the values you access. However note that if you are going to access all the values it will be much faster to materialize the results in a <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a> first.</p>
<p>In some cases, if the full <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a> result would be very large, you may save memory by accessing it as a TensorRef. But not always. So don't count on it.</p>
<h2><a class="anchor" id="autotoc_md1172"></a>
Controlling How Expressions Are Evaluated</h2>
<p>The tensor library provides several implementations of the various operations such as contractions and convolutions. The implementations are optimized for different environments: single threaded on CPU, multi threaded on CPU, or on a GPU using cuda. Additional implementations may be added later.</p>
<p>You can choose which implementation to use with the <code>device()</code> call. If you do not choose an implementation explicitly the default implementation that uses a single thread on the CPU is used.</p>
<p>The default implementation has been optimized for recent Intel CPUs, taking advantage of SSE, AVX, and FMA instructions. <a class="el" href="struct_work.html">Work</a> is ongoing to tune the library on ARM CPUs. Note that you need to pass compiler-dependent flags to enable the use of SSE, AVX, and other instructions.</p>
<p>For example, the following code adds two tensors using the default single-threaded CPU implementation: </p><pre class="fragment">Tensor&lt;float, 2&gt; a(30, 40);
Tensor&lt;float, 2&gt; b(30, 40);
Tensor&lt;float, 2&gt; c = a + b;
</pre><p>To choose a different implementation you have to insert a <code>device()</code> call before the assignment of the result. For technical C++ reasons this requires that the <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a> for the result be declared on its own. This means that you have to know the size of the result. </p><pre class="fragment">Eigen::Tensor&lt;float, 2&gt; c(30, 40);
c.device(...) = a + b;
</pre><p>The call to <code>device()</code> must be the last call on the left of the operator=.</p>
<p>You must pass to the <code>device()</code> call an <a class="el" href="namespace_eigen.html" title="Namespace containing all symbols from the Eigen library.">Eigen</a> device object. There are presently three devices you can use: <a class="el" href="struct_default_device.html">DefaultDevice</a>, ThreadPoolDevice and GpuDevice.</p>
<h3><a class="anchor" id="autotoc_md1173"></a>
Evaluating With the DefaultDevice</h3>
<p>This is exactly the same as not inserting a <code>device()</code> call. </p><pre class="fragment">DefaultDevice my_device;
c.device(my_device) = a + b;
</pre><h3><a class="anchor" id="autotoc_md1174"></a>
Evaluating with a Thread Pool</h3>
<pre class="fragment">// Create the Eigen ThreadPoolDevice.
Eigen::ThreadPoolDevice my_device(4 /* number of threads to use */);

// Now just use the device when evaluating expressions.
Eigen::Tensor&lt;float, 2&gt; c(30, 50);
c.device(my_device) = a.contract(b, dot_product_dims);
</pre><h3><a class="anchor" id="autotoc_md1175"></a>
Evaluating On GPU</h3>
<p>This is presently a bit more complicated than just using a thread pool device. You need to create a GPU device but you also need to explicitly allocate the memory for tensors with cuda.</p>
<h1><a class="anchor" id="autotoc_md1176"></a>
API Reference</h1>
<h2><a class="anchor" id="autotoc_md1177"></a>
Datatypes</h2>
<p>In the documentation of the tensor methods and Operation we mention datatypes that are tensor-type specific:</p>
<h3><a class="anchor" id="autotoc_md1178"></a>
<code>&lt;Tensor-Type&gt;::</code><code>Dimensions</code></h3>
<p>Acts like an array of ints. Has an <code>int size</code> attribute, and can be indexed like an array to access individual values. Used to represent the dimensions of a tensor. See <code><a class="el" href="ittnotify__static_8h.html#ae7f065e8ec86c9b6234e9a5f7beb921e">dimensions()</a></code>.</p>
<h3><a class="anchor" id="autotoc_md1179"></a>
<code>&lt;Tensor-Type&gt;::</code><code>Index</code></h3>
<p>Acts like an <code>int</code>. Used for indexing tensors along their dimensions. See <code>operator()</code>, <code>dimension()</code>, and <code><a class="el" href="imgui__impl__opengl3__loader_8h.html#ac42c05b5701aef6bab82675cf3b55fee">size()</a></code>.</p>
<h3><a class="anchor" id="autotoc_md1180"></a>
<code>&lt;Tensor-Type&gt;::</code><code>Scalar</code></h3>
<p>Represents the datatype of individual tensor elements. For example, for a <code><a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a>&lt;float&gt;</code>, <code><a class="el" href="bench__gemm_8cpp.html#a052eb942d12b6404aade6fae4b075fb9">Scalar</a></code> is the type <code>float</code>. See <code><a class="el" href="_matrix__set_constant__int_8cpp.html#a76d9bdf892e002d33c2bbf3c5bf8ca5b">setConstant()</a></code>.</p>
<h3><a class="anchor" id="autotoc_md1181"></a>
<code>&lt;Operation&gt;</code></h3>
<p>We use this pseudo type to indicate that a tensor Operation is returned by a method. We indicate in the text the type and dimensions of the tensor that the Operation returns after evaluation.</p>
<p>The Operation will have to be evaluated, for example by assigning it to a tensor, before you can access the values of the resulting tensor. You can also access the values through a TensorRef.</p>
<h1><a class="anchor" id="autotoc_md1182"></a>
Built-in Tensor Methods</h1>
<p>These are usual C++ methods that act on tensors immediately. They are not Operations which provide delayed evaluation of their results. Unless specified otherwise, all the methods listed below are available on all tensor classes: <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a>, TensorFixedSize, and <a class="el" href="class_tensor_map.html" title="A tensor expression mapping an existing array of data.">TensorMap</a>.</p>
<h1><a class="anchor" id="autotoc_md1183"></a>
Metadata</h1>
<h2><a class="anchor" id="autotoc_md1184"></a>
<code>int NumDimensions</code></h2>
<p>Constant value indicating the number of dimensions of a <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a>. This is also known as the tensor "rank". </p><pre class="fragment">  Eigen::Tensor&lt;float, 2&gt; a(3, 4);
  cout &lt;&lt; "Dims " &lt;&lt; a.NumDimensions;
  =&gt; Dims 2
</pre><h2><a class="anchor" id="autotoc_md1185"></a>
<code>Dimensions dimensions()</code></h2>
<p>Returns an array-like object representing the dimensions of the tensor. The actual type of the <code><a class="el" href="ittnotify__static_8h.html#ae7f065e8ec86c9b6234e9a5f7beb921e">dimensions()</a></code> result is <code>&lt;Tensor-Type&gt;::</code><code>Dimensions</code>. </p><pre class="fragment">Eigen::Tensor&lt;float, 2&gt; a(3, 4);
const Eigen::Tensor&lt;float, 2&gt;::Dimensions&amp; d = a.dimensions();
cout &lt;&lt; "Dim size: " &lt;&lt; d.size &lt;&lt; ", dim 0: " &lt;&lt; d[0]
     &lt;&lt; ", dim 1: " &lt;&lt; d[1];
=&gt; Dim size: 2, dim 0: 3, dim 1: 4
</pre><p>If you use a C++11 compiler, you can use <code>auto</code> to simplify the code: </p><pre class="fragment">const auto&amp; d = a.dimensions();
cout &lt;&lt; "Dim size: " &lt;&lt; d.size &lt;&lt; ", dim 0: " &lt;&lt; d[0]
     &lt;&lt; ", dim 1: " &lt;&lt; d[1];
=&gt; Dim size: 2, dim 0: 3, dim 1: 4
</pre><h2><a class="anchor" id="autotoc_md1186"></a>
<code>Index dimension(Index n)</code></h2>
<p>Returns the n-th dimension of the tensor. The actual type of the <code>dimension()</code> result is <code>&lt;Tensor-Type&gt;::</code><code>Index</code>, but you can always use it like an int. </p><pre class="fragment">  Eigen::Tensor&lt;float, 2&gt; a(3, 4);
  int dim1 = a.dimension(1);
  cout &lt;&lt; "Dim 1: " &lt;&lt; dim1;
  =&gt; Dim 1: 4
</pre><h2><a class="anchor" id="autotoc_md1187"></a>
<code>Index size()</code></h2>
<p>Returns the total number of elements in the tensor. This is the product of all the tensor dimensions. The actual type of the <code><a class="el" href="imgui__impl__opengl3__loader_8h.html#ac42c05b5701aef6bab82675cf3b55fee">size()</a></code> result is <code>&lt;Tensor-Type&gt;::</code><code>Index</code>, but you can always use it like an int. </p><pre class="fragment">Eigen::Tensor&lt;float, 2&gt; a(3, 4);
cout &lt;&lt; "Size: " &lt;&lt; a.size();
=&gt; Size: 12
</pre><h2><a class="anchor" id="autotoc_md1188"></a>
Getting Dimensions From An Operation</h2>
<p><a class="el" href="bench__gemm_8cpp.html#addc86e8508f14411ec98f521c520f875">A</a> few operations provide <code><a class="el" href="ittnotify__static_8h.html#ae7f065e8ec86c9b6234e9a5f7beb921e">dimensions()</a></code> directly, e.g. <code>TensorReslicingOp</code>. Most operations defer calculating dimensions until the operation is being evaluated. If you need access to the dimensions of a deferred operation, you can wrap it in a TensorRef (see Assigning to a TensorRef above), which provides <code><a class="el" href="ittnotify__static_8h.html#ae7f065e8ec86c9b6234e9a5f7beb921e">dimensions()</a></code> and <code>dimension()</code> as above.</p>
<p>TensorRef can also wrap the plain <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a> types, so this is a useful idiom in templated contexts where the underlying object could be either a raw <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a> or some deferred operation (e.g. a slice of a <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a>). In this case, the template code can wrap the object in a TensorRef and reason about its dimensionality while remaining agnostic to the underlying type.</p>
<h1><a class="anchor" id="autotoc_md1189"></a>
Constructors</h1>
<h2><a class="anchor" id="autotoc_md1190"></a>
Tensor</h2>
<p>Creates a tensor of the specified size. The number of arguments must be equal to the rank of the tensor. The content of the tensor is not initialized. </p><pre class="fragment">Eigen::Tensor&lt;float, 2&gt; a(3, 4);
cout &lt;&lt; "NumRows: " &lt;&lt; a.dimension(0) &lt;&lt; " NumCols: " &lt;&lt; a.dimension(1) &lt;&lt; endl;
=&gt; NumRows: 3 NumCols: 4
</pre><h2><a class="anchor" id="autotoc_md1191"></a>
TensorFixedSize</h2>
<p>Creates a tensor of the specified size. The number of arguments in the Sizes&lt;&gt; template parameter determines the rank of the tensor. The content of the tensor is not initialized. </p><pre class="fragment">Eigen::TensorFixedSize&lt;float, Sizes&lt;3, 4&gt;&gt; a;
cout &lt;&lt; "Rank: " &lt;&lt; a.rank() &lt;&lt; endl;
=&gt; Rank: 2
cout &lt;&lt; "NumRows: " &lt;&lt; a.dimension(0) &lt;&lt; " NumCols: " &lt;&lt; a.dimension(1) &lt;&lt; endl;
=&gt; NumRows: 3 NumCols: 4
</pre><h2><a class="anchor" id="autotoc_md1192"></a>
TensorMap</h2>
<p>Creates a tensor mapping an existing array of data. The data must not be freed until the <a class="el" href="class_tensor_map.html" title="A tensor expression mapping an existing array of data.">TensorMap</a> is discarded, and the size of the data must be large enough to accommodate the coefficients of the tensor. </p><pre class="fragment">float data[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11};
Eigen::TensorMap&lt;Tensor&lt;float, 2&gt;&gt; a(data, 3, 4);
cout &lt;&lt; "NumRows: " &lt;&lt; a.dimension(0) &lt;&lt; " NumCols: " &lt;&lt; a.dimension(1) &lt;&lt; endl;
=&gt; NumRows: 3 NumCols: 4
cout &lt;&lt; "a(1, 2): " &lt;&lt; a(1, 2) &lt;&lt; endl;
=&gt; a(1, 2): 7
</pre><h1><a class="anchor" id="autotoc_md1193"></a>
Contents Initialization</h1>
<p>When a new <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a> or a new TensorFixedSize are created, memory is allocated to hold all the tensor elements, but the memory is not initialized. Similarly, when a new <a class="el" href="class_tensor_map.html" title="A tensor expression mapping an existing array of data.">TensorMap</a> is created on top of non-initialized memory the memory its contents are not initialized.</p>
<p>You can use one of the methods below to initialize the tensor memory. These have an immediate effect on the tensor and return the tensor itself as a result. These are not tensor Operations which delay evaluation.</p>
<h2><a class="anchor" id="autotoc_md1194"></a>
<code>&lt;Tensor-Type&gt; setConstant(const Scalar&amp; val)</code></h2>
<p>Sets all elements of the tensor to the constant value <code>val</code>. <code><a class="el" href="bench__gemm_8cpp.html#a052eb942d12b6404aade6fae4b075fb9">Scalar</a></code> is the type of data stored in the tensor. You can pass any value that is convertible to that type.</p>
<p>Returns the tensor itself in case you want to chain another call. </p><pre class="fragment">a.setConstant(12.3f);
cout &lt;&lt; "Constant: " &lt;&lt; endl &lt;&lt; a &lt;&lt; endl &lt;&lt; endl;
=&gt;
Constant:
12.3 12.3 12.3 12.3
12.3 12.3 12.3 12.3
12.3 12.3 12.3 12.3
</pre><p>Note that <code><a class="el" href="_matrix__set_constant__int_8cpp.html#a76d9bdf892e002d33c2bbf3c5bf8ca5b">setConstant()</a></code> can be used on any tensor where the element type has a copy constructor and an <code>operator=()</code>: </p><pre class="fragment">Eigen::Tensor&lt;string, 2&gt; a(2, 3);
a.setConstant("yolo");
cout &lt;&lt; "String tensor: " &lt;&lt; endl &lt;&lt; a &lt;&lt; endl &lt;&lt; endl;
=&gt;
String tensor:
yolo yolo yolo
yolo yolo yolo
</pre><h2><a class="anchor" id="autotoc_md1195"></a>
<code>&lt;Tensor-Type&gt; setZero()</code></h2>
<p>Fills the tensor with zeros. Equivalent to <code>setConstant(Scalar(0))</code>. Returns the tensor itself in case you want to chain another call. </p><pre class="fragment">a.setZero();
cout &lt;&lt; "Zeros: " &lt;&lt; endl &lt;&lt; a &lt;&lt; endl &lt;&lt; endl;
=&gt;
Zeros:
0 0 0 0
0 0 0 0
0 0 0 0
</pre><h2><a class="anchor" id="autotoc_md1196"></a>
<code>&lt;Tensor-Type&gt; setValues({..initializer_list})</code></h2>
<p>Fills the tensor with explicit values specified in a <a class="el" href="classstd_1_1initializer__list.html">std::initializer_list</a>. The type of the initializer list depends on the type and rank of the tensor.</p>
<p>If the tensor has rank N, the initializer list must be nested N times. The most deeply nested lists must contains P scalars of the <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a> type where P is the size of the last dimension of the <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a>.</p>
<p>For example, for a <code>TensorFixedSize&lt;float, 2, 3&gt;</code> the initializer list must contains 2 lists of 3 floats each.</p>
<p><code>setValues()</code> returns the tensor itself in case you want to chain another call. </p><pre class="fragment">Eigen::Tensor&lt;float, 2&gt; a(2, 3);
a.setValues({{0.0f, 1.0f, 2.0f}, {3.0f, 4.0f, 5.0f}});
cout &lt;&lt; "a" &lt;&lt; endl &lt;&lt; a &lt;&lt; endl &lt;&lt; endl;
=&gt;
a
0 1 2
3 4 5
</pre><p>If a list is too short, the corresponding elements of the tensor will not be changed. This is valid at each level of nesting. For example the following code only sets the values of the first row of the tensor. </p><pre class="fragment">Eigen::Tensor&lt;int, 2&gt; a(2, 3);
a.setConstant(1000);
a.setValues({{10, 20, 30}});
cout &lt;&lt; "a" &lt;&lt; endl &lt;&lt; a &lt;&lt; endl &lt;&lt; endl;
=&gt;
a
10   20   30
1000 1000 1000
</pre><h2><a class="anchor" id="autotoc_md1197"></a>
<code>&lt;Tensor-Type&gt; setRandom()</code></h2>
<p>Fills the tensor with random values. Returns the tensor itself in case you want to chain another call. </p><pre class="fragment">a.setRandom();
cout &lt;&lt; "Random: " &lt;&lt; endl &lt;&lt; a &lt;&lt; endl &lt;&lt; endl;
=&gt;
Random:
  0.680375    0.59688  -0.329554    0.10794
 -0.211234   0.823295   0.536459 -0.0452059
  0.566198  -0.604897  -0.444451   0.257742
</pre><p>You can customize <code><a class="el" href="_householder_q_r__householder_q_8cpp.html#a7bddadaf72fd7356fb04dd15cf547bc2">setRandom()</a></code> by providing your own random number generator as a template argument: </p><pre class="fragment">a.setRandom&lt;MyRandomGenerator&gt;();
</pre><p>Here, <code>MyRandomGenerator</code> must be a struct with the following member functions, where <a class="el" href="bench__gemm_8cpp.html#a052eb942d12b6404aade6fae4b075fb9">Scalar</a> and Index are the same as <code>&lt;Tensor-Type&gt;::</code><code><a class="el" href="bench__gemm_8cpp.html#a052eb942d12b6404aade6fae4b075fb9">Scalar</a></code> and <code>&lt;Tensor-Type&gt;::</code><code>Index</code>.</p>
<p>See <code>struct UniformRandomGenerator</code> in <a class="el" href="_tensor_functors_8h.html">TensorFunctors.h</a> for an example. </p><pre class="fragment">// Custom number generator for use with setRandom().
struct MyRandomGenerator {
  // Default and copy constructors. Both are needed
  MyRandomGenerator() { }
  MyRandomGenerator(const MyRandomGenerator&amp; ) { }

  // Return a random value to be used.  "element_location" is the
  // location of the entry to set in the tensor, it can typically
  // be ignored.
  Scalar operator()(Eigen::DenseIndex element_location,
                    Eigen::DenseIndex /*unused*/ = 0) const {
    return &lt;randomly generated value of type T&gt;;
  }

  // Same as above but generates several numbers at a time.
  typename internal::packet_traits&lt;Scalar&gt;::type packetOp(
      Eigen::DenseIndex packet_location, Eigen::DenseIndex /*unused*/ = 0) const {
    return &lt;a packet of randomly generated values&gt;;
  }
};
</pre><p>You can also use one of the 2 random number generators that are part of the tensor library:</p><ul>
<li>UniformRandomGenerator</li>
<li>NormalRandomGenerator</li>
</ul>
<h1><a class="anchor" id="autotoc_md1198"></a>
Data Access</h1>
<p>The <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a>, TensorFixedSize, and TensorRef classes provide the following accessors to access the tensor coefficients: </p><pre class="fragment">const Scalar&amp; operator()(const array&lt;Index, NumIndices&gt;&amp; indices)
const Scalar&amp; operator()(Index firstIndex, IndexTypes... otherIndices)
Scalar&amp; operator()(const array&lt;Index, NumIndices&gt;&amp; indices)
Scalar&amp; operator()(Index firstIndex, IndexTypes... otherIndices)
</pre><p>The number of indices must be equal to the rank of the tensor. Moreover, these accessors are not available on tensor expressions. In order to access the values of a tensor expression, the expression must either be evaluated or wrapped in a TensorRef.</p>
<h2><a class="anchor" id="autotoc_md1199"></a>
<code>Scalar* data()</code> and <code>const Scalar* data() const</code></h2>
<p>Returns a pointer to the storage for the tensor. The pointer is const if the tensor was const. This allows direct access to the data. The layout of the data depends on the tensor layout: RowMajor or ColMajor.</p>
<p>This access is usually only needed for special cases, for example when mixing <a class="el" href="namespace_eigen.html" title="Namespace containing all symbols from the Eigen library.">Eigen</a> <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a> code with other libraries.</p>
<p><a class="el" href="bench__gemm_8cpp.html#a052eb942d12b6404aade6fae4b075fb9">Scalar</a> is the type of data stored in the tensor. </p><pre class="fragment">Eigen::Tensor&lt;float, 2&gt; a(3, 4);
float* a_data = a.data();
a_data[0] = 123.45f;
cout &lt;&lt; "a(0, 0): " &lt;&lt; a(0, 0);
=&gt; a(0, 0): 123.45
</pre><h1><a class="anchor" id="autotoc_md1200"></a>
Tensor Operations</h1>
<p>All the methods documented below return non evaluated tensor <code>Operations</code>. These can be chained: you can apply another <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a> Operation to the value returned by the method.</p>
<p>The chain of Operation is evaluated lazily, typically when it is assigned to a tensor. See "Controlling when Expression are Evaluated" for more details about their evaluation.</p>
<h2><a class="anchor" id="autotoc_md1201"></a>
<code>&lt;Operation&gt; constant(const Scalar&amp; val)</code></h2>
<p>Returns a tensor of the same type and dimensions as the original tensor but where all elements have the value <code>val</code>.</p>
<p>This is useful, for example, when you want to add or subtract a constant from a tensor, or multiply every element of a tensor by a scalar. </p><pre class="fragment">Eigen::Tensor&lt;float, 2&gt; a(2, 3);
a.setConstant(1.0f);
Eigen::Tensor&lt;float, 2&gt; b = a + a.constant(2.0f);
Eigen::Tensor&lt;float, 2&gt; c = b * b.constant(0.2f);
cout &lt;&lt; "a" &lt;&lt; endl &lt;&lt; a &lt;&lt; endl &lt;&lt; endl;
cout &lt;&lt; "b" &lt;&lt; endl &lt;&lt; b &lt;&lt; endl &lt;&lt; endl;
cout &lt;&lt; "c" &lt;&lt; endl &lt;&lt; c &lt;&lt; endl &lt;&lt; endl;
=&gt;
a
1 1 1
1 1 1

b
3 3 3
3 3 3

c
0.6 0.6 0.6
0.6 0.6 0.6
</pre><h2><a class="anchor" id="autotoc_md1202"></a>
<code>&lt;Operation&gt; random()</code></h2>
<p>Returns a tensor of the same type and dimensions as the current tensor but where all elements have random values.</p>
<p>This is for example useful to add random values to an existing tensor. The generation of random values can be customized in the same manner as for <code><a class="el" href="_householder_q_r__householder_q_8cpp.html#a7bddadaf72fd7356fb04dd15cf547bc2">setRandom()</a></code>. </p><pre class="fragment">Eigen::Tensor&lt;float, 2&gt; a(2, 3);
a.setConstant(1.0f);
Eigen::Tensor&lt;float, 2&gt; b = a + a.random();
cout &lt;&lt; "a" &lt;&lt; endl &lt;&lt; a &lt;&lt; endl &lt;&lt; endl;
cout &lt;&lt; "b" &lt;&lt; endl &lt;&lt; b &lt;&lt; endl &lt;&lt; endl;
=&gt;
a
1 1 1
1 1 1

b
1.68038   1.5662  1.82329
0.788766  1.59688 0.395103
</pre><h1><a class="anchor" id="autotoc_md1203"></a>
Unary Element Wise Operations</h1>
<p>All these operations take a single input tensor as argument and return a tensor of the same type and dimensions as the tensor to which they are applied. The requested operations are applied to each element independently.</p>
<h2><a class="anchor" id="autotoc_md1204"></a>
<code>&lt;Operation&gt; operator-()</code></h2>
<p>Returns a tensor of the same type and dimensions as the original tensor containing the opposite values of the original tensor. </p><pre class="fragment">Eigen::Tensor&lt;float, 2&gt; a(2, 3);
a.setConstant(1.0f);
Eigen::Tensor&lt;float, 2&gt; b = -a;
cout &lt;&lt; "a" &lt;&lt; endl &lt;&lt; a &lt;&lt; endl &lt;&lt; endl;
cout &lt;&lt; "b" &lt;&lt; endl &lt;&lt; b &lt;&lt; endl &lt;&lt; endl;
=&gt;
a
1 1 1
1 1 1

b
-1 -1 -1
-1 -1 -1
</pre><h2><a class="anchor" id="autotoc_md1205"></a>
<code>&lt;Operation&gt; sqrt()</code></h2>
<p>Returns a tensor of the same type and dimensions as the original tensor containing the square roots of the original tensor.</p>
<h2><a class="anchor" id="autotoc_md1206"></a>
<code>&lt;Operation&gt; rsqrt()</code></h2>
<p>Returns a tensor of the same type and dimensions as the original tensor containing the inverse square roots of the original tensor.</p>
<h2><a class="anchor" id="autotoc_md1207"></a>
<code>&lt;Operation&gt; square()</code></h2>
<p>Returns a tensor of the same type and dimensions as the original tensor containing the squares of the original tensor values.</p>
<h2><a class="anchor" id="autotoc_md1208"></a>
<code>&lt;Operation&gt; inverse()</code></h2>
<p>Returns a tensor of the same type and dimensions as the original tensor containing the inverse of the original tensor values.</p>
<h2><a class="anchor" id="autotoc_md1209"></a>
<code>&lt;Operation&gt; exp()</code></h2>
<p>Returns a tensor of the same type and dimensions as the original tensor containing the exponential of the original tensor.</p>
<h2><a class="anchor" id="autotoc_md1210"></a>
<code>&lt;Operation&gt; log()</code></h2>
<p>Returns a tensor of the same type and dimensions as the original tensor containing the natural logarithms of the original tensor.</p>
<h2><a class="anchor" id="autotoc_md1211"></a>
<code>&lt;Operation&gt; abs()</code></h2>
<p>Returns a tensor of the same type and dimensions as the original tensor containing the absolute values of the original tensor.</p>
<h2><a class="anchor" id="autotoc_md1212"></a>
<code>&lt;Operation&gt; pow(Scalar exponent)</code></h2>
<p>Returns a tensor of the same type and dimensions as the original tensor containing the coefficients of the original tensor to the power of the exponent.</p>
<p>The type of the exponent, <a class="el" href="bench__gemm_8cpp.html#a052eb942d12b6404aade6fae4b075fb9">Scalar</a>, is always the same as the type of the tensor coefficients. For example, only integer exponents can be used in conjuntion with tensors of integer values.</p>
<p>You can use <a class="el" href="_common_cwise_unary_ops_8h.html#aa89d007196125d10fa7d6e19811aca05">cast()</a> to lift this restriction. For example this computes cubic roots of an int <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a>: </p><pre class="fragment">Eigen::Tensor&lt;int, 2&gt; a(2, 3);
a.setValues({{0, 1, 8}, {27, 64, 125}});
Eigen::Tensor&lt;double, 2&gt; b = a.cast&lt;double&gt;().pow(1.0 / 3.0);
cout &lt;&lt; "a" &lt;&lt; endl &lt;&lt; a &lt;&lt; endl &lt;&lt; endl;
cout &lt;&lt; "b" &lt;&lt; endl &lt;&lt; b &lt;&lt; endl &lt;&lt; endl;
=&gt;
a
0   1   8
27  64 125

b
0 1 2
3 4 5
</pre><h2><a class="anchor" id="autotoc_md1213"></a>
<code>&lt;Operation&gt; operator * (Scalar scale)</code></h2>
<p>Multiplies all the coefficients of the input tensor by the provided scale.</p>
<h2><a class="anchor" id="autotoc_md1214"></a>
<code>&lt;Operation&gt; cwiseMax(Scalar threshold)</code></h2>
<p>TODO</p>
<h2><a class="anchor" id="autotoc_md1215"></a>
<code>&lt;Operation&gt; cwiseMin(Scalar threshold)</code></h2>
<p>TODO</p>
<h2><a class="anchor" id="autotoc_md1216"></a>
<code>&lt;Operation&gt; unaryExpr(const CustomUnaryOp&amp; func)</code></h2>
<p>TODO</p>
<h1><a class="anchor" id="autotoc_md1217"></a>
Binary Element Wise Operations</h1>
<p>These operations take two input tensors as arguments. The 2 input tensors should be of the same type and dimensions. The result is a tensor of the same dimensions as the tensors to which they are applied, and unless otherwise specified it is also of the same type. The requested operations are applied to each pair of elements independently.</p>
<h2><a class="anchor" id="autotoc_md1218"></a>
<code>&lt;Operation&gt; operator+(const OtherDerived&amp; other)</code></h2>
<p>Returns a tensor of the same type and dimensions as the input tensors containing the coefficient wise sums of the inputs.</p>
<h2><a class="anchor" id="autotoc_md1219"></a>
<code>&lt;Operation&gt; operator-(const OtherDerived&amp; other)</code></h2>
<p>Returns a tensor of the same type and dimensions as the input tensors containing the coefficient wise differences of the inputs.</p>
<h2><a class="anchor" id="autotoc_md1220"></a>
<code>&lt;Operation&gt; operator*(const OtherDerived&amp; other)</code></h2>
<p>Returns a tensor of the same type and dimensions as the input tensors containing the coefficient wise products of the inputs.</p>
<h2><a class="anchor" id="autotoc_md1221"></a>
<code>&lt;Operation&gt; operator/(const OtherDerived&amp; other)</code></h2>
<p>Returns a tensor of the same type and dimensions as the input tensors containing the coefficient wise quotients of the inputs.</p>
<p>This operator is not supported for integer types.</p>
<h2><a class="anchor" id="autotoc_md1222"></a>
<code>&lt;Operation&gt; cwiseMax(const OtherDerived&amp; other)</code></h2>
<p>Returns a tensor of the same type and dimensions as the input tensors containing the coefficient wise maximums of the inputs.</p>
<h2><a class="anchor" id="autotoc_md1223"></a>
<code>&lt;Operation&gt; cwiseMin(const OtherDerived&amp; other)</code></h2>
<p>Returns a tensor of the same type and dimensions as the input tensors containing the coefficient wise mimimums of the inputs.</p>
<h2><a class="anchor" id="autotoc_md1224"></a>
<code>&lt;Operation&gt; Logical operators</code></h2>
<p>The following logical operators are supported as well:</p>
<ul>
<li>operator&amp;&amp;(const OtherDerived&amp; other)</li>
<li>operator||(const OtherDerived&amp; other)</li>
<li>operator&lt;(const OtherDerived&amp; other)</li>
<li>operator&lt;=(const OtherDerived&amp; other)</li>
<li>operator&gt;(const OtherDerived&amp; other)</li>
<li>operator&gt;=(const OtherDerived&amp; other)</li>
<li>operator==(const OtherDerived&amp; other)</li>
<li>operator!=(const OtherDerived&amp; other)</li>
</ul>
<p>They all return a tensor of boolean values.</p>
<h1><a class="anchor" id="autotoc_md1225"></a>
Selection (select(const ThenDerived&amp; thenTensor, const ElseDerived&amp; elseTensor)</h1>
<p>Selection is a coefficient-wise ternary operator that is the tensor equivalent to the if-then-else operation. </p><pre class="fragment">Tensor&lt;bool, 3&gt; if = ...;
Tensor&lt;float, 3&gt; then = ...;
Tensor&lt;float, 3&gt; else = ...;
Tensor&lt;float, 3&gt; result = if.select(then, else);
</pre><p>The 3 arguments must be of the same dimensions, which will also be the dimension of the result. The 'if' tensor must be of type boolean, the 'then' and the 'else' tensor must be of the same type, which will also be the type of the result.</p>
<p>Each coefficient in the result is equal to the corresponding coefficient in the 'then' tensor if the corresponding value in the 'if' tensor is true. If not, the resulting coefficient will come from the 'else' tensor.</p>
<h1><a class="anchor" id="autotoc_md1226"></a>
Contraction</h1>
<p><a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a> <em>contractions</em> are a generalization of the matrix product to the multidimensional case. </p><pre class="fragment">// Create 2 matrices using tensors of rank 2
Eigen::Tensor&lt;int, 2&gt; a(2, 3);
a.setValues({{1, 2, 3}, {6, 5, 4}});
Eigen::Tensor&lt;int, 2&gt; b(3, 2);
b.setValues({{1, 2}, {4, 5}, {5, 6}});

// Compute the traditional matrix product
Eigen::array&lt;Eigen::IndexPair&lt;int&gt;, 1&gt; product_dims = { Eigen::IndexPair&lt;int&gt;(1, 0) };
Eigen::Tensor&lt;int, 2&gt; AB = a.contract(b, product_dims);

// Compute the product of the transpose of the matrices
Eigen::array&lt;Eigen::IndexPair&lt;int&gt;, 1&gt; transposed_product_dims = { Eigen::IndexPair&lt;int&gt;(0, 1) };
Eigen::Tensor&lt;int, 2&gt; AtBt = a.contract(b, transposed_product_dims);

// Contraction to scalar value using a double contraction.
// First coordinate of both tensors are contracted as well as both second coordinates, i.e., this computes the sum of the squares of the elements.
Eigen::array&lt;Eigen::IndexPair&lt;int&gt;, 2&gt; double_contraction_product_dims = { Eigen::IndexPair&lt;int&gt;(0, 0), Eigen::IndexPair&lt;int&gt;(1, 1) };
Eigen::Tensor&lt;int, 0&gt; AdoubleContractedA = a.contract(a, double_contraction_product_dims);

// Extracting the scalar value of the tensor contraction for further usage
int value = AdoubleContractedA(0);
</pre><h1><a class="anchor" id="autotoc_md1227"></a>
Reduction Operations</h1>
<p><a class="el" href="bench__gemm_8cpp.html#addc86e8508f14411ec98f521c520f875">A</a> <em>Reduction</em> operation returns a tensor with fewer dimensions than the original tensor. The values in the returned tensor are computed by applying a <em>reduction operator</em> to slices of values from the original tensor. You specify the dimensions along which the slices are made.</p>
<p>The <a class="el" href="namespace_eigen.html" title="Namespace containing all symbols from the Eigen library.">Eigen</a> <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a> library provides a set of predefined reduction operators such as <code>maximum()</code> and <code><a class="el" href="test__parallel__for__each_8cpp.html#a539b07c7f86d3a9854ed81da50a4fb7d">sum()</a></code> and lets you define additional operators by implementing a few methods from a reductor template.</p>
<h2><a class="anchor" id="autotoc_md1228"></a>
Reduction Dimensions</h2>
<p>All reduction operations take a single parameter of type <code>&lt;TensorType&gt;::</code><code>Dimensions</code> which can always be specified as an array of ints. These are called the "reduction dimensions." The values are the indices of the dimensions of the input tensor over which the reduction is done. The parameter can have at most as many element as the rank of the input tensor; each element must be less than the tensor rank, as it indicates one of the dimensions to reduce.</p>
<p>Each dimension of the input tensor should occur at most once in the reduction dimensions as the implementation does not remove duplicates.</p>
<p>The order of the values in the reduction dimensions does not affect the results, but the code may execute faster if you list the dimensions in increasing order.</p>
<p>Example: Reduction along one dimension. </p><pre class="fragment">// Create a tensor of 2 dimensions
Eigen::Tensor&lt;int, 2&gt; a(2, 3);
a.setValues({{1, 2, 3}, {6, 5, 4}});
// Reduce it along the second dimension (1)...
Eigen::array&lt;int, 1&gt; dims({1 /* dimension to reduce */});
// ...using the "maximum" operator.
// The result is a tensor with one dimension.  The size of
// that dimension is the same as the first (non-reduced) dimension of a.
Eigen::Tensor&lt;int, 1&gt; b = a.maximum(dims);
cout &lt;&lt; "a" &lt;&lt; endl &lt;&lt; a &lt;&lt; endl &lt;&lt; endl;
cout &lt;&lt; "b" &lt;&lt; endl &lt;&lt; b &lt;&lt; endl &lt;&lt; endl;
=&gt;
a
1 2 3
6 5 4

b
3
6
</pre><p>Example: Reduction along two dimensions. </p><pre class="fragment">Eigen::Tensor&lt;float, 3, Eigen::ColMajor&gt; a(2, 3, 4);
a.setValues({{{0.0f, 1.0f, 2.0f, 3.0f},
              {7.0f, 6.0f, 5.0f, 4.0f},
              {8.0f, 9.0f, 10.0f, 11.0f}},
             {{12.0f, 13.0f, 14.0f, 15.0f},
              {19.0f, 18.0f, 17.0f, 16.0f},
              {20.0f, 21.0f, 22.0f, 23.0f}}});
// The tensor a has 3 dimensions.  We reduce along the
// first 2, resulting in a tensor with a single dimension
// of size 4 (the last dimension of a.)
// Note that we pass the array of reduction dimensions
// directly to the maximum() call.
Eigen::Tensor&lt;float, 1, Eigen::ColMajor&gt; b =
    a.maximum(Eigen::array&lt;int, 2&gt;({0, 1}));
cout &lt;&lt; "b" &lt;&lt; endl &lt;&lt; b &lt;&lt; endl &lt;&lt; endl;
=&gt;
b
20
21
22
23
</pre><h3><a class="anchor" id="autotoc_md1229"></a>
Reduction along all dimensions</h3>
<p>As a special case, if you pass no parameter to a reduction operation the original tensor is reduced along <em>all</em> its dimensions. The result is a scalar, represented as a zero-dimension tensor. </p><pre class="fragment">Eigen::Tensor&lt;float, 3&gt; a(2, 3, 4);
a.setValues({{{0.0f, 1.0f, 2.0f, 3.0f},
              {7.0f, 6.0f, 5.0f, 4.0f},
              {8.0f, 9.0f, 10.0f, 11.0f}},
             {{12.0f, 13.0f, 14.0f, 15.0f},
              {19.0f, 18.0f, 17.0f, 16.0f},
              {20.0f, 21.0f, 22.0f, 23.0f}}});
// Reduce along all dimensions using the sum() operator.
Eigen::Tensor&lt;float, 0&gt; b = a.sum();
cout &lt;&lt; "b" &lt;&lt; endl &lt;&lt; b &lt;&lt; endl &lt;&lt; endl;
=&gt;
b
276
</pre><h2><a class="anchor" id="autotoc_md1230"></a>
<code>&lt;Operation&gt; sum(const Dimensions&amp; new_dims)</code></h2>
<h2><a class="anchor" id="autotoc_md1231"></a>
<code>&lt;Operation&gt; sum()</code></h2>
<p>Reduce a tensor using the <a class="el" href="test__parallel__for__each_8cpp.html#a539b07c7f86d3a9854ed81da50a4fb7d">sum()</a> operator. The resulting values are the sum of the reduced values.</p>
<h2><a class="anchor" id="autotoc_md1232"></a>
<code>&lt;Operation&gt; mean(const Dimensions&amp; new_dims)</code></h2>
<h2><a class="anchor" id="autotoc_md1233"></a>
<code>&lt;Operation&gt; mean()</code></h2>
<p>Reduce a tensor using the mean() operator. The resulting values are the mean of the reduced values.</p>
<h2><a class="anchor" id="autotoc_md1234"></a>
<code>&lt;Operation&gt; maximum(const Dimensions&amp; new_dims)</code></h2>
<h2><a class="anchor" id="autotoc_md1235"></a>
<code>&lt;Operation&gt; maximum()</code></h2>
<p>Reduce a tensor using the maximum() operator. The resulting values are the largest of the reduced values.</p>
<h2><a class="anchor" id="autotoc_md1236"></a>
<code>&lt;Operation&gt; minimum(const Dimensions&amp; new_dims)</code></h2>
<h2><a class="anchor" id="autotoc_md1237"></a>
<code>&lt;Operation&gt; minimum()</code></h2>
<p>Reduce a tensor using the minimum() operator. The resulting values are the smallest of the reduced values.</p>
<h2><a class="anchor" id="autotoc_md1238"></a>
<code>&lt;Operation&gt; prod(const Dimensions&amp; new_dims)</code></h2>
<h2><a class="anchor" id="autotoc_md1239"></a>
<code>&lt;Operation&gt; prod()</code></h2>
<p>Reduce a tensor using the <a class="el" href="product__threshold_8cpp.html#a4c8a5d15c39c46c003b0faca699d3d36">prod()</a> operator. The resulting values are the product of the reduced values.</p>
<h2><a class="anchor" id="autotoc_md1240"></a>
<code>&lt;Operation&gt; all(const Dimensions&amp; new_dims)</code></h2>
<h2><a class="anchor" id="autotoc_md1241"></a>
<code>&lt;Operation&gt; all()</code></h2>
<p>Reduce a tensor using the all() operator. Casts tensor to bool and then checks whether all elements are true. Runs through all elements rather than short-circuiting, so may be significantly inefficient.</p>
<h2><a class="anchor" id="autotoc_md1242"></a>
<code>&lt;Operation&gt; any(const Dimensions&amp; new_dims)</code></h2>
<h2><a class="anchor" id="autotoc_md1243"></a>
<code>&lt;Operation&gt; any()</code></h2>
<p>Reduce a tensor using the any() operator. Casts tensor to bool and then checks whether any element is true. Runs through all elements rather than short-circuiting, so may be significantly inefficient.</p>
<h2><a class="anchor" id="autotoc_md1244"></a>
<code>&lt;Operation&gt; reduce(const Dimensions&amp; new_dims, const Reducer&amp; reducer)</code></h2>
<p>Reduce a tensor using a user-defined reduction operator. See <code>SumReducer</code> in <a class="el" href="_tensor_functors_8h.html">TensorFunctors.h</a> for information on how to implement a reduction operator.</p>
<h1><a class="anchor" id="autotoc_md1245"></a>
Scan Operations</h1>
<p><a class="el" href="bench__gemm_8cpp.html#addc86e8508f14411ec98f521c520f875">A</a> <em>Scan</em> operation returns a tensor with the same dimensions as the original tensor. The operation performs an inclusive scan along the specified axis, which means it computes a running total along the axis for a given reduction operation. If the reduction operation corresponds to summation, then this computes the prefix sum of the tensor along the given axis.</p>
<p>Example: dd a comment to this line </p><pre class="fragment">// Create a tensor of 2 dimensions
Eigen::Tensor&lt;int, 2&gt; a(2, 3);
a.setValues({{1, 2, 3}, {4, 5, 6}});
// Scan it along the second dimension (1) using summation
Eigen::Tensor&lt;int, 2&gt; b = a.cumsum(1);
// The result is a tensor with the same size as the input
cout &lt;&lt; "a" &lt;&lt; endl &lt;&lt; a &lt;&lt; endl &lt;&lt; endl;
cout &lt;&lt; "b" &lt;&lt; endl &lt;&lt; b &lt;&lt; endl &lt;&lt; endl;
=&gt;
a
1 2 3
4 5 6

b
1  3  6
4  9 15
</pre><h2><a class="anchor" id="autotoc_md1246"></a>
<code>&lt;Operation&gt; cumsum(const Index&amp; axis)</code></h2>
<p>Perform a scan by summing consecutive entries.</p>
<h2><a class="anchor" id="autotoc_md1247"></a>
<code>&lt;Operation&gt; cumprod(const Index&amp; axis)</code></h2>
<p>Perform a scan by multiplying consecutive entries.</p>
<h1><a class="anchor" id="autotoc_md1248"></a>
Convolutions</h1>
<h2><a class="anchor" id="autotoc_md1249"></a>
<code>&lt;Operation&gt; convolve(const Kernel&amp; kernel, const Dimensions&amp; dims)</code></h2>
<p>Returns a tensor that is the output of the convolution of the input tensor with the kernel, along the specified dimensions of the input tensor. The dimension size for dimensions of the output tensor which were part of the convolution will be reduced by the formula: output_dim_size = input_dim_size - kernel_dim_size + 1 (requires: input_dim_size &gt;= kernel_dim_size). The dimension sizes for dimensions that were not part of the convolution will remain the same. Performance of the convolution can depend on the length of the <a class="el" href="imgui__impl__opengl3__loader_8h.html#adec60f1216ca1b900f8d776c5b6190e0">stride(s)</a> of the input tensor dimension(s) along which the convolution is computed (the first dimension has the shortest stride for ColMajor, whereas RowMajor's shortest stride is for the last dimension). </p><pre class="fragment">// Compute convolution along the second and third dimension.
Tensor&lt;float, 4, DataLayout&gt; input(3, 3, 7, 11);
Tensor&lt;float, 2, DataLayout&gt; kernel(2, 2);
Tensor&lt;float, 4, DataLayout&gt; output(3, 2, 6, 11);
input.setRandom();
kernel.setRandom();

Eigen::array&lt;ptrdiff_t, 2&gt; dims({1, 2});  // Specify second and third dimension for convolution.
output = input.convolve(kernel, dims);

for (int i = 0; i &lt; 3; ++i) {
  for (int j = 0; j &lt; 2; ++j) {
    for (int k = 0; k &lt; 6; ++k) {
      for (int l = 0; l &lt; 11; ++l) {
        const float result = output(i,j,k,l);
        const float expected = input(i,j+0,k+0,l) * kernel(0,0) +
                               input(i,j+1,k+0,l) * kernel(1,0) +
                               input(i,j+0,k+1,l) * kernel(0,1) +
                               input(i,j+1,k+1,l) * kernel(1,1);
        VERIFY_IS_APPROX(result, expected);
      }
    }
  }
}
</pre><h1><a class="anchor" id="autotoc_md1250"></a>
Geometrical Operations</h1>
<p>These operations return a <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a> with different dimensions than the original <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a>. They can be used to access slices of tensors, see them with different dimensions, or pad tensors with additional data.</p>
<h2><a class="anchor" id="autotoc_md1251"></a>
<code>&lt;Operation&gt; reshape(const Dimensions&amp; new_dims)</code></h2>
<p>Returns a view of the input tensor that has been reshaped to the specified new dimensions. The argument new_dims is an array of Index values. The rank of the resulting tensor is equal to the number of elements in new_dims.</p>
<p>The product of all the sizes in the new dimension array must be equal to the number of elements in the input tensor. </p><pre class="fragment">// Increase the rank of the input tensor by introducing a new dimension
// of size 1.
Tensor&lt;float, 2&gt; input(7, 11);
array&lt;int, 3&gt; three_dims{{7, 11, 1}};
Tensor&lt;float, 3&gt; result = input.reshape(three_dims);

// Decrease the rank of the input tensor by merging 2 dimensions;
array&lt;int, 1&gt; one_dim{{7 * 11}};
Tensor&lt;float, 1&gt; result = input.reshape(one_dim);
</pre><p>This operation does not move any data in the input tensor, so the resulting contents of a reshaped <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a> depend on the data layout of the original <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a>.</p>
<p>For example this is what happens when you <code><a class="el" href="boing_8c.html#a5272e39ef9d8944cb3f99d656f9f555a">reshape()</a></code> a 2D ColMajor tensor to one dimension: </p><pre class="fragment">Eigen::Tensor&lt;float, 2, Eigen::ColMajor&gt; a(2, 3);
a.setValues({{0.0f, 100.0f, 200.0f}, {300.0f, 400.0f, 500.0f}});
Eigen::array&lt;Eigen::DenseIndex, 1&gt; one_dim({3 * 2});
Eigen::Tensor&lt;float, 1, Eigen::ColMajor&gt; b = a.reshape(one_dim);
cout &lt;&lt; "b" &lt;&lt; endl &lt;&lt; b &lt;&lt; endl;
=&gt;
b
  0
300
100
400
200
500
</pre><p>This is what happens when the 2D <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a> is RowMajor: </p><pre class="fragment">Eigen::Tensor&lt;float, 2, Eigen::RowMajor&gt; a(2, 3);
a.setValues({{0.0f, 100.0f, 200.0f}, {300.0f, 400.0f, 500.0f}});
Eigen::array&lt;Eigen::DenseIndex, 1&gt; one_dim({3 * 2});
Eigen::Tensor&lt;float, 1, Eigen::RowMajor&gt; b = a.reshape(one_dim);
cout &lt;&lt; "b" &lt;&lt; endl &lt;&lt; b &lt;&lt; endl;
=&gt;
b
  0
100
200
300
400
500
</pre><p>The reshape operation is a lvalue. In other words, it can be used on the left side of the assignment operator.</p>
<p>The previous example can be rewritten as follow: </p><pre class="fragment">Eigen::Tensor&lt;float, 2, Eigen::ColMajor&gt; a(2, 3);
a.setValues({{0.0f, 100.0f, 200.0f}, {300.0f, 400.0f, 500.0f}});
Eigen::array&lt;Eigen::DenseIndex, 2&gt; two_dim({2, 3});
Eigen::Tensor&lt;float, 1, Eigen::ColMajor&gt; b(6);
b.reshape(two_dim) = a;
cout &lt;&lt; "b" &lt;&lt; endl &lt;&lt; b &lt;&lt; endl;
=&gt;
b
  0
300
100
400
200
500
</pre><p>Note that "b" itself was not reshaped but that instead the assignment is done to the reshape view of b.</p>
<h2><a class="anchor" id="autotoc_md1252"></a>
<code>&lt;Operation&gt; shuffle(const Shuffle&amp; shuffle)</code></h2>
<p>Returns a copy of the input tensor whose dimensions have been reordered according to the specified permutation. The argument shuffle is an array of Index values. Its size is the rank of the input tensor. It must contain a permutation of 0, 1, ..., rank - 1. The i-th dimension of the output tensor equals to the size of the shuffle[i]-th dimension of the input tensor. For example: </p><pre class="fragment">// Shuffle all dimensions to the left by 1.
Tensor&lt;float, 3&gt; input(20, 30, 50);
// ... set some values in input.
Tensor&lt;float, 3&gt; output = input.shuffle({1, 2, 0})

eigen_assert(output.dimension(0) == 30);
eigen_assert(output.dimension(1) == 50);
eigen_assert(output.dimension(2) == 20);
</pre><p>Indices into the output tensor are shuffled accordingly to formulate indices into the input tensor. For example, one can assert in the above code snippet that: </p><pre class="fragment">eigen_assert(output(3, 7, 11) == input(11, 3, 7));
</pre><p>In general, one can assert that </p><pre class="fragment">eigen_assert(output(..., indices[shuffle[i]], ...) ==
             input(..., indices[i], ...))
</pre><p>The shuffle operation results in a lvalue, which means that it can be assigned to. In other words, it can be used on the left side of the assignment operator.</p>
<p>Let's rewrite the previous example to take advantage of this feature: </p><pre class="fragment">// Shuffle all dimensions to the left by 1.
Tensor&lt;float, 3&gt; input(20, 30, 50);
// ... set some values in input.
Tensor&lt;float, 3&gt; output(30, 50, 20);
output.shuffle({2, 0, 1}) = input;
</pre><h2><a class="anchor" id="autotoc_md1253"></a>
<code>&lt;Operation&gt; stride(const Strides&amp; strides)</code></h2>
<p>Returns a view of the input tensor that strides (skips stride-1 elements) along each of the dimensions. The argument strides is an array of Index values. The dimensions of the resulting tensor are ceil(input_dimensions[i] / strides[i]).</p>
<p>For example this is what happens when you <code><a class="el" href="imgui__impl__opengl3__loader_8h.html#adec60f1216ca1b900f8d776c5b6190e0">stride()</a></code> a 2D tensor: </p><pre class="fragment">Eigen::Tensor&lt;int, 2&gt; a(4, 3);
a.setValues({{0, 100, 200}, {300, 400, 500}, {600, 700, 800}, {900, 1000, 1100}});
Eigen::array&lt;Eigen::DenseIndex, 2&gt; strides({3, 2});
Eigen::Tensor&lt;int, 2&gt; b = a.stride(strides);
cout &lt;&lt; "b" &lt;&lt; endl &lt;&lt; b &lt;&lt; endl;
=&gt;
b
   0   200
 900  1100
</pre><p>It is possible to assign a tensor to a stride: <a class="el" href="class_tensor.html" title="The tensor class.">Tensor&lt;float, 3&gt;</a> <a class="el" href="benchmarks_2scan_2scan_8hpp.html#ab7e6955a695fad0be513586926040b1a">input(20, 30, 50)</a>; // ... set some values in input. <a class="el" href="class_tensor.html" title="The tensor class.">Tensor&lt;float, 3&gt;</a> <a class="el" href="benchmarks_2scan_2scan_8hpp.html#a8390452002ecc7a0dadc5ae0dccc9b6c">output(40, 90, 200)</a>; output.stride({2, 3, 4}) = input;</p>
<h2><a class="anchor" id="autotoc_md1254"></a>
<code>&lt;Operation&gt; slice(const StartIndices&amp; offsets, const Sizes&amp; extents)</code></h2>
<p>Returns a sub-tensor of the given tensor. For each dimension i, the slice is made of the coefficients stored between offset[i] and offset[i] + extents[i] in the input tensor. </p><pre class="fragment">Eigen::Tensor&lt;int, 2&gt; a(4, 3);
a.setValues({{0, 100, 200}, {300, 400, 500},
             {600, 700, 800}, {900, 1000, 1100}});
Eigen::array&lt;int, 2&gt; offsets = {1, 0};
Eigen::array&lt;int, 2&gt; extents = {2, 2};
Eigen::Tensor&lt;int, 1&gt; slice = a.slice(offsets, extents);
cout &lt;&lt; "a" &lt;&lt; endl &lt;&lt; a &lt;&lt; endl;
=&gt;
a
   0   100   200
 300   400   500
 600   700   800
 900  1000  1100
cout &lt;&lt; "slice" &lt;&lt; endl &lt;&lt; slice &lt;&lt; endl;
=&gt;
slice
 300   400
 600   700
</pre><h2><a class="anchor" id="autotoc_md1255"></a>
<code>&lt;Operation&gt; chip(const Index offset, const Index dim)</code></h2>
<p><a class="el" href="bench__gemm_8cpp.html#addc86e8508f14411ec98f521c520f875">A</a> chip is a special kind of slice. It is the subtensor at the given offset in the dimension dim. The returned tensor has one fewer dimension than the input tensor: the dimension dim is removed.</p>
<p>For example, a matrix chip would be either a row or a column of the input matrix. </p><pre class="fragment">Eigen::Tensor&lt;int, 2&gt; a(4, 3);
a.setValues({{0, 100, 200}, {300, 400, 500},
             {600, 700, 800}, {900, 1000, 1100}});
Eigen::Tensor&lt;int, 1&gt; row_3 = a.chip(2, 0);
Eigen::Tensor&lt;int, 1&gt; col_2 = a.chip(1, 1);
cout &lt;&lt; "a" &lt;&lt; endl &lt;&lt; a &lt;&lt; endl;
=&gt;
a
   0   100   200
 300   400   500
 600   700   800
 900  1000  1100
cout &lt;&lt; "row_3" &lt;&lt; endl &lt;&lt; row_3 &lt;&lt; endl;
=&gt;
row_3
   600   700   800
cout &lt;&lt; "col_2" &lt;&lt; endl &lt;&lt; col_2 &lt;&lt; endl;
=&gt;
col_2
   100   400   700    1000
</pre><p>It is possible to assign values to a tensor chip since the chip operation is a lvalue. For example: </p><pre class="fragment">Eigen::Tensor&lt;int, 1&gt; a(3);
a.setValues({{100, 200, 300}});
Eigen::Tensor&lt;int, 2&gt; b(2, 3);
b.setZero();
b.chip(0, 0) = a;
cout &lt;&lt; "a" &lt;&lt; endl &lt;&lt; a &lt;&lt; endl;
=&gt;
a
 100
 200
 300
cout &lt;&lt; "b" &lt;&lt; endl &lt;&lt; b &lt;&lt; endl;
=&gt;
b
   100   200   300
     0     0     0
</pre><h2><a class="anchor" id="autotoc_md1256"></a>
<code>&lt;Operation&gt; reverse(const ReverseDimensions&amp; reverse)</code></h2>
<p>Returns a view of the input tensor that reverses the order of the coefficients along a subset of the dimensions. The argument reverse is an array of boolean values that indicates whether or not the order of the coefficients should be reversed along each of the dimensions. This operation preserves the dimensions of the input tensor.</p>
<p>For example this is what happens when you <code><a class="el" href="runtime_2spdlog_2include_2spdlog_2fmt_2bundled_2color_8h.html#a535b59b8edc8902bb3c4f254625f91baa4d9c2073afa3c2abb817dceb22c34de6">reverse()</a></code> the first dimension of a 2D tensor: </p><pre class="fragment">Eigen::Tensor&lt;int, 2&gt; a(4, 3);
a.setValues({{0, 100, 200}, {300, 400, 500},
            {600, 700, 800}, {900, 1000, 1100}});
Eigen::array&lt;bool, 2&gt; reverse({true, false});
Eigen::Tensor&lt;int, 2&gt; b = a.reverse(reverse);
cout &lt;&lt; "a" &lt;&lt; endl &lt;&lt; a &lt;&lt; endl &lt;&lt; "b" &lt;&lt; endl &lt;&lt; b &lt;&lt; endl;
=&gt;
a
   0   100   200
 300   400   500
 600   700   800
 900  1000  1100
b
 900  1000  1100
 600   700   800
 300   400   500
   0   100   200
</pre><h2><a class="anchor" id="autotoc_md1257"></a>
<code>&lt;Operation&gt; broadcast(const Broadcast&amp; broadcast)</code></h2>
<p>Returns a view of the input tensor in which the input is replicated one to many times. The broadcast argument specifies how many copies of the input tensor need to be made in each of the dimensions. </p><pre class="fragment">Eigen::Tensor&lt;int, 2&gt; a(2, 3);
a.setValues({{0, 100, 200}, {300, 400, 500}});
Eigen::array&lt;int, 2&gt; bcast({3, 2});
Eigen::Tensor&lt;int, 2&gt; b = a.broadcast(bcast);
cout &lt;&lt; "a" &lt;&lt; endl &lt;&lt; a &lt;&lt; endl &lt;&lt; "b" &lt;&lt; endl &lt;&lt; b &lt;&lt; endl;
=&gt;
a
   0   100   200
 300   400   500
b
   0   100   200    0   100   200
 300   400   500  300   400   500
   0   100   200    0   100   200
 300   400   500  300   400   500
   0   100   200    0   100   200
 300   400   500  300   400   500
</pre><h2><a class="anchor" id="autotoc_md1258"></a>
<code>&lt;Operation&gt; concatenate(const OtherDerived&amp; other, Axis axis)</code></h2>
<p>TODO</p>
<h2><a class="anchor" id="autotoc_md1259"></a>
<code>&lt;Operation&gt; pad(const PaddingDimensions&amp; padding)</code></h2>
<p>Returns a view of the input tensor in which the input is padded with zeros. </p><pre class="fragment">Eigen::Tensor&lt;int, 2&gt; a(2, 3);
a.setValues({{0, 100, 200}, {300, 400, 500}});
Eigen::array&lt;pair&lt;int, int&gt;, 2&gt; paddings;
paddings[0] = make_pair(0, 1);
paddings[1] = make_pair(2, 3);
Eigen::Tensor&lt;int, 2&gt; b = a.pad(paddings);
cout &lt;&lt; "a" &lt;&lt; endl &lt;&lt; a &lt;&lt; endl &lt;&lt; "b" &lt;&lt; endl &lt;&lt; b &lt;&lt; endl;
=&gt;
a
   0   100   200
 300   400   500
b
   0     0     0    0
   0     0     0    0
   0   100   200    0
 300   400   500    0
   0     0     0    0
   0     0     0    0
   0     0     0    0
</pre><h2><a class="anchor" id="autotoc_md1260"></a>
<code>&lt;Operation&gt; extract_patches(const PatchDims&amp; patch_dims)</code></h2>
<p>Returns a tensor of coefficient patches extracted from the input tensor, where each patch is of dimension specified by 'patch_dims'. The returned tensor has one greater dimension than the input tensor, which is used to index each patch. The patch index in the output tensor depends on the data layout of the input tensor: the patch index is the last dimension ColMajor layout, and the first dimension in RowMajor layout.</p>
<p>For example, given the following input tensor:</p>
<p><a class="el" href="class_eigen_1_1_tensor.html" title="The tensor class.">Eigen::Tensor&lt;float, 2, DataLayout&gt;</a> tensor(3,4); tensor.setValues({{0.0f, 1.0f, 2.0f, 3.0f}, {4.0f, 5.0f, 6.0f, 7.0f}, {8.0f, 9.0f, 10.0f, 11.0f}});</p>
<p>cout &lt;&lt; "tensor: " &lt;&lt; endl &lt;&lt; tensor &lt;&lt; endl; =&gt; tensor: 0 1 2 3 4 5 6 7 8 9 10 11</p>
<p>Six 2x2 patches can be extracted and indexed using the following code:</p>
<p><a class="el" href="class_eigen_1_1_tensor.html" title="The tensor class.">Eigen::Tensor&lt;float, 3, DataLayout&gt;</a> patch; <a class="el" href="class_eigen_1_1array.html">Eigen::array&lt;ptrdiff_t, 2&gt;</a> patch_dims; patch_dims[0] = 2; patch_dims[1] = 2; patch = tensor.extract_patches(patch_dims); for (int k = 0; k &lt; 6; ++k) { cout &lt;&lt; "patch index: " &lt;&lt; k &lt;&lt; endl; for (int i = 0; i &lt; 2; ++i) { for (int j = 0; j &lt; 2; ++j) { if (DataLayout == ColMajor) { cout &lt;&lt; <a class="el" href="structpatch.html">patch(i, j, k)</a> &lt;&lt; " "; } else { cout &lt;&lt; <a class="el" href="structpatch.html">patch(k, i, j)</a> &lt;&lt; " "; } } cout &lt;&lt; endl; } }</p>
<p>This code results in the following output when the data layout is ColMajor:</p>
<p>patch index: 0 0 1 4 5 patch index: 1 4 5 8 9 patch index: 2 1 2 5 6 patch index: 3 5 6 9 10 patch index: 4 2 3 6 7 patch index: 5 6 7 10 11</p>
<p>This code results in the following output when the data layout is RowMajor: (NOTE: the set of patches is the same as in ColMajor, but are indexed differently).</p>
<p>patch index: 0 0 1 4 5 patch index: 1 1 2 5 6 patch index: 2 2 3 6 7 patch index: 3 4 5 8 9 patch index: 4 5 6 9 10 patch index: 5 6 7 10 11</p>
<h2><a class="anchor" id="autotoc_md1261"></a>
<code>&lt;Operation&gt; extract_image_patches(const Index patch_rows, const Index patch_cols, const Index row_stride, const Index col_stride, const PaddingType padding_type)</code></h2>
<p>Returns a tensor of coefficient image patches extracted from the input tensor, which is expected to have dimensions ordered as follows (depending on the data layout of the input tensor, and the number of additional dimensions 'N'):</p>
<p>*) ColMajor 1st dimension: channels (of size d) 2nd dimension: rows (of size r) 3rd dimension: columns (of size c) 4th-Nth dimension: time (for video) or batch (for bulk processing).</p>
<p>*) RowMajor (reverse order of ColMajor) 1st-Nth dimension: time (for video) or batch (for bulk processing). N+1'th dimension: columns (of size c) N+2'th dimension: rows (of size r) N+3'th dimension: channels (of size d)</p>
<p>The returned tensor has one greater dimension than the input tensor, which is used to index each patch. The patch index in the output tensor depends on the data layout of the input tensor: the patch index is the 4'th dimension in ColMajor layout, and the 4'th from the last dimension in RowMajor layout.</p>
<p>For example, given the following input tensor with the following dimension sizes: *) depth: 2 *) rows: 3 *) columns: 5 *) batch: 7</p>
<p><a class="el" href="class_tensor.html" title="The tensor class.">Tensor&lt;float, 4&gt;</a> tensor(2,3,5,7); <a class="el" href="class_tensor.html" title="The tensor class.">Tensor&lt;float, 4, RowMajor&gt;</a> tensor_row_major = tensor.swap_layout();</p>
<p>2x2 image patches can be extracted and indexed using the following code:</p>
<p>*) 2D patch: ColMajor (patch indexed by second-to-last dimension) <a class="el" href="class_tensor.html" title="The tensor class.">Tensor&lt;float, 5&gt;</a> twod_patch; twod_patch = tensor.extract_image_patches&lt;2, 2&gt;(); // twod_patch.dimension(0) == 2 // twod_patch.dimension(1) == 2 // twod_patch.dimension(2) == 2 // twod_patch.dimension(3) == 3*5 // twod_patch.dimension(4) == 7</p>
<p>*) 2D patch: RowMajor (patch indexed by the second dimension) <a class="el" href="class_tensor.html" title="The tensor class.">Tensor&lt;float, 5, RowMajor&gt;</a> twod_patch_row_major; twod_patch_row_major = tensor_row_major.extract_image_patches&lt;2, 2&gt;(); // twod_patch_row_major.dimension(0) == 7 // twod_patch_row_major.dimension(1) == 3*5 // twod_patch_row_major.dimension(2) == 2 // twod_patch_row_major.dimension(3) == 2 // twod_patch_row_major.dimension(4) == 2</p>
<h1><a class="anchor" id="autotoc_md1262"></a>
Special Operations</h1>
<h2><a class="anchor" id="autotoc_md1263"></a>
<code>&lt;Operation&gt; cast&lt;T&gt;()</code></h2>
<p>Returns a tensor of type T with the same dimensions as the original tensor. The returned tensor contains the values of the original tensor converted to type T. </p><pre class="fragment">Eigen::Tensor&lt;float, 2&gt; a(2, 3);
Eigen::Tensor&lt;int, 2&gt; b = a.cast&lt;int&gt;();
</pre><p>This can be useful for example if you need to do element-wise division of Tensors of integers. This is not currently supported by the <a class="el" href="class_tensor.html" title="The tensor class.">Tensor</a> library but you can easily cast the tensors to floats to do the division: </p><pre class="fragment">Eigen::Tensor&lt;int, 2&gt; a(2, 3);
a.setValues({{0, 1, 2}, {3, 4, 5}});
Eigen::Tensor&lt;int, 2&gt; b =
    (a.cast&lt;float&gt;() / a.constant(2).cast&lt;float&gt;()).cast&lt;int&gt;();
cout &lt;&lt; "a" &lt;&lt; endl &lt;&lt; a &lt;&lt; endl &lt;&lt; endl;
cout &lt;&lt; "b" &lt;&lt; endl &lt;&lt; b &lt;&lt; endl &lt;&lt; endl;
=&gt;
a
0 1 2
3 4 5

b
0 0 1
1 2 2
</pre><h2><a class="anchor" id="autotoc_md1264"></a>
<code>&lt;Operation&gt; eval()</code></h2>
<p>TODO</p>
<h1><a class="anchor" id="autotoc_md1265"></a>
Representation of scalar values</h1>
<p><a class="el" href="bench__gemm_8cpp.html#a052eb942d12b6404aade6fae4b075fb9">Scalar</a> values are often represented by tensors of size 1 and rank 0.For example Tensor&lt;T, N&gt;::maximum() currently returns a <a class="el" href="class_tensor.html" title="The tensor class.">Tensor&lt;T, 0&gt;</a>. Similarly, the inner product of 2 1d tensors (through contractions) returns a 0d tensor.</p>
<h1><a class="anchor" id="autotoc_md1266"></a>
Limitations</h1>
<ul>
<li>The number of tensor dimensions is currently limited to 250 when using a compiler that supports cxx11. It is limited to only 5 for older compilers.</li>
<li>The IndexList class requires a cxx11 compliant compiler. You can use an array of indices instead if you don't have access to a modern compiler.</li>
<li>On GPUs only floating point values are properly tested and optimized for.</li>
<li><a class="el" href="external_2taskflow_23rd-party_2eigen-3_83_87_2blas_2common_8h.html#a1a215510434ed195e4ce08e1f0b86afe">Complex</a> and integer values are known to be broken on GPUs. If you try to use them you'll most likely end up triggering a static assertion failure such as EIGEN_STATIC_ASSERT(packetSize &gt; 1, YOU_MADE_A_PROGRAMMING_MISTAKE) </li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_397d9aeee4af8edecac90968d93b57df.html">external</a></li><li class="navelem"><a class="el" href="dir_a586d2919c2294cf68ed57ec5a464d2f.html">taskflow</a></li><li class="navelem"><a class="el" href="dir_8a551ad5ddcada96b3faa8407baf5b5b.html">3rd-party</a></li><li class="navelem"><a class="el" href="dir_6c93be1e894d30561f4c37354dfed8f5.html">eigen-3.3.7</a></li><li class="navelem"><a class="el" href="dir_433b8db4572bc4fe5be144b7aa59565b.html">unsupported</a></li><li class="navelem"><a class="el" href="dir_a5de36d4bbea65a182d971d2cf008733.html">Eigen</a></li><li class="navelem"><a class="el" href="dir_ad2b2bf62dd385752d76ce18c79fa2e7.html">CXX11</a></li><li class="navelem"><a class="el" href="dir_d064e452fc2dade8b88ee01619c76d87.html">src</a></li><li class="navelem"><a class="el" href="dir_d977e71cbbd043db4da1270ffcf16b6b.html">Tensor</a></li>
    <li class="footer">制作者 <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.13.2 </li>
  </ul>
</div>
</body>
</html>
